{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,211\n",
      "Trainable params: 1,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2498/2498 [==============================] - 2s 719us/step - loss: 0.9448 - accuracy: 0.7167 - val_loss: 0.7910 - val_accuracy: 0.7391\n",
      "Epoch 2/50\n",
      "2498/2498 [==============================] - 2s 688us/step - loss: 0.7453 - accuracy: 0.7416 - val_loss: 0.7129 - val_accuracy: 0.7429\n",
      "Epoch 3/50\n",
      "2498/2498 [==============================] - 2s 952us/step - loss: 0.6951 - accuracy: 0.7440 - val_loss: 0.6815 - val_accuracy: 0.7442\n",
      "Epoch 4/50\n",
      "2498/2498 [==============================] - 2s 868us/step - loss: 0.6731 - accuracy: 0.7447 - val_loss: 0.6664 - val_accuracy: 0.7454\n",
      "Epoch 5/50\n",
      "2498/2498 [==============================] - 2s 892us/step - loss: 0.6616 - accuracy: 0.7453 - val_loss: 0.6576 - val_accuracy: 0.7442\n",
      "Epoch 6/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6545 - accuracy: 0.7456 - val_loss: 0.6518 - val_accuracy: 0.7456\n",
      "Epoch 7/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6494 - accuracy: 0.7460 - val_loss: 0.6473 - val_accuracy: 0.7451\n",
      "Epoch 8/50\n",
      "2498/2498 [==============================] - 2s 925us/step - loss: 0.6456 - accuracy: 0.7461 - val_loss: 0.6448 - val_accuracy: 0.7471\n",
      "Epoch 9/50\n",
      "2498/2498 [==============================] - 2s 1ms/step - loss: 0.6425 - accuracy: 0.7464 - val_loss: 0.6423 - val_accuracy: 0.7479\n",
      "Epoch 10/50\n",
      "2498/2498 [==============================] - 2s 900us/step - loss: 0.6399 - accuracy: 0.7466 - val_loss: 0.6387 - val_accuracy: 0.7457\n",
      "Epoch 11/50\n",
      "2498/2498 [==============================] - 2s 825us/step - loss: 0.6376 - accuracy: 0.7470 - val_loss: 0.6368 - val_accuracy: 0.7475\n",
      "Epoch 12/50\n",
      "2498/2498 [==============================] - 2s 991us/step - loss: 0.6356 - accuracy: 0.7471 - val_loss: 0.6347 - val_accuracy: 0.7471\n",
      "Epoch 13/50\n",
      "2498/2498 [==============================] - 2s 792us/step - loss: 0.6338 - accuracy: 0.7472 - val_loss: 0.6330 - val_accuracy: 0.7468\n",
      "Epoch 14/50\n",
      "2498/2498 [==============================] - 2s 948us/step - loss: 0.6322 - accuracy: 0.7474 - val_loss: 0.6316 - val_accuracy: 0.7459\n",
      "Epoch 15/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6306 - accuracy: 0.7476 - val_loss: 0.6301 - val_accuracy: 0.7458\n",
      "Epoch 16/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6293 - accuracy: 0.7475 - val_loss: 0.6286 - val_accuracy: 0.7463\n",
      "Epoch 17/50\n",
      "2498/2498 [==============================] - 2s 977us/step - loss: 0.6280 - accuracy: 0.7478 - val_loss: 0.6275 - val_accuracy: 0.7475\n",
      "Epoch 18/50\n",
      "2498/2498 [==============================] - 2s 729us/step - loss: 0.6268 - accuracy: 0.7478 - val_loss: 0.6265 - val_accuracy: 0.7461\n",
      "Epoch 19/50\n",
      "2498/2498 [==============================] - 2s 700us/step - loss: 0.6257 - accuracy: 0.7479 - val_loss: 0.6253 - val_accuracy: 0.7468\n",
      "Epoch 20/50\n",
      "2498/2498 [==============================] - 2s 637us/step - loss: 0.6247 - accuracy: 0.7481 - val_loss: 0.6246 - val_accuracy: 0.7478\n",
      "Epoch 21/50\n",
      "2498/2498 [==============================] - 2s 705us/step - loss: 0.6237 - accuracy: 0.7480 - val_loss: 0.6235 - val_accuracy: 0.7484\n",
      "Epoch 22/50\n",
      "2498/2498 [==============================] - 2s 658us/step - loss: 0.6228 - accuracy: 0.7485 - val_loss: 0.6236 - val_accuracy: 0.7492\n",
      "Epoch 23/50\n",
      "2498/2498 [==============================] - 2s 623us/step - loss: 0.6219 - accuracy: 0.7480 - val_loss: 0.6219 - val_accuracy: 0.7483\n",
      "Epoch 24/50\n",
      "2498/2498 [==============================] - 2s 674us/step - loss: 0.6212 - accuracy: 0.7484 - val_loss: 0.6221 - val_accuracy: 0.7495\n",
      "Epoch 25/50\n",
      "2498/2498 [==============================] - 2s 801us/step - loss: 0.6204 - accuracy: 0.7483 - val_loss: 0.6207 - val_accuracy: 0.7461\n",
      "Epoch 26/50\n",
      "2498/2498 [==============================] - 2s 733us/step - loss: 0.6197 - accuracy: 0.7486 - val_loss: 0.6215 - val_accuracy: 0.7498\n",
      "Epoch 27/50\n",
      "2498/2498 [==============================] - 2s 752us/step - loss: 0.6190 - accuracy: 0.7486 - val_loss: 0.6202 - val_accuracy: 0.7499\n",
      "Epoch 28/50\n",
      "2498/2498 [==============================] - 2s 733us/step - loss: 0.6183 - accuracy: 0.7486 - val_loss: 0.6185 - val_accuracy: 0.7489\n",
      "Epoch 29/50\n",
      "2498/2498 [==============================] - 2s 787us/step - loss: 0.6177 - accuracy: 0.7486 - val_loss: 0.6183 - val_accuracy: 0.7460\n",
      "Epoch 30/50\n",
      "2498/2498 [==============================] - 2s 738us/step - loss: 0.6171 - accuracy: 0.7488 - val_loss: 0.6171 - val_accuracy: 0.7478\n",
      "Epoch 31/50\n",
      "2498/2498 [==============================] - 2s 961us/step - loss: 0.6165 - accuracy: 0.7489 - val_loss: 0.6170 - val_accuracy: 0.7495\n",
      "Epoch 32/50\n",
      "2498/2498 [==============================] - 2s 770us/step - loss: 0.6160 - accuracy: 0.7492 - val_loss: 0.6163 - val_accuracy: 0.7499\n",
      "Epoch 33/50\n",
      "2498/2498 [==============================] - 2s 692us/step - loss: 0.6155 - accuracy: 0.7487 - val_loss: 0.6158 - val_accuracy: 0.7461\n",
      "Epoch 34/50\n",
      "2498/2498 [==============================] - 2s 696us/step - loss: 0.6149 - accuracy: 0.7490 - val_loss: 0.6151 - val_accuracy: 0.7479\n",
      "Epoch 35/50\n",
      "2498/2498 [==============================] - 2s 681us/step - loss: 0.6145 - accuracy: 0.7492 - val_loss: 0.6162 - val_accuracy: 0.7449\n",
      "Epoch 36/50\n",
      "2498/2498 [==============================] - 2s 716us/step - loss: 0.6140 - accuracy: 0.7490 - val_loss: 0.6154 - val_accuracy: 0.7505\n",
      "Epoch 37/50\n",
      "2498/2498 [==============================] - 2s 721us/step - loss: 0.6136 - accuracy: 0.7491 - val_loss: 0.6141 - val_accuracy: 0.7498\n",
      "Epoch 38/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6131 - accuracy: 0.7494 - val_loss: 0.6135 - val_accuracy: 0.7489\n",
      "Epoch 39/50\n",
      "2498/2498 [==============================] - 2s 944us/step - loss: 0.6127 - accuracy: 0.7490 - val_loss: 0.6137 - val_accuracy: 0.7468\n",
      "Epoch 40/50\n",
      "2498/2498 [==============================] - 2s 996us/step - loss: 0.6123 - accuracy: 0.7495 - val_loss: 0.6127 - val_accuracy: 0.7490\n",
      "Epoch 41/50\n",
      "2498/2498 [==============================] - 2s 837us/step - loss: 0.6119 - accuracy: 0.7493 - val_loss: 0.6126 - val_accuracy: 0.7496\n",
      "Epoch 42/50\n",
      "2498/2498 [==============================] - 2s 667us/step - loss: 0.6115 - accuracy: 0.7493 - val_loss: 0.6117 - val_accuracy: 0.7480\n",
      "Epoch 43/50\n",
      "2498/2498 [==============================] - 2s 672us/step - loss: 0.6112 - accuracy: 0.7493 - val_loss: 0.6110 - val_accuracy: 0.7487\n",
      "Epoch 44/50\n",
      "2498/2498 [==============================] - 2s 822us/step - loss: 0.6108 - accuracy: 0.7496 - val_loss: 0.6109 - val_accuracy: 0.7484\n",
      "Epoch 45/50\n",
      "2498/2498 [==============================] - 2s 681us/step - loss: 0.6105 - accuracy: 0.7493 - val_loss: 0.6115 - val_accuracy: 0.7501\n",
      "Epoch 46/50\n",
      "2498/2498 [==============================] - 2s 841us/step - loss: 0.6102 - accuracy: 0.7493 - val_loss: 0.6105 - val_accuracy: 0.7491\n",
      "Epoch 47/50\n",
      "2498/2498 [==============================] - 2s 734us/step - loss: 0.6098 - accuracy: 0.7495 - val_loss: 0.6100 - val_accuracy: 0.7477\n",
      "Epoch 48/50\n",
      "2498/2498 [==============================] - 2s 688us/step - loss: 0.6095 - accuracy: 0.7495 - val_loss: 0.6099 - val_accuracy: 0.7475\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 2s 674us/step - loss: 0.6092 - accuracy: 0.7495 - val_loss: 0.6096 - val_accuracy: 0.7484\n",
      "Epoch 50/50\n",
      "2498/2498 [==============================] - 2s 719us/step - loss: 0.6089 - accuracy: 0.7497 - val_loss: 0.6095 - val_accuracy: 0.7502\n",
      "4441/4441 [==============================] - 2s 418us/step - loss: 1.2575 - accuracy: 0.4533\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x0000019CAD688D30>\n",
      "Epoch Sizes:  50\n",
      "Neurons or Units:  64\n",
      "Test score: 1.2575186491012573\n",
      "Test accuracy: 0.45332029461860657\n",
      "\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2498/2498 [==============================] - 2s 778us/step - loss: 0.9650 - accuracy: 0.7078 - val_loss: 0.8031 - val_accuracy: 0.7377\n",
      "Epoch 2/50\n",
      "2498/2498 [==============================] - 2s 772us/step - loss: 0.7528 - accuracy: 0.7399 - val_loss: 0.7179 - val_accuracy: 0.7426\n",
      "Epoch 3/50\n",
      "2498/2498 [==============================] - 2s 943us/step - loss: 0.6986 - accuracy: 0.7429 - val_loss: 0.6842 - val_accuracy: 0.7446\n",
      "Epoch 4/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6748 - accuracy: 0.7442 - val_loss: 0.6676 - val_accuracy: 0.7453\n",
      "Epoch 5/50\n",
      "2498/2498 [==============================] - 2s 972us/step - loss: 0.6623 - accuracy: 0.7450 - val_loss: 0.6579 - val_accuracy: 0.7439\n",
      "Epoch 6/50\n",
      "2498/2498 [==============================] - 2s 904us/step - loss: 0.6547 - accuracy: 0.7455 - val_loss: 0.6520 - val_accuracy: 0.7462\n",
      "Epoch 7/50\n",
      "2498/2498 [==============================] - 2s 658us/step - loss: 0.6495 - accuracy: 0.7458 - val_loss: 0.6475 - val_accuracy: 0.7453\n",
      "Epoch 8/50\n",
      "2498/2498 [==============================] - 2s 648us/step - loss: 0.6456 - accuracy: 0.7461 - val_loss: 0.6444 - val_accuracy: 0.7469\n",
      "Epoch 9/50\n",
      "2498/2498 [==============================] - 2s 666us/step - loss: 0.6424 - accuracy: 0.7466 - val_loss: 0.6412 - val_accuracy: 0.7465\n",
      "Epoch 10/50\n",
      "2498/2498 [==============================] - 2s 691us/step - loss: 0.6398 - accuracy: 0.7467 - val_loss: 0.6391 - val_accuracy: 0.7481\n",
      "Epoch 11/50\n",
      "2498/2498 [==============================] - 2s 750us/step - loss: 0.6375 - accuracy: 0.7469 - val_loss: 0.6366 - val_accuracy: 0.7475\n",
      "Epoch 12/50\n",
      "2498/2498 [==============================] - 2s 730us/step - loss: 0.6355 - accuracy: 0.7469 - val_loss: 0.6349 - val_accuracy: 0.7482\n",
      "Epoch 13/50\n",
      "2498/2498 [==============================] - 2s 679us/step - loss: 0.6336 - accuracy: 0.7473 - val_loss: 0.6331 - val_accuracy: 0.7477\n",
      "Epoch 14/50\n",
      "2498/2498 [==============================] - 2s 684us/step - loss: 0.6320 - accuracy: 0.7476 - val_loss: 0.6317 - val_accuracy: 0.7486\n",
      "Epoch 15/50\n",
      "2498/2498 [==============================] - 2s 802us/step - loss: 0.6304 - accuracy: 0.7474 - val_loss: 0.6299 - val_accuracy: 0.7471\n",
      "Epoch 16/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6291 - accuracy: 0.7478 - val_loss: 0.6289 - val_accuracy: 0.7456\n",
      "Epoch 17/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6278 - accuracy: 0.7477 - val_loss: 0.6273 - val_accuracy: 0.7473\n",
      "Epoch 18/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6267 - accuracy: 0.7481 - val_loss: 0.6263 - val_accuracy: 0.7478\n",
      "Epoch 19/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6256 - accuracy: 0.7479 - val_loss: 0.6253 - val_accuracy: 0.7466\n",
      "Epoch 20/50\n",
      "2498/2498 [==============================] - 2s 821us/step - loss: 0.6246 - accuracy: 0.7482 - val_loss: 0.6245 - val_accuracy: 0.7490\n",
      "Epoch 21/50\n",
      "2498/2498 [==============================] - 2s 694us/step - loss: 0.6237 - accuracy: 0.7480 - val_loss: 0.6235 - val_accuracy: 0.7476\n",
      "Epoch 22/50\n",
      "2498/2498 [==============================] - 2s 642us/step - loss: 0.6227 - accuracy: 0.7481 - val_loss: 0.6225 - val_accuracy: 0.7476\n",
      "Epoch 23/50\n",
      "2498/2498 [==============================] - 2s 833us/step - loss: 0.6219 - accuracy: 0.7485 - val_loss: 0.6219 - val_accuracy: 0.7471\n",
      "Epoch 24/50\n",
      "2498/2498 [==============================] - 2s 807us/step - loss: 0.6211 - accuracy: 0.7484 - val_loss: 0.6207 - val_accuracy: 0.7484\n",
      "Epoch 25/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6204 - accuracy: 0.7486 - val_loss: 0.6208 - val_accuracy: 0.7459\n",
      "Epoch 26/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6196 - accuracy: 0.7486 - val_loss: 0.6195 - val_accuracy: 0.7476\n",
      "Epoch 27/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6189 - accuracy: 0.7487 - val_loss: 0.6189 - val_accuracy: 0.7489\n",
      "Epoch 28/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6183 - accuracy: 0.7486 - val_loss: 0.6183 - val_accuracy: 0.7473\n",
      "Epoch 29/50\n",
      "2498/2498 [==============================] - 2s 884us/step - loss: 0.6177 - accuracy: 0.7486 - val_loss: 0.6176 - val_accuracy: 0.7476\n",
      "Epoch 30/50\n",
      "2498/2498 [==============================] - 2s 952us/step - loss: 0.6170 - accuracy: 0.7492 - val_loss: 0.6176 - val_accuracy: 0.7495\n",
      "Epoch 31/50\n",
      "2498/2498 [==============================] - 2s 834us/step - loss: 0.6165 - accuracy: 0.7489 - val_loss: 0.6166 - val_accuracy: 0.7479\n",
      "Epoch 32/50\n",
      "2498/2498 [==============================] - 2s 946us/step - loss: 0.6160 - accuracy: 0.7490 - val_loss: 0.6158 - val_accuracy: 0.7485\n",
      "Epoch 33/50\n",
      "2498/2498 [==============================] - 2s 974us/step - loss: 0.6154 - accuracy: 0.7490 - val_loss: 0.6157 - val_accuracy: 0.7475\n",
      "Epoch 34/50\n",
      "2498/2498 [==============================] - 2s 708us/step - loss: 0.6149 - accuracy: 0.7490 - val_loss: 0.6149 - val_accuracy: 0.7484\n",
      "Epoch 35/50\n",
      "2498/2498 [==============================] - 2s 723us/step - loss: 0.6144 - accuracy: 0.7489 - val_loss: 0.6149 - val_accuracy: 0.7485\n",
      "Epoch 36/50\n",
      "2498/2498 [==============================] - 2s 665us/step - loss: 0.6140 - accuracy: 0.7490 - val_loss: 0.6141 - val_accuracy: 0.7485\n",
      "Epoch 37/50\n",
      "2498/2498 [==============================] - 2s 825us/step - loss: 0.6135 - accuracy: 0.7492 - val_loss: 0.6135 - val_accuracy: 0.7495\n",
      "Epoch 38/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6131 - accuracy: 0.7494 - val_loss: 0.6135 - val_accuracy: 0.7482\n",
      "Epoch 39/50\n",
      "2498/2498 [==============================] - 2s 925us/step - loss: 0.6127 - accuracy: 0.7493 - val_loss: 0.6129 - val_accuracy: 0.7496\n",
      "Epoch 40/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6123 - accuracy: 0.7494 - val_loss: 0.6122 - val_accuracy: 0.7485\n",
      "Epoch 41/50\n",
      "2498/2498 [==============================] - 2s 842us/step - loss: 0.6118 - accuracy: 0.7494 - val_loss: 0.6124 - val_accuracy: 0.7501\n",
      "Epoch 42/50\n",
      "2498/2498 [==============================] - 2s 827us/step - loss: 0.6114 - accuracy: 0.7493 - val_loss: 0.6129 - val_accuracy: 0.7504\n",
      "Epoch 43/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6111 - accuracy: 0.7494 - val_loss: 0.6113 - val_accuracy: 0.7477\n",
      "Epoch 44/50\n",
      "2498/2498 [==============================] - 2s 764us/step - loss: 0.6107 - accuracy: 0.7492 - val_loss: 0.6112 - val_accuracy: 0.7493\n",
      "Epoch 45/50\n",
      "2498/2498 [==============================] - 2s 937us/step - loss: 0.6105 - accuracy: 0.7496 - val_loss: 0.6110 - val_accuracy: 0.7468\n",
      "Epoch 46/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6101 - accuracy: 0.7495 - val_loss: 0.6105 - val_accuracy: 0.7494\n",
      "Epoch 47/50\n",
      "2498/2498 [==============================] - 2s 692us/step - loss: 0.6098 - accuracy: 0.7494 - val_loss: 0.6111 - val_accuracy: 0.7498\n",
      "Epoch 48/50\n",
      "2498/2498 [==============================] - 2s 868us/step - loss: 0.6094 - accuracy: 0.7497 - val_loss: 0.6095 - val_accuracy: 0.7489\n",
      "Epoch 49/50\n",
      "2498/2498 [==============================] - 2s 966us/step - loss: 0.6091 - accuracy: 0.7494 - val_loss: 0.6091 - val_accuracy: 0.7492\n",
      "Epoch 50/50\n",
      "2498/2498 [==============================] - 2s 938us/step - loss: 0.6089 - accuracy: 0.7497 - val_loss: 0.6096 - val_accuracy: 0.7469\n",
      "4441/4441 [==============================] - 2s 393us/step - loss: 1.2606 - accuracy: 0.4575\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x0000019CAD688D30>\n",
      "Epoch Sizes:  50\n",
      "Neurons or Units:  128\n",
      "Test score: 1.2606074810028076\n",
      "Test accuracy: 0.45748648047447205\n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,667\n",
      "Trainable params: 4,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.9859 - accuracy: 0.7057 - val_loss: 0.8118 - val_accuracy: 0.7337\n",
      "Epoch 2/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.7577 - accuracy: 0.7392 - val_loss: 0.7203 - val_accuracy: 0.7416\n",
      "Epoch 3/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.7002 - accuracy: 0.7428 - val_loss: 0.6849 - val_accuracy: 0.7436\n",
      "Epoch 4/50\n",
      "2498/2498 [==============================] - 2s 982us/step - loss: 0.6755 - accuracy: 0.7437 - val_loss: 0.6682 - val_accuracy: 0.7457\n",
      "Epoch 5/50\n",
      "2498/2498 [==============================] - 2s 977us/step - loss: 0.6627 - accuracy: 0.7447 - val_loss: 0.6583 - val_accuracy: 0.7440\n",
      "Epoch 6/50\n",
      "2498/2498 [==============================] - 2s 829us/step - loss: 0.6550 - accuracy: 0.7450 - val_loss: 0.6522 - val_accuracy: 0.7452\n",
      "Epoch 7/50\n",
      "2498/2498 [==============================] - 2s 875us/step - loss: 0.6498 - accuracy: 0.7455 - val_loss: 0.6475 - val_accuracy: 0.7459\n",
      "Epoch 8/50\n",
      "2498/2498 [==============================] - 2s 919us/step - loss: 0.6458 - accuracy: 0.7460 - val_loss: 0.6440 - val_accuracy: 0.7457\n",
      "Epoch 9/50\n",
      "2498/2498 [==============================] - 2s 951us/step - loss: 0.6426 - accuracy: 0.7462 - val_loss: 0.6413 - val_accuracy: 0.7461\n",
      "Epoch 10/50\n",
      "2498/2498 [==============================] - 2s 910us/step - loss: 0.6400 - accuracy: 0.7465 - val_loss: 0.6389 - val_accuracy: 0.7471\n",
      "Epoch 11/50\n",
      "2498/2498 [==============================] - 2s 891us/step - loss: 0.6376 - accuracy: 0.7465 - val_loss: 0.6370 - val_accuracy: 0.7475\n",
      "Epoch 12/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6356 - accuracy: 0.7467 - val_loss: 0.6364 - val_accuracy: 0.7489\n",
      "Epoch 13/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6338 - accuracy: 0.7468 - val_loss: 0.6329 - val_accuracy: 0.7461\n",
      "Epoch 14/50\n",
      "2498/2498 [==============================] - 2s 822us/step - loss: 0.6321 - accuracy: 0.7471 - val_loss: 0.6314 - val_accuracy: 0.7468\n",
      "Epoch 15/50\n",
      "2498/2498 [==============================] - 2s 766us/step - loss: 0.6306 - accuracy: 0.7472 - val_loss: 0.6299 - val_accuracy: 0.7467\n",
      "Epoch 16/50\n",
      "2498/2498 [==============================] - 2s 897us/step - loss: 0.6293 - accuracy: 0.7472 - val_loss: 0.6289 - val_accuracy: 0.7454\n",
      "Epoch 17/50\n",
      "2498/2498 [==============================] - 2s 906us/step - loss: 0.6280 - accuracy: 0.7477 - val_loss: 0.6276 - val_accuracy: 0.7480\n",
      "Epoch 18/50\n",
      "2498/2498 [==============================] - 2s 977us/step - loss: 0.6268 - accuracy: 0.7474 - val_loss: 0.6263 - val_accuracy: 0.7460\n",
      "Epoch 19/50\n",
      "2498/2498 [==============================] - 2s 951us/step - loss: 0.6257 - accuracy: 0.7477 - val_loss: 0.6252 - val_accuracy: 0.7469\n",
      "Epoch 20/50\n",
      "2498/2498 [==============================] - 2s 920us/step - loss: 0.6247 - accuracy: 0.7479 - val_loss: 0.6241 - val_accuracy: 0.7471\n",
      "Epoch 21/50\n",
      "2498/2498 [==============================] - 2s 996us/step - loss: 0.6237 - accuracy: 0.7479 - val_loss: 0.6235 - val_accuracy: 0.7482\n",
      "Epoch 22/50\n",
      "2498/2498 [==============================] - 2s 909us/step - loss: 0.6228 - accuracy: 0.7480 - val_loss: 0.6239 - val_accuracy: 0.7497\n",
      "Epoch 23/50\n",
      "2498/2498 [==============================] - 2s 926us/step - loss: 0.6220 - accuracy: 0.7479 - val_loss: 0.6216 - val_accuracy: 0.7480\n",
      "Epoch 24/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6212 - accuracy: 0.7480 - val_loss: 0.6214 - val_accuracy: 0.7490\n",
      "Epoch 25/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6205 - accuracy: 0.7480 - val_loss: 0.6203 - val_accuracy: 0.7466\n",
      "Epoch 26/50\n",
      "2498/2498 [==============================] - 2s 765us/step - loss: 0.6197 - accuracy: 0.7483 - val_loss: 0.6197 - val_accuracy: 0.7480\n",
      "Epoch 27/50\n",
      "2498/2498 [==============================] - 2s 782us/step - loss: 0.6190 - accuracy: 0.7480 - val_loss: 0.6190 - val_accuracy: 0.7483\n",
      "Epoch 28/50\n",
      "2498/2498 [==============================] - 2s 951us/step - loss: 0.6184 - accuracy: 0.7481 - val_loss: 0.6185 - val_accuracy: 0.7493\n",
      "Epoch 29/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6177 - accuracy: 0.7483 - val_loss: 0.6176 - val_accuracy: 0.7472\n",
      "Epoch 30/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6171 - accuracy: 0.7486 - val_loss: 0.6169 - val_accuracy: 0.7479\n",
      "Epoch 31/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6165 - accuracy: 0.7487 - val_loss: 0.6165 - val_accuracy: 0.7488\n",
      "Epoch 32/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6159 - accuracy: 0.7488 - val_loss: 0.6157 - val_accuracy: 0.7486\n",
      "Epoch 33/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6154 - accuracy: 0.7491 - val_loss: 0.6160 - val_accuracy: 0.7502\n",
      "Epoch 34/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6149 - accuracy: 0.7488 - val_loss: 0.6156 - val_accuracy: 0.7467\n",
      "Epoch 35/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6144 - accuracy: 0.7488 - val_loss: 0.6149 - val_accuracy: 0.7468\n",
      "Epoch 36/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6139 - accuracy: 0.7490 - val_loss: 0.6138 - val_accuracy: 0.7483\n",
      "Epoch 37/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6134 - accuracy: 0.7491 - val_loss: 0.6137 - val_accuracy: 0.7493\n",
      "Epoch 38/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6130 - accuracy: 0.7491 - val_loss: 0.6135 - val_accuracy: 0.7471\n",
      "Epoch 39/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6126 - accuracy: 0.7492 - val_loss: 0.6125 - val_accuracy: 0.7486\n",
      "Epoch 40/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6122 - accuracy: 0.7493 - val_loss: 0.6120 - val_accuracy: 0.7492\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6117 - accuracy: 0.7495 - val_loss: 0.6118 - val_accuracy: 0.7488\n",
      "Epoch 42/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6114 - accuracy: 0.7494 - val_loss: 0.6119 - val_accuracy: 0.7467\n",
      "Epoch 43/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6110 - accuracy: 0.7492 - val_loss: 0.6112 - val_accuracy: 0.7493\n",
      "Epoch 44/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6107 - accuracy: 0.7494 - val_loss: 0.6117 - val_accuracy: 0.7506\n",
      "Epoch 45/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6103 - accuracy: 0.7493 - val_loss: 0.6113 - val_accuracy: 0.7497\n",
      "Epoch 46/50\n",
      "2498/2498 [==============================] - 2s 910us/step - loss: 0.6099 - accuracy: 0.7496 - val_loss: 0.6099 - val_accuracy: 0.7496\n",
      "Epoch 47/50\n",
      "2498/2498 [==============================] - 2s 926us/step - loss: 0.6096 - accuracy: 0.7495 - val_loss: 0.6106 - val_accuracy: 0.7496\n",
      "Epoch 48/50\n",
      "2498/2498 [==============================] - 2s 951us/step - loss: 0.6093 - accuracy: 0.7493 - val_loss: 0.6093 - val_accuracy: 0.7489\n",
      "Epoch 49/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6089 - accuracy: 0.7497 - val_loss: 0.6104 - val_accuracy: 0.7507\n",
      "Epoch 50/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6086 - accuracy: 0.7497 - val_loss: 0.6092 - val_accuracy: 0.7496\n",
      "4441/4441 [==============================] - 2s 495us/step - loss: 1.2742 - accuracy: 0.4546\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x0000019CAD688D30>\n",
      "Epoch Sizes:  50\n",
      "Neurons or Units:  256\n",
      "Test score: 1.2742340564727783\n",
      "Test accuracy: 0.4546433389186859\n",
      "\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,211\n",
      "Trainable params: 1,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2498/2498 [==============================] - 2s 741us/step - loss: 0.9680 - accuracy: 0.6982 - val_loss: 0.8064 - val_accuracy: 0.7292\n",
      "Epoch 2/100\n",
      "2498/2498 [==============================] - 2s 661us/step - loss: 0.7560 - accuracy: 0.7360 - val_loss: 0.7209 - val_accuracy: 0.7386\n",
      "Epoch 3/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.7013 - accuracy: 0.7414 - val_loss: 0.6864 - val_accuracy: 0.7413\n",
      "Epoch 4/100\n",
      "2498/2498 [==============================] - 2s 699us/step - loss: 0.6769 - accuracy: 0.7432 - val_loss: 0.6692 - val_accuracy: 0.7423\n",
      "Epoch 5/100\n",
      "2498/2498 [==============================] - 2s 615us/step - loss: 0.6638 - accuracy: 0.7446 - val_loss: 0.6593 - val_accuracy: 0.7451\n",
      "Epoch 6/100\n",
      "2498/2498 [==============================] - 2s 650us/step - loss: 0.6558 - accuracy: 0.7454 - val_loss: 0.6530 - val_accuracy: 0.7436\n",
      "Epoch 7/100\n",
      "2498/2498 [==============================] - 2s 765us/step - loss: 0.6504 - accuracy: 0.7458 - val_loss: 0.6482 - val_accuracy: 0.7449\n",
      "Epoch 8/100\n",
      "2498/2498 [==============================] - 2s 886us/step - loss: 0.6462 - accuracy: 0.7464 - val_loss: 0.6446 - val_accuracy: 0.7463\n",
      "Epoch 9/100\n",
      "2498/2498 [==============================] - 2s 896us/step - loss: 0.6428 - accuracy: 0.7467 - val_loss: 0.6418 - val_accuracy: 0.7458\n",
      "Epoch 10/100\n",
      "2498/2498 [==============================] - 2s 957us/step - loss: 0.6401 - accuracy: 0.7468 - val_loss: 0.6388 - val_accuracy: 0.7462\n",
      "Epoch 11/100\n",
      "2498/2498 [==============================] - 2s 751us/step - loss: 0.6377 - accuracy: 0.7469 - val_loss: 0.6375 - val_accuracy: 0.7441\n",
      "Epoch 12/100\n",
      "2498/2498 [==============================] - 2s 818us/step - loss: 0.6356 - accuracy: 0.7471 - val_loss: 0.6350 - val_accuracy: 0.7460\n",
      "Epoch 13/100\n",
      "2498/2498 [==============================] - 2s 787us/step - loss: 0.6338 - accuracy: 0.7474 - val_loss: 0.6331 - val_accuracy: 0.7481\n",
      "Epoch 14/100\n",
      "2498/2498 [==============================] - 2s 856us/step - loss: 0.6321 - accuracy: 0.7476 - val_loss: 0.6319 - val_accuracy: 0.7489\n",
      "Epoch 15/100\n",
      "2498/2498 [==============================] - 2s 869us/step - loss: 0.6305 - accuracy: 0.7474 - val_loss: 0.6303 - val_accuracy: 0.7483\n",
      "Epoch 16/100\n",
      "2498/2498 [==============================] - 2s 694us/step - loss: 0.6291 - accuracy: 0.7479 - val_loss: 0.6292 - val_accuracy: 0.7487\n",
      "Epoch 17/100\n",
      "2498/2498 [==============================] - 2s 902us/step - loss: 0.6278 - accuracy: 0.7478 - val_loss: 0.6274 - val_accuracy: 0.7480\n",
      "Epoch 18/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6267 - accuracy: 0.7477 - val_loss: 0.6262 - val_accuracy: 0.7476\n",
      "Epoch 19/100\n",
      "2498/2498 [==============================] - 2s 655us/step - loss: 0.6256 - accuracy: 0.7481 - val_loss: 0.6255 - val_accuracy: 0.7491\n",
      "Epoch 20/100\n",
      "2498/2498 [==============================] - 2s 605us/step - loss: 0.6245 - accuracy: 0.7481 - val_loss: 0.6241 - val_accuracy: 0.7483\n",
      "Epoch 21/100\n",
      "2498/2498 [==============================] - 2s 658us/step - loss: 0.6236 - accuracy: 0.7481 - val_loss: 0.6232 - val_accuracy: 0.7484\n",
      "Epoch 22/100\n",
      "2498/2498 [==============================] - 2s 739us/step - loss: 0.6226 - accuracy: 0.7483 - val_loss: 0.6226 - val_accuracy: 0.7488\n",
      "Epoch 23/100\n",
      "2498/2498 [==============================] - 2s 836us/step - loss: 0.6218 - accuracy: 0.7482 - val_loss: 0.6221 - val_accuracy: 0.7488\n",
      "Epoch 24/100\n",
      "2498/2498 [==============================] - 2s 907us/step - loss: 0.6209 - accuracy: 0.7484 - val_loss: 0.6209 - val_accuracy: 0.7490\n",
      "Epoch 25/100\n",
      "2498/2498 [==============================] - 2s 935us/step - loss: 0.6201 - accuracy: 0.7485 - val_loss: 0.6198 - val_accuracy: 0.7484\n",
      "Epoch 26/100\n",
      "2498/2498 [==============================] - 2s 856us/step - loss: 0.6194 - accuracy: 0.7487 - val_loss: 0.6193 - val_accuracy: 0.7489\n",
      "Epoch 27/100\n",
      "2498/2498 [==============================] - 2s 800us/step - loss: 0.6187 - accuracy: 0.7489 - val_loss: 0.6194 - val_accuracy: 0.7504\n",
      "Epoch 28/100\n",
      "2498/2498 [==============================] - 2s 765us/step - loss: 0.6180 - accuracy: 0.7489 - val_loss: 0.6181 - val_accuracy: 0.7495\n",
      "Epoch 29/100\n",
      "2498/2498 [==============================] - 2s 982us/step - loss: 0.6173 - accuracy: 0.7486 - val_loss: 0.6173 - val_accuracy: 0.7488\n",
      "Epoch 30/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6167 - accuracy: 0.7489 - val_loss: 0.6167 - val_accuracy: 0.7471\n",
      "Epoch 31/100\n",
      "2498/2498 [==============================] - 2s 658us/step - loss: 0.6161 - accuracy: 0.7490 - val_loss: 0.6160 - val_accuracy: 0.7484\n",
      "Epoch 32/100\n",
      "2498/2498 [==============================] - 2s 716us/step - loss: 0.6156 - accuracy: 0.7492 - val_loss: 0.6170 - val_accuracy: 0.7451\n",
      "Epoch 33/100\n",
      "2498/2498 [==============================] - 2s 669us/step - loss: 0.6150 - accuracy: 0.7488 - val_loss: 0.6151 - val_accuracy: 0.7492\n",
      "Epoch 34/100\n",
      "2498/2498 [==============================] - 2s 810us/step - loss: 0.6146 - accuracy: 0.7494 - val_loss: 0.6146 - val_accuracy: 0.7493\n",
      "Epoch 35/100\n",
      "2498/2498 [==============================] - 2s 715us/step - loss: 0.6140 - accuracy: 0.7489 - val_loss: 0.6141 - val_accuracy: 0.7486\n",
      "Epoch 36/100\n",
      "2498/2498 [==============================] - 2s 649us/step - loss: 0.6136 - accuracy: 0.7490 - val_loss: 0.6134 - val_accuracy: 0.7483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "2498/2498 [==============================] - 2s 778us/step - loss: 0.6131 - accuracy: 0.7489 - val_loss: 0.6136 - val_accuracy: 0.7499\n",
      "Epoch 38/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6127 - accuracy: 0.7493 - val_loss: 0.6144 - val_accuracy: 0.7455\n",
      "Epoch 39/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6122 - accuracy: 0.7492 - val_loss: 0.6131 - val_accuracy: 0.7468\n",
      "Epoch 40/100\n",
      "2498/2498 [==============================] - 2s 625us/step - loss: 0.6119 - accuracy: 0.7495 - val_loss: 0.6121 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "2498/2498 [==============================] - 2s 627us/step - loss: 0.6114 - accuracy: 0.7494 - val_loss: 0.6115 - val_accuracy: 0.7494\n",
      "Epoch 42/100\n",
      "2498/2498 [==============================] - 2s 621us/step - loss: 0.6110 - accuracy: 0.7493 - val_loss: 0.6112 - val_accuracy: 0.7491\n",
      "Epoch 43/100\n",
      "2498/2498 [==============================] - 2s 601us/step - loss: 0.6107 - accuracy: 0.7494 - val_loss: 0.6110 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "2498/2498 [==============================] - 2s 814us/step - loss: 0.6103 - accuracy: 0.7496 - val_loss: 0.6114 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "2498/2498 [==============================] - 2s 620us/step - loss: 0.6099 - accuracy: 0.7493 - val_loss: 0.6099 - val_accuracy: 0.7497\n",
      "Epoch 46/100\n",
      "2498/2498 [==============================] - 2s 700us/step - loss: 0.6096 - accuracy: 0.7495 - val_loss: 0.6104 - val_accuracy: 0.7479\n",
      "Epoch 47/100\n",
      "2498/2498 [==============================] - 2s 771us/step - loss: 0.6092 - accuracy: 0.7497 - val_loss: 0.6095 - val_accuracy: 0.7496\n",
      "Epoch 48/100\n",
      "2498/2498 [==============================] - 2s 702us/step - loss: 0.6089 - accuracy: 0.7493 - val_loss: 0.6088 - val_accuracy: 0.7491\n",
      "Epoch 49/100\n",
      "2498/2498 [==============================] - 2s 955us/step - loss: 0.6086 - accuracy: 0.7497 - val_loss: 0.6091 - val_accuracy: 0.7502\n",
      "Epoch 50/100\n",
      "2498/2498 [==============================] - 2s 941us/step - loss: 0.6083 - accuracy: 0.7499 - val_loss: 0.6087 - val_accuracy: 0.7487\n",
      "Epoch 51/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6080 - accuracy: 0.7498 - val_loss: 0.6084 - val_accuracy: 0.7497\n",
      "Epoch 52/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6077 - accuracy: 0.7499 - val_loss: 0.6076 - val_accuracy: 0.7492\n",
      "Epoch 53/100\n",
      "2498/2498 [==============================] - 2s 824us/step - loss: 0.6074 - accuracy: 0.7498 - val_loss: 0.6075 - val_accuracy: 0.7499\n",
      "Epoch 54/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6071 - accuracy: 0.7496 - val_loss: 0.6085 - val_accuracy: 0.7467\n",
      "Epoch 55/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6068 - accuracy: 0.7497 - val_loss: 0.6067 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6066 - accuracy: 0.7499 - val_loss: 0.6075 - val_accuracy: 0.7510\n",
      "Epoch 57/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6063 - accuracy: 0.7499 - val_loss: 0.6064 - val_accuracy: 0.7496\n",
      "Epoch 58/100\n",
      "2498/2498 [==============================] - 2s 800us/step - loss: 0.6061 - accuracy: 0.7502 - val_loss: 0.6060 - val_accuracy: 0.7504\n",
      "Epoch 59/100\n",
      "2498/2498 [==============================] - 2s 878us/step - loss: 0.6058 - accuracy: 0.7499 - val_loss: 0.6058 - val_accuracy: 0.7492\n",
      "Epoch 60/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6055 - accuracy: 0.7497 - val_loss: 0.6054 - val_accuracy: 0.7496\n",
      "Epoch 61/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6053 - accuracy: 0.7499 - val_loss: 0.6056 - val_accuracy: 0.7494\n",
      "Epoch 62/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6050 - accuracy: 0.7501 - val_loss: 0.6056 - val_accuracy: 0.7483\n",
      "Epoch 63/100\n",
      "2498/2498 [==============================] - 2s 841us/step - loss: 0.6048 - accuracy: 0.7502 - val_loss: 0.6058 - val_accuracy: 0.7476\n",
      "Epoch 64/100\n",
      "2498/2498 [==============================] - 2s 920us/step - loss: 0.6046 - accuracy: 0.7499 - val_loss: 0.6051 - val_accuracy: 0.7480\n",
      "Epoch 65/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6043 - accuracy: 0.7501 - val_loss: 0.6046 - val_accuracy: 0.7489\n",
      "Epoch 66/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6042 - accuracy: 0.7500 - val_loss: 0.6043 - val_accuracy: 0.7497\n",
      "Epoch 67/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6039 - accuracy: 0.7498 - val_loss: 0.6045 - val_accuracy: 0.7505\n",
      "Epoch 68/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6037 - accuracy: 0.7499 - val_loss: 0.6047 - val_accuracy: 0.7509\n",
      "Epoch 69/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6035 - accuracy: 0.7501 - val_loss: 0.6040 - val_accuracy: 0.7493\n",
      "Epoch 70/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6033 - accuracy: 0.7501 - val_loss: 0.6035 - val_accuracy: 0.7503\n",
      "Epoch 71/100\n",
      "2498/2498 [==============================] - 2s 833us/step - loss: 0.6031 - accuracy: 0.7501 - val_loss: 0.6031 - val_accuracy: 0.7499\n",
      "Epoch 72/100\n",
      "2498/2498 [==============================] - 2s 693us/step - loss: 0.6030 - accuracy: 0.7503 - val_loss: 0.6030 - val_accuracy: 0.7494\n",
      "Epoch 73/100\n",
      "2498/2498 [==============================] - 2s 847us/step - loss: 0.6027 - accuracy: 0.7503 - val_loss: 0.6028 - val_accuracy: 0.7504\n",
      "Epoch 74/100\n",
      "2498/2498 [==============================] - 2s 784us/step - loss: 0.6025 - accuracy: 0.7501 - val_loss: 0.6025 - val_accuracy: 0.7491\n",
      "Epoch 75/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6025 - accuracy: 0.7504 - val_loss: 0.6023 - val_accuracy: 0.7502\n",
      "Epoch 76/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6021 - accuracy: 0.7503 - val_loss: 0.6023 - val_accuracy: 0.7497\n",
      "Epoch 77/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6020 - accuracy: 0.7502 - val_loss: 0.6033 - val_accuracy: 0.7484\n",
      "Epoch 78/100\n",
      "2498/2498 [==============================] - 2s 891us/step - loss: 0.6018 - accuracy: 0.7503 - val_loss: 0.6035 - val_accuracy: 0.7476\n",
      "Epoch 79/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6017 - accuracy: 0.7504 - val_loss: 0.6020 - val_accuracy: 0.7505\n",
      "Epoch 80/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6015 - accuracy: 0.7506 - val_loss: 0.6018 - val_accuracy: 0.7509\n",
      "Epoch 81/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6013 - accuracy: 0.7503 - val_loss: 0.6015 - val_accuracy: 0.7501\n",
      "Epoch 82/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6011 - accuracy: 0.7504 - val_loss: 0.6039 - val_accuracy: 0.7461\n",
      "Epoch 83/100\n",
      "2498/2498 [==============================] - 2s 907us/step - loss: 0.6010 - accuracy: 0.7504 - val_loss: 0.6011 - val_accuracy: 0.7506\n",
      "Epoch 84/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6009 - accuracy: 0.7503 - val_loss: 0.6021 - val_accuracy: 0.7505\n",
      "Epoch 85/100\n",
      "2498/2498 [==============================] - 2s 759us/step - loss: 0.6007 - accuracy: 0.7506 - val_loss: 0.6012 - val_accuracy: 0.7485\n",
      "Epoch 86/100\n",
      "2498/2498 [==============================] - 2s 979us/step - loss: 0.6006 - accuracy: 0.7504 - val_loss: 0.6006 - val_accuracy: 0.7498\n",
      "Epoch 87/100\n",
      "2498/2498 [==============================] - 2s 848us/step - loss: 0.6003 - accuracy: 0.7507 - val_loss: 0.6006 - val_accuracy: 0.7499\n",
      "Epoch 88/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6002 - accuracy: 0.7505 - val_loss: 0.6033 - val_accuracy: 0.7504\n",
      "Epoch 89/100\n",
      "2498/2498 [==============================] - 2s 929us/step - loss: 0.6000 - accuracy: 0.7503 - val_loss: 0.6028 - val_accuracy: 0.7463\n",
      "Epoch 90/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6000 - accuracy: 0.7504 - val_loss: 0.5999 - val_accuracy: 0.7506\n",
      "Epoch 91/100\n",
      "2498/2498 [==============================] - 2s 867us/step - loss: 0.5998 - accuracy: 0.7505 - val_loss: 0.6000 - val_accuracy: 0.7511\n",
      "Epoch 92/100\n",
      "2498/2498 [==============================] - 2s 933us/step - loss: 0.5996 - accuracy: 0.7505 - val_loss: 0.6007 - val_accuracy: 0.7513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "2498/2498 [==============================] - 2s 805us/step - loss: 0.5995 - accuracy: 0.7502 - val_loss: 0.6005 - val_accuracy: 0.7507\n",
      "Epoch 94/100\n",
      "2498/2498 [==============================] - 2s 746us/step - loss: 0.5995 - accuracy: 0.7507 - val_loss: 0.5995 - val_accuracy: 0.7509\n",
      "Epoch 95/100\n",
      "2498/2498 [==============================] - 2s 761us/step - loss: 0.5993 - accuracy: 0.7504 - val_loss: 0.5997 - val_accuracy: 0.7507\n",
      "Epoch 96/100\n",
      "2498/2498 [==============================] - 2s 737us/step - loss: 0.5991 - accuracy: 0.7505 - val_loss: 0.5993 - val_accuracy: 0.7495\n",
      "Epoch 97/100\n",
      "2498/2498 [==============================] - 2s 780us/step - loss: 0.5989 - accuracy: 0.7506 - val_loss: 0.5994 - val_accuracy: 0.7513\n",
      "Epoch 98/100\n",
      "2498/2498 [==============================] - 2s 855us/step - loss: 0.5990 - accuracy: 0.7506 - val_loss: 0.5989 - val_accuracy: 0.7504\n",
      "Epoch 99/100\n",
      "2498/2498 [==============================] - 2s 767us/step - loss: 0.5987 - accuracy: 0.7502 - val_loss: 0.6004 - val_accuracy: 0.7517\n",
      "Epoch 100/100\n",
      "2498/2498 [==============================] - 2s 823us/step - loss: 0.5985 - accuracy: 0.7507 - val_loss: 0.6001 - val_accuracy: 0.7508\n",
      "4441/4441 [==============================] - 2s 485us/step - loss: 1.2677 - accuracy: 0.4510\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x0000019CAD688D30>\n",
      "Epoch Sizes:  100\n",
      "Neurons or Units:  64\n",
      "Test score: 1.2676982879638672\n",
      "Test accuracy: 0.4510471820831299\n",
      "\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2498/2498 [==============================] - 2s 929us/step - loss: 0.9633 - accuracy: 0.6981 - val_loss: 0.8011 - val_accuracy: 0.7365\n",
      "Epoch 2/100\n",
      "2498/2498 [==============================] - 2s 813us/step - loss: 0.7527 - accuracy: 0.7410 - val_loss: 0.7179 - val_accuracy: 0.7423\n",
      "Epoch 3/100\n",
      "2498/2498 [==============================] - 2s 956us/step - loss: 0.6987 - accuracy: 0.7436 - val_loss: 0.6838 - val_accuracy: 0.7441\n",
      "Epoch 4/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6746 - accuracy: 0.7447 - val_loss: 0.6672 - val_accuracy: 0.7441\n",
      "Epoch 5/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6620 - accuracy: 0.7453 - val_loss: 0.6578 - val_accuracy: 0.7455\n",
      "Epoch 6/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6544 - accuracy: 0.7458 - val_loss: 0.6515 - val_accuracy: 0.7447\n",
      "Epoch 7/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6492 - accuracy: 0.7462 - val_loss: 0.6471 - val_accuracy: 0.7460\n",
      "Epoch 8/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6453 - accuracy: 0.7463 - val_loss: 0.6435 - val_accuracy: 0.7454\n",
      "Epoch 9/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6421 - accuracy: 0.7467 - val_loss: 0.6407 - val_accuracy: 0.7457\n",
      "Epoch 10/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6394 - accuracy: 0.7472 - val_loss: 0.6388 - val_accuracy: 0.7442\n",
      "Epoch 11/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6371 - accuracy: 0.7473 - val_loss: 0.6362 - val_accuracy: 0.7474\n",
      "Epoch 12/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6350 - accuracy: 0.7473 - val_loss: 0.6341 - val_accuracy: 0.7474\n",
      "Epoch 13/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6332 - accuracy: 0.7473 - val_loss: 0.6325 - val_accuracy: 0.7480\n",
      "Epoch 14/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6314 - accuracy: 0.7479 - val_loss: 0.6309 - val_accuracy: 0.7479\n",
      "Epoch 15/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6299 - accuracy: 0.7477 - val_loss: 0.6296 - val_accuracy: 0.7483\n",
      "Epoch 16/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6285 - accuracy: 0.7477 - val_loss: 0.6281 - val_accuracy: 0.7467\n",
      "Epoch 17/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6273 - accuracy: 0.7480 - val_loss: 0.6269 - val_accuracy: 0.7465\n",
      "Epoch 18/100\n",
      "2498/2498 [==============================] - 2s 1ms/step - loss: 0.6261 - accuracy: 0.7478 - val_loss: 0.6258 - val_accuracy: 0.7481\n",
      "Epoch 19/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6250 - accuracy: 0.7482 - val_loss: 0.6256 - val_accuracy: 0.7451\n",
      "Epoch 20/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6240 - accuracy: 0.7483 - val_loss: 0.6236 - val_accuracy: 0.7480\n",
      "Epoch 21/100\n",
      "2498/2498 [==============================] - 2s 988us/step - loss: 0.6230 - accuracy: 0.7481 - val_loss: 0.6230 - val_accuracy: 0.7468\n",
      "Epoch 22/100\n",
      "2498/2498 [==============================] - 2s 1ms/step - loss: 0.6221 - accuracy: 0.7486 - val_loss: 0.6222 - val_accuracy: 0.7485\n",
      "Epoch 23/100\n",
      "2498/2498 [==============================] - 2s 933us/step - loss: 0.6212 - accuracy: 0.7485 - val_loss: 0.6213 - val_accuracy: 0.7467\n",
      "Epoch 24/100\n",
      "2498/2498 [==============================] - 2s 984us/step - loss: 0.6204 - accuracy: 0.7483 - val_loss: 0.6214 - val_accuracy: 0.7499\n",
      "Epoch 25/100\n",
      "2498/2498 [==============================] - 2s 932us/step - loss: 0.6197 - accuracy: 0.7488 - val_loss: 0.6194 - val_accuracy: 0.7483\n",
      "Epoch 26/100\n",
      "2498/2498 [==============================] - 2s 973us/step - loss: 0.6189 - accuracy: 0.7487 - val_loss: 0.6189 - val_accuracy: 0.7492\n",
      "Epoch 27/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6183 - accuracy: 0.7486 - val_loss: 0.6186 - val_accuracy: 0.7492\n",
      "Epoch 28/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6176 - accuracy: 0.7488 - val_loss: 0.6175 - val_accuracy: 0.7488\n",
      "Epoch 29/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6170 - accuracy: 0.7487 - val_loss: 0.6173 - val_accuracy: 0.7494\n",
      "Epoch 30/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6164 - accuracy: 0.7488 - val_loss: 0.6163 - val_accuracy: 0.7484\n",
      "Epoch 31/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6158 - accuracy: 0.7491 - val_loss: 0.6162 - val_accuracy: 0.7499\n",
      "Epoch 32/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6152 - accuracy: 0.7492 - val_loss: 0.6156 - val_accuracy: 0.7497\n",
      "Epoch 33/100\n",
      "2498/2498 [==============================] - 2s 888us/step - loss: 0.6147 - accuracy: 0.7493 - val_loss: 0.6148 - val_accuracy: 0.7494\n",
      "Epoch 34/100\n",
      "2498/2498 [==============================] - 2s 870us/step - loss: 0.6143 - accuracy: 0.7491 - val_loss: 0.6151 - val_accuracy: 0.7499\n",
      "Epoch 35/100\n",
      "2498/2498 [==============================] - 2s 908us/step - loss: 0.6137 - accuracy: 0.7492 - val_loss: 0.6140 - val_accuracy: 0.7472\n",
      "Epoch 36/100\n",
      "2498/2498 [==============================] - 2s 770us/step - loss: 0.6133 - accuracy: 0.7491 - val_loss: 0.6132 - val_accuracy: 0.7491\n",
      "Epoch 37/100\n",
      "2498/2498 [==============================] - 2s 716us/step - loss: 0.6128 - accuracy: 0.7496 - val_loss: 0.6126 - val_accuracy: 0.7489\n",
      "Epoch 38/100\n",
      "2498/2498 [==============================] - 2s 709us/step - loss: 0.6124 - accuracy: 0.7494 - val_loss: 0.6128 - val_accuracy: 0.7498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "2498/2498 [==============================] - 2s 788us/step - loss: 0.6119 - accuracy: 0.7495 - val_loss: 0.6122 - val_accuracy: 0.7482\n",
      "Epoch 40/100\n",
      "2498/2498 [==============================] - 2s 874us/step - loss: 0.6115 - accuracy: 0.7493 - val_loss: 0.6119 - val_accuracy: 0.7499\n",
      "Epoch 41/100\n",
      "2498/2498 [==============================] - 2s 910us/step - loss: 0.6111 - accuracy: 0.7496 - val_loss: 0.6112 - val_accuracy: 0.7479\n",
      "Epoch 42/100\n",
      "2498/2498 [==============================] - 2s 816us/step - loss: 0.6107 - accuracy: 0.7496 - val_loss: 0.6106 - val_accuracy: 0.7495\n",
      "Epoch 43/100\n",
      "2498/2498 [==============================] - 2s 795us/step - loss: 0.6103 - accuracy: 0.7498 - val_loss: 0.6105 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "2498/2498 [==============================] - 2s 705us/step - loss: 0.6099 - accuracy: 0.7497 - val_loss: 0.6097 - val_accuracy: 0.7487\n",
      "Epoch 45/100\n",
      "2498/2498 [==============================] - 2s 823us/step - loss: 0.6096 - accuracy: 0.7500 - val_loss: 0.6102 - val_accuracy: 0.7498\n",
      "Epoch 46/100\n",
      "2498/2498 [==============================] - 2s 915us/step - loss: 0.6092 - accuracy: 0.7498 - val_loss: 0.6094 - val_accuracy: 0.7481\n",
      "Epoch 47/100\n",
      "2498/2498 [==============================] - 2s 892us/step - loss: 0.6089 - accuracy: 0.7496 - val_loss: 0.6091 - val_accuracy: 0.7490\n",
      "Epoch 48/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6085 - accuracy: 0.7498 - val_loss: 0.6086 - val_accuracy: 0.7485\n",
      "Epoch 49/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6082 - accuracy: 0.7498 - val_loss: 0.6084 - val_accuracy: 0.7492\n",
      "Epoch 50/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6079 - accuracy: 0.7498 - val_loss: 0.6085 - val_accuracy: 0.7493\n",
      "Epoch 51/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6076 - accuracy: 0.7498 - val_loss: 0.6076 - val_accuracy: 0.7488\n",
      "Epoch 52/100\n",
      "2498/2498 [==============================] - 2s 920us/step - loss: 0.6073 - accuracy: 0.7500 - val_loss: 0.6072 - val_accuracy: 0.7493\n",
      "Epoch 53/100\n",
      "2498/2498 [==============================] - 2s 731us/step - loss: 0.6070 - accuracy: 0.7499 - val_loss: 0.6074 - val_accuracy: 0.7503\n",
      "Epoch 54/100\n",
      "2498/2498 [==============================] - 2s 965us/step - loss: 0.6067 - accuracy: 0.7497 - val_loss: 0.6100 - val_accuracy: 0.7451\n",
      "Epoch 55/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6064 - accuracy: 0.7500 - val_loss: 0.6075 - val_accuracy: 0.7511\n",
      "Epoch 56/100\n",
      "2498/2498 [==============================] - 2s 947us/step - loss: 0.6063 - accuracy: 0.7500 - val_loss: 0.6064 - val_accuracy: 0.7490\n",
      "Epoch 57/100\n",
      "2498/2498 [==============================] - 2s 799us/step - loss: 0.6059 - accuracy: 0.7501 - val_loss: 0.6070 - val_accuracy: 0.7474\n",
      "Epoch 58/100\n",
      "2498/2498 [==============================] - 2s 991us/step - loss: 0.6057 - accuracy: 0.7499 - val_loss: 0.6057 - val_accuracy: 0.7507\n",
      "Epoch 59/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6055 - accuracy: 0.7500 - val_loss: 0.6060 - val_accuracy: 0.7478\n",
      "Epoch 60/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6052 - accuracy: 0.7502 - val_loss: 0.6054 - val_accuracy: 0.7492\n",
      "Epoch 61/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6049 - accuracy: 0.7500 - val_loss: 0.6050 - val_accuracy: 0.7488\n",
      "Epoch 62/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6048 - accuracy: 0.7500 - val_loss: 0.6051 - val_accuracy: 0.7501\n",
      "Epoch 63/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6045 - accuracy: 0.7500 - val_loss: 0.6048 - val_accuracy: 0.7491\n",
      "Epoch 64/100\n",
      "2498/2498 [==============================] - 2s 955us/step - loss: 0.6043 - accuracy: 0.7501 - val_loss: 0.6045 - val_accuracy: 0.7483\n",
      "Epoch 65/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6041 - accuracy: 0.7502 - val_loss: 0.6042 - val_accuracy: 0.7499\n",
      "Epoch 66/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6038 - accuracy: 0.7502 - val_loss: 0.6044 - val_accuracy: 0.7507\n",
      "Epoch 67/100\n",
      "2498/2498 [==============================] - 2s 992us/step - loss: 0.6036 - accuracy: 0.7502 - val_loss: 0.6041 - val_accuracy: 0.7505\n",
      "Epoch 68/100\n",
      "2498/2498 [==============================] - 2s 913us/step - loss: 0.6034 - accuracy: 0.7501 - val_loss: 0.6049 - val_accuracy: 0.7509\n",
      "Epoch 69/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6032 - accuracy: 0.7506 - val_loss: 0.6043 - val_accuracy: 0.7477\n",
      "Epoch 70/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6030 - accuracy: 0.7506 - val_loss: 0.6032 - val_accuracy: 0.7501\n",
      "Epoch 71/100\n",
      "2498/2498 [==============================] - 2s 962us/step - loss: 0.6028 - accuracy: 0.7504 - val_loss: 0.6029 - val_accuracy: 0.7492\n",
      "Epoch 72/100\n",
      "2498/2498 [==============================] - 2s 977us/step - loss: 0.6027 - accuracy: 0.7503 - val_loss: 0.6026 - val_accuracy: 0.7499\n",
      "Epoch 73/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6024 - accuracy: 0.7503 - val_loss: 0.6029 - val_accuracy: 0.7507\n",
      "Epoch 74/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6023 - accuracy: 0.7504 - val_loss: 0.6022 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6020 - accuracy: 0.7503 - val_loss: 0.6022 - val_accuracy: 0.7499\n",
      "Epoch 76/100\n",
      "2498/2498 [==============================] - 2s 940us/step - loss: 0.6019 - accuracy: 0.7503 - val_loss: 0.6023 - val_accuracy: 0.7507\n",
      "Epoch 77/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6017 - accuracy: 0.7507 - val_loss: 0.6031 - val_accuracy: 0.7469\n",
      "Epoch 78/100\n",
      "2498/2498 [==============================] - 2s 979us/step - loss: 0.6015 - accuracy: 0.7507 - val_loss: 0.6020 - val_accuracy: 0.7505\n",
      "Epoch 79/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6014 - accuracy: 0.7505 - val_loss: 0.6029 - val_accuracy: 0.7510\n",
      "Epoch 80/100\n",
      "2498/2498 [==============================] - 2s 969us/step - loss: 0.6012 - accuracy: 0.7503 - val_loss: 0.6020 - val_accuracy: 0.7511\n",
      "Epoch 81/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6011 - accuracy: 0.7505 - val_loss: 0.6011 - val_accuracy: 0.7501\n",
      "Epoch 82/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6009 - accuracy: 0.7505 - val_loss: 0.6010 - val_accuracy: 0.7491\n",
      "Epoch 83/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6008 - accuracy: 0.7504 - val_loss: 0.6020 - val_accuracy: 0.7515\n",
      "Epoch 84/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6006 - accuracy: 0.7507 - val_loss: 0.6021 - val_accuracy: 0.7509\n",
      "Epoch 85/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6005 - accuracy: 0.7510 - val_loss: 0.6009 - val_accuracy: 0.7506\n",
      "Epoch 86/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6003 - accuracy: 0.7505 - val_loss: 0.6003 - val_accuracy: 0.7505\n",
      "Epoch 87/100\n",
      "2498/2498 [==============================] - 2s 982us/step - loss: 0.6002 - accuracy: 0.7501 - val_loss: 0.6020 - val_accuracy: 0.7511\n",
      "Epoch 88/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6000 - accuracy: 0.7507 - val_loss: 0.5999 - val_accuracy: 0.7493\n",
      "Epoch 89/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5999 - accuracy: 0.7505 - val_loss: 0.5997 - val_accuracy: 0.7498\n",
      "Epoch 90/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5997 - accuracy: 0.7504 - val_loss: 0.5999 - val_accuracy: 0.7506\n",
      "Epoch 91/100\n",
      "2498/2498 [==============================] - 2s 885us/step - loss: 0.5995 - accuracy: 0.7505 - val_loss: 0.6003 - val_accuracy: 0.7485\n",
      "Epoch 92/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5994 - accuracy: 0.7504 - val_loss: 0.6026 - val_accuracy: 0.7517\n",
      "Epoch 93/100\n",
      "2498/2498 [==============================] - 2s 799us/step - loss: 0.5992 - accuracy: 0.7506 - val_loss: 0.5995 - val_accuracy: 0.7488\n",
      "Epoch 94/100\n",
      "2498/2498 [==============================] - 2s 690us/step - loss: 0.5991 - accuracy: 0.7508 - val_loss: 0.5991 - val_accuracy: 0.7498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5989 - accuracy: 0.7506 - val_loss: 0.5992 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "2498/2498 [==============================] - 2s 918us/step - loss: 0.5989 - accuracy: 0.7511 - val_loss: 0.5992 - val_accuracy: 0.7491\n",
      "Epoch 97/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5988 - accuracy: 0.7506 - val_loss: 0.5991 - val_accuracy: 0.7509\n",
      "Epoch 98/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5987 - accuracy: 0.7507 - val_loss: 0.5988 - val_accuracy: 0.7502\n",
      "Epoch 99/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5985 - accuracy: 0.7509 - val_loss: 0.5987 - val_accuracy: 0.7498\n",
      "Epoch 100/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5984 - accuracy: 0.7507 - val_loss: 0.5995 - val_accuracy: 0.7512\n",
      "4441/4441 [==============================] - 3s 694us/step - loss: 1.2731 - accuracy: 0.4514\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x0000019CAD688D30>\n",
      "Epoch Sizes:  100\n",
      "Neurons or Units:  128\n",
      "Test score: 1.2731062173843384\n",
      "Test accuracy: 0.4514060914516449\n",
      "\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,667\n",
      "Trainable params: 4,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.9838 - accuracy: 0.7130 - val_loss: 0.8109 - val_accuracy: 0.7348\n",
      "Epoch 2/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.7572 - accuracy: 0.7396 - val_loss: 0.7198 - val_accuracy: 0.7418\n",
      "Epoch 3/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.7002 - accuracy: 0.7428 - val_loss: 0.6849 - val_accuracy: 0.7439\n",
      "Epoch 4/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6757 - accuracy: 0.7439 - val_loss: 0.6682 - val_accuracy: 0.7442\n",
      "Epoch 5/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6631 - accuracy: 0.7447 - val_loss: 0.6587 - val_accuracy: 0.7433\n",
      "Epoch 6/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6555 - accuracy: 0.7453 - val_loss: 0.6528 - val_accuracy: 0.7462\n",
      "Epoch 7/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6504 - accuracy: 0.7457 - val_loss: 0.6480 - val_accuracy: 0.7453\n",
      "Epoch 8/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6464 - accuracy: 0.7460 - val_loss: 0.6446 - val_accuracy: 0.7453\n",
      "Epoch 9/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6432 - accuracy: 0.7462 - val_loss: 0.6417 - val_accuracy: 0.7462\n",
      "Epoch 10/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6405 - accuracy: 0.7463 - val_loss: 0.6395 - val_accuracy: 0.7471\n",
      "Epoch 11/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6381 - accuracy: 0.7469 - val_loss: 0.6371 - val_accuracy: 0.7455\n",
      "Epoch 12/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6360 - accuracy: 0.7470 - val_loss: 0.6351 - val_accuracy: 0.7452\n",
      "Epoch 13/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6342 - accuracy: 0.7469 - val_loss: 0.6334 - val_accuracy: 0.7471\n",
      "Epoch 14/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6325 - accuracy: 0.7473 - val_loss: 0.6317 - val_accuracy: 0.7462\n",
      "Epoch 15/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6310 - accuracy: 0.7473 - val_loss: 0.6304 - val_accuracy: 0.7456\n",
      "Epoch 16/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6295 - accuracy: 0.7477 - val_loss: 0.6291 - val_accuracy: 0.7460\n",
      "Epoch 17/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6282 - accuracy: 0.7479 - val_loss: 0.6287 - val_accuracy: 0.7497\n",
      "Epoch 18/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6271 - accuracy: 0.7479 - val_loss: 0.6264 - val_accuracy: 0.7470\n",
      "Epoch 19/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6259 - accuracy: 0.7478 - val_loss: 0.6258 - val_accuracy: 0.7484\n",
      "Epoch 20/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6248 - accuracy: 0.7480 - val_loss: 0.6246 - val_accuracy: 0.7485\n",
      "Epoch 21/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6239 - accuracy: 0.7482 - val_loss: 0.6238 - val_accuracy: 0.7463\n",
      "Epoch 22/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6230 - accuracy: 0.7483 - val_loss: 0.6227 - val_accuracy: 0.7473\n",
      "Epoch 23/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6222 - accuracy: 0.7481 - val_loss: 0.6217 - val_accuracy: 0.7474\n",
      "Epoch 24/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6213 - accuracy: 0.7485 - val_loss: 0.6214 - val_accuracy: 0.7468\n",
      "Epoch 25/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6205 - accuracy: 0.7483 - val_loss: 0.6203 - val_accuracy: 0.7486\n",
      "Epoch 26/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6198 - accuracy: 0.7485 - val_loss: 0.6196 - val_accuracy: 0.7476\n",
      "Epoch 27/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6191 - accuracy: 0.7484 - val_loss: 0.6191 - val_accuracy: 0.7490\n",
      "Epoch 28/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6185 - accuracy: 0.7486 - val_loss: 0.6183 - val_accuracy: 0.7471\n",
      "Epoch 29/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6178 - accuracy: 0.7485 - val_loss: 0.6177 - val_accuracy: 0.7486\n",
      "Epoch 30/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6172 - accuracy: 0.7487 - val_loss: 0.6180 - val_accuracy: 0.7462\n",
      "Epoch 31/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6167 - accuracy: 0.7486 - val_loss: 0.6169 - val_accuracy: 0.7496\n",
      "Epoch 32/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6161 - accuracy: 0.7488 - val_loss: 0.6161 - val_accuracy: 0.7472\n",
      "Epoch 33/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6155 - accuracy: 0.7490 - val_loss: 0.6158 - val_accuracy: 0.7469\n",
      "Epoch 34/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6151 - accuracy: 0.7489 - val_loss: 0.6150 - val_accuracy: 0.7479\n",
      "Epoch 35/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6145 - accuracy: 0.7489 - val_loss: 0.6146 - val_accuracy: 0.7481\n",
      "Epoch 36/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6141 - accuracy: 0.7490 - val_loss: 0.6146 - val_accuracy: 0.7470\n",
      "Epoch 37/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6137 - accuracy: 0.7493 - val_loss: 0.6133 - val_accuracy: 0.7489\n",
      "Epoch 38/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6132 - accuracy: 0.7490 - val_loss: 0.6150 - val_accuracy: 0.7503\n",
      "Epoch 39/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6128 - accuracy: 0.7490 - val_loss: 0.6127 - val_accuracy: 0.7483\n",
      "Epoch 40/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6124 - accuracy: 0.7492 - val_loss: 0.6136 - val_accuracy: 0.7461\n",
      "Epoch 41/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6120 - accuracy: 0.7492 - val_loss: 0.6123 - val_accuracy: 0.7477\n",
      "Epoch 42/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6116 - accuracy: 0.7496 - val_loss: 0.6114 - val_accuracy: 0.7493\n",
      "Epoch 43/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6112 - accuracy: 0.7494 - val_loss: 0.6111 - val_accuracy: 0.7497\n",
      "Epoch 44/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6109 - accuracy: 0.7492 - val_loss: 0.6110 - val_accuracy: 0.7501\n",
      "Epoch 45/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6105 - accuracy: 0.7493 - val_loss: 0.6129 - val_accuracy: 0.7511\n",
      "Epoch 46/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6101 - accuracy: 0.7494 - val_loss: 0.6109 - val_accuracy: 0.7505\n",
      "Epoch 47/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6098 - accuracy: 0.7493 - val_loss: 0.6096 - val_accuracy: 0.7490\n",
      "Epoch 48/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6095 - accuracy: 0.7496 - val_loss: 0.6104 - val_accuracy: 0.7471\n",
      "Epoch 49/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6092 - accuracy: 0.7496 - val_loss: 0.6099 - val_accuracy: 0.7505\n",
      "Epoch 50/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6089 - accuracy: 0.7496 - val_loss: 0.6093 - val_accuracy: 0.7475\n",
      "Epoch 51/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6086 - accuracy: 0.7495 - val_loss: 0.6085 - val_accuracy: 0.7496\n",
      "Epoch 52/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6083 - accuracy: 0.7497 - val_loss: 0.6082 - val_accuracy: 0.7494\n",
      "Epoch 53/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6080 - accuracy: 0.7497 - val_loss: 0.6092 - val_accuracy: 0.7473\n",
      "Epoch 54/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6077 - accuracy: 0.7497 - val_loss: 0.6083 - val_accuracy: 0.7479\n",
      "Epoch 55/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6075 - accuracy: 0.7496 - val_loss: 0.6079 - val_accuracy: 0.7475\n",
      "Epoch 56/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6072 - accuracy: 0.7499 - val_loss: 0.6074 - val_accuracy: 0.7505\n",
      "Epoch 57/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6069 - accuracy: 0.7497 - val_loss: 0.6069 - val_accuracy: 0.7486\n",
      "Epoch 58/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6067 - accuracy: 0.7496 - val_loss: 0.6068 - val_accuracy: 0.7494\n",
      "Epoch 59/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6064 - accuracy: 0.7501 - val_loss: 0.6086 - val_accuracy: 0.7458\n",
      "Epoch 60/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6062 - accuracy: 0.7496 - val_loss: 0.6071 - val_accuracy: 0.7511\n",
      "Epoch 61/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6060 - accuracy: 0.7498 - val_loss: 0.6057 - val_accuracy: 0.7492\n",
      "Epoch 62/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6057 - accuracy: 0.7499 - val_loss: 0.6056 - val_accuracy: 0.7491\n",
      "Epoch 63/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6055 - accuracy: 0.7499 - val_loss: 0.6055 - val_accuracy: 0.7492\n",
      "Epoch 64/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6053 - accuracy: 0.7500 - val_loss: 0.6055 - val_accuracy: 0.7505\n",
      "Epoch 65/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6050 - accuracy: 0.7503 - val_loss: 0.6058 - val_accuracy: 0.7506\n",
      "Epoch 66/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6048 - accuracy: 0.7500 - val_loss: 0.6048 - val_accuracy: 0.7493\n",
      "Epoch 67/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6046 - accuracy: 0.7499 - val_loss: 0.6046 - val_accuracy: 0.7488\n",
      "Epoch 68/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6043 - accuracy: 0.7502 - val_loss: 0.6068 - val_accuracy: 0.7461\n",
      "Epoch 69/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6042 - accuracy: 0.7500 - val_loss: 0.6044 - val_accuracy: 0.7503\n",
      "Epoch 70/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6040 - accuracy: 0.7500 - val_loss: 0.6038 - val_accuracy: 0.7495\n",
      "Epoch 71/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6038 - accuracy: 0.7500 - val_loss: 0.6040 - val_accuracy: 0.7503\n",
      "Epoch 72/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6035 - accuracy: 0.7501 - val_loss: 0.6038 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6034 - accuracy: 0.7500 - val_loss: 0.6064 - val_accuracy: 0.7514\n",
      "Epoch 74/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6032 - accuracy: 0.7504 - val_loss: 0.6030 - val_accuracy: 0.7498\n",
      "Epoch 75/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6030 - accuracy: 0.7501 - val_loss: 0.6030 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6029 - accuracy: 0.7504 - val_loss: 0.6055 - val_accuracy: 0.7463\n",
      "Epoch 77/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6027 - accuracy: 0.7504 - val_loss: 0.6039 - val_accuracy: 0.7513\n",
      "Epoch 78/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6025 - accuracy: 0.7501 - val_loss: 0.6057 - val_accuracy: 0.7509\n",
      "Epoch 79/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6024 - accuracy: 0.7502 - val_loss: 0.6032 - val_accuracy: 0.7477\n",
      "Epoch 80/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6021 - accuracy: 0.7504 - val_loss: 0.6026 - val_accuracy: 0.7507\n",
      "Epoch 81/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6021 - accuracy: 0.7500 - val_loss: 0.6019 - val_accuracy: 0.7499\n",
      "Epoch 82/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6019 - accuracy: 0.7504 - val_loss: 0.6022 - val_accuracy: 0.7492\n",
      "Epoch 83/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6018 - accuracy: 0.7503 - val_loss: 0.6019 - val_accuracy: 0.7492\n",
      "Epoch 84/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6015 - accuracy: 0.7502 - val_loss: 0.6015 - val_accuracy: 0.7506\n",
      "Epoch 85/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6014 - accuracy: 0.7500 - val_loss: 0.6017 - val_accuracy: 0.7497\n",
      "Epoch 86/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6013 - accuracy: 0.7505 - val_loss: 0.6019 - val_accuracy: 0.7480\n",
      "Epoch 87/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6011 - accuracy: 0.7503 - val_loss: 0.6034 - val_accuracy: 0.7520\n",
      "Epoch 88/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6009 - accuracy: 0.7503 - val_loss: 0.6014 - val_accuracy: 0.7493\n",
      "Epoch 89/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6008 - accuracy: 0.7506 - val_loss: 0.6020 - val_accuracy: 0.7513\n",
      "Epoch 90/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6007 - accuracy: 0.7502 - val_loss: 0.6015 - val_accuracy: 0.7481\n",
      "Epoch 91/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6005 - accuracy: 0.7503 - val_loss: 0.6009 - val_accuracy: 0.7507\n",
      "Epoch 92/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6003 - accuracy: 0.7504 - val_loss: 0.6011 - val_accuracy: 0.7514\n",
      "Epoch 93/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6003 - accuracy: 0.7503 - val_loss: 0.6006 - val_accuracy: 0.7503\n",
      "Epoch 94/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6001 - accuracy: 0.7507 - val_loss: 0.6000 - val_accuracy: 0.7503\n",
      "Epoch 95/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5999 - accuracy: 0.7501 - val_loss: 0.6000 - val_accuracy: 0.7494\n",
      "Epoch 96/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5998 - accuracy: 0.7502 - val_loss: 0.6001 - val_accuracy: 0.7507\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5997 - accuracy: 0.7505 - val_loss: 0.6013 - val_accuracy: 0.7516\n",
      "Epoch 98/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5996 - accuracy: 0.7505 - val_loss: 0.5997 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5995 - accuracy: 0.7506 - val_loss: 0.6002 - val_accuracy: 0.7505\n",
      "Epoch 100/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5994 - accuracy: 0.7505 - val_loss: 0.6002 - val_accuracy: 0.7508\n",
      "4441/4441 [==============================] - 3s 686us/step - loss: 1.2649 - accuracy: 0.4528\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x0000019CAD688D30>\n",
      "Epoch Sizes:  100\n",
      "Neurons or Units:  256\n",
      "Test score: 1.2649024724960327\n",
      "Test accuracy: 0.45284879207611084\n",
      "\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,211\n",
      "Trainable params: 1,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.9638 - accuracy: 0.6992 - val_loss: 0.7997 - val_accuracy: 0.7315\n",
      "Epoch 2/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.7527 - accuracy: 0.7357 - val_loss: 0.7196 - val_accuracy: 0.7377\n",
      "Epoch 3/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.7015 - accuracy: 0.7394 - val_loss: 0.6873 - val_accuracy: 0.7394\n",
      "Epoch 4/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6782 - accuracy: 0.7415 - val_loss: 0.6706 - val_accuracy: 0.7427\n",
      "Epoch 5/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6651 - accuracy: 0.7433 - val_loss: 0.6605 - val_accuracy: 0.7440\n",
      "Epoch 6/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6569 - accuracy: 0.7446 - val_loss: 0.6538 - val_accuracy: 0.7452\n",
      "Epoch 7/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6511 - accuracy: 0.7455 - val_loss: 0.6486 - val_accuracy: 0.7448\n",
      "Epoch 8/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6467 - accuracy: 0.7458 - val_loss: 0.6448 - val_accuracy: 0.7461\n",
      "Epoch 9/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6433 - accuracy: 0.7463 - val_loss: 0.6426 - val_accuracy: 0.7475\n",
      "Epoch 10/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6404 - accuracy: 0.7467 - val_loss: 0.6396 - val_accuracy: 0.7472\n",
      "Epoch 11/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6380 - accuracy: 0.7467 - val_loss: 0.6373 - val_accuracy: 0.7450\n",
      "Epoch 12/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6359 - accuracy: 0.7471 - val_loss: 0.6350 - val_accuracy: 0.7470\n",
      "Epoch 13/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6338 - accuracy: 0.7474 - val_loss: 0.6336 - val_accuracy: 0.7483\n",
      "Epoch 14/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6321 - accuracy: 0.7474 - val_loss: 0.6317 - val_accuracy: 0.7476\n",
      "Epoch 15/200\n",
      "2498/2498 [==============================] - 2s 994us/step - loss: 0.6306 - accuracy: 0.7475 - val_loss: 0.6300 - val_accuracy: 0.7475\n",
      "Epoch 16/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6291 - accuracy: 0.7476 - val_loss: 0.6287 - val_accuracy: 0.7478\n",
      "Epoch 17/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6278 - accuracy: 0.7478 - val_loss: 0.6273 - val_accuracy: 0.7473\n",
      "Epoch 18/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6267 - accuracy: 0.7481 - val_loss: 0.6264 - val_accuracy: 0.7480\n",
      "Epoch 19/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6256 - accuracy: 0.7479 - val_loss: 0.6257 - val_accuracy: 0.7489\n",
      "Epoch 20/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6245 - accuracy: 0.7482 - val_loss: 0.6248 - val_accuracy: 0.7490\n",
      "Epoch 21/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6236 - accuracy: 0.7481 - val_loss: 0.6232 - val_accuracy: 0.7483\n",
      "Epoch 22/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6226 - accuracy: 0.7482 - val_loss: 0.6224 - val_accuracy: 0.7482\n",
      "Epoch 23/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6217 - accuracy: 0.7487 - val_loss: 0.6214 - val_accuracy: 0.7480\n",
      "Epoch 24/200\n",
      "2498/2498 [==============================] - 2s 996us/step - loss: 0.6210 - accuracy: 0.7485 - val_loss: 0.6213 - val_accuracy: 0.7495\n",
      "Epoch 25/200\n",
      "2498/2498 [==============================] - 2s 992us/step - loss: 0.6202 - accuracy: 0.7483 - val_loss: 0.6200 - val_accuracy: 0.7471\n",
      "Epoch 26/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6195 - accuracy: 0.7485 - val_loss: 0.6192 - val_accuracy: 0.7480\n",
      "Epoch 27/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6188 - accuracy: 0.7485 - val_loss: 0.6186 - val_accuracy: 0.7476\n",
      "Epoch 28/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6181 - accuracy: 0.7483 - val_loss: 0.6179 - val_accuracy: 0.7488\n",
      "Epoch 29/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6175 - accuracy: 0.7486 - val_loss: 0.6176 - val_accuracy: 0.7486\n",
      "Epoch 30/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6169 - accuracy: 0.7492 - val_loss: 0.6173 - val_accuracy: 0.7466\n",
      "Epoch 31/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6163 - accuracy: 0.7488 - val_loss: 0.6178 - val_accuracy: 0.7507\n",
      "Epoch 32/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6158 - accuracy: 0.7491 - val_loss: 0.6167 - val_accuracy: 0.7500\n",
      "Epoch 33/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6153 - accuracy: 0.7490 - val_loss: 0.6155 - val_accuracy: 0.7497\n",
      "Epoch 34/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6147 - accuracy: 0.7491 - val_loss: 0.6147 - val_accuracy: 0.7491\n",
      "Epoch 35/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6142 - accuracy: 0.7493 - val_loss: 0.6147 - val_accuracy: 0.7497\n",
      "Epoch 36/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6138 - accuracy: 0.7494 - val_loss: 0.6142 - val_accuracy: 0.7467\n",
      "Epoch 37/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6133 - accuracy: 0.7489 - val_loss: 0.6136 - val_accuracy: 0.7492\n",
      "Epoch 38/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6129 - accuracy: 0.7490 - val_loss: 0.6134 - val_accuracy: 0.7494\n",
      "Epoch 39/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6125 - accuracy: 0.7494 - val_loss: 0.6143 - val_accuracy: 0.7505\n",
      "Epoch 40/200\n",
      "2498/2498 [==============================] - 2s 986us/step - loss: 0.6121 - accuracy: 0.7491 - val_loss: 0.6123 - val_accuracy: 0.7495\n",
      "Epoch 41/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6117 - accuracy: 0.7491 - val_loss: 0.6123 - val_accuracy: 0.7472\n",
      "Epoch 42/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6113 - accuracy: 0.7494 - val_loss: 0.6121 - val_accuracy: 0.7467\n",
      "Epoch 43/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6109 - accuracy: 0.7494 - val_loss: 0.6110 - val_accuracy: 0.7493\n",
      "Epoch 44/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6106 - accuracy: 0.7492 - val_loss: 0.6121 - val_accuracy: 0.7501\n",
      "Epoch 45/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6103 - accuracy: 0.7494 - val_loss: 0.6104 - val_accuracy: 0.7487\n",
      "Epoch 46/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6099 - accuracy: 0.7497 - val_loss: 0.6101 - val_accuracy: 0.7479\n",
      "Epoch 47/200\n",
      "2498/2498 [==============================] - 2s 980us/step - loss: 0.6096 - accuracy: 0.7496 - val_loss: 0.6096 - val_accuracy: 0.7493\n",
      "Epoch 48/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6092 - accuracy: 0.7497 - val_loss: 0.6111 - val_accuracy: 0.7508\n",
      "Epoch 49/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6089 - accuracy: 0.7496 - val_loss: 0.6095 - val_accuracy: 0.7477\n",
      "Epoch 50/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6086 - accuracy: 0.7496 - val_loss: 0.6089 - val_accuracy: 0.7504\n",
      "Epoch 51/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6084 - accuracy: 0.7498 - val_loss: 0.6088 - val_accuracy: 0.7501\n",
      "Epoch 52/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6081 - accuracy: 0.7495 - val_loss: 0.6089 - val_accuracy: 0.7506\n",
      "Epoch 53/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6078 - accuracy: 0.7496 - val_loss: 0.6097 - val_accuracy: 0.7508\n",
      "Epoch 54/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6075 - accuracy: 0.7499 - val_loss: 0.6082 - val_accuracy: 0.7495\n",
      "Epoch 55/200\n",
      "2498/2498 [==============================] - 2s 1000us/step - loss: 0.6072 - accuracy: 0.7496 - val_loss: 0.6073 - val_accuracy: 0.7482\n",
      "Epoch 56/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6069 - accuracy: 0.7500 - val_loss: 0.6099 - val_accuracy: 0.7511\n",
      "Epoch 57/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6068 - accuracy: 0.7497 - val_loss: 0.6068 - val_accuracy: 0.7495\n",
      "Epoch 58/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6065 - accuracy: 0.7500 - val_loss: 0.6068 - val_accuracy: 0.7501\n",
      "Epoch 59/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6063 - accuracy: 0.7501 - val_loss: 0.6063 - val_accuracy: 0.7492\n",
      "Epoch 60/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6060 - accuracy: 0.7501 - val_loss: 0.6063 - val_accuracy: 0.7499\n",
      "Epoch 61/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6058 - accuracy: 0.7501 - val_loss: 0.6056 - val_accuracy: 0.7496\n",
      "Epoch 62/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6055 - accuracy: 0.7500 - val_loss: 0.6073 - val_accuracy: 0.7511\n",
      "Epoch 63/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6054 - accuracy: 0.7498 - val_loss: 0.6054 - val_accuracy: 0.7483\n",
      "Epoch 64/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6051 - accuracy: 0.7497 - val_loss: 0.6054 - val_accuracy: 0.7483\n",
      "Epoch 65/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6049 - accuracy: 0.7499 - val_loss: 0.6075 - val_accuracy: 0.7511\n",
      "Epoch 66/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6047 - accuracy: 0.7500 - val_loss: 0.6052 - val_accuracy: 0.7503\n",
      "Epoch 67/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6044 - accuracy: 0.7501 - val_loss: 0.6067 - val_accuracy: 0.7512\n",
      "Epoch 68/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6043 - accuracy: 0.7499 - val_loss: 0.6052 - val_accuracy: 0.7507\n",
      "Epoch 69/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6041 - accuracy: 0.7496 - val_loss: 0.6041 - val_accuracy: 0.7493\n",
      "Epoch 70/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6039 - accuracy: 0.7499 - val_loss: 0.6039 - val_accuracy: 0.7491\n",
      "Epoch 71/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6037 - accuracy: 0.7502 - val_loss: 0.6036 - val_accuracy: 0.7496\n",
      "Epoch 72/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6035 - accuracy: 0.7502 - val_loss: 0.6056 - val_accuracy: 0.7513\n",
      "Epoch 73/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6033 - accuracy: 0.7502 - val_loss: 0.6037 - val_accuracy: 0.7498\n",
      "Epoch 74/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6032 - accuracy: 0.7501 - val_loss: 0.6037 - val_accuracy: 0.7506\n",
      "Epoch 75/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6030 - accuracy: 0.7503 - val_loss: 0.6043 - val_accuracy: 0.7505\n",
      "Epoch 76/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6028 - accuracy: 0.7504 - val_loss: 0.6028 - val_accuracy: 0.7498\n",
      "Epoch 77/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6027 - accuracy: 0.7500 - val_loss: 0.6046 - val_accuracy: 0.7513\n",
      "Epoch 78/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6025 - accuracy: 0.7502 - val_loss: 0.6030 - val_accuracy: 0.7489\n",
      "Epoch 79/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6023 - accuracy: 0.7499 - val_loss: 0.6025 - val_accuracy: 0.7487\n",
      "Epoch 80/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6022 - accuracy: 0.7505 - val_loss: 0.6039 - val_accuracy: 0.7471\n",
      "Epoch 81/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6020 - accuracy: 0.7505 - val_loss: 0.6025 - val_accuracy: 0.7504\n",
      "Epoch 82/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6018 - accuracy: 0.7504 - val_loss: 0.6028 - val_accuracy: 0.7508\n",
      "Epoch 83/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6016 - accuracy: 0.7503 - val_loss: 0.6022 - val_accuracy: 0.7491\n",
      "Epoch 84/200\n",
      "2498/2498 [==============================] - 2s 976us/step - loss: 0.6015 - accuracy: 0.7502 - val_loss: 0.6027 - val_accuracy: 0.7506\n",
      "Epoch 85/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6014 - accuracy: 0.7503 - val_loss: 0.6014 - val_accuracy: 0.7503\n",
      "Epoch 86/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6012 - accuracy: 0.7505 - val_loss: 0.6011 - val_accuracy: 0.7494\n",
      "Epoch 87/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6011 - accuracy: 0.7505 - val_loss: 0.6023 - val_accuracy: 0.7479\n",
      "Epoch 88/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6009 - accuracy: 0.7501 - val_loss: 0.6008 - val_accuracy: 0.7491\n",
      "Epoch 89/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6007 - accuracy: 0.7504 - val_loss: 0.6019 - val_accuracy: 0.7516\n",
      "Epoch 90/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6006 - accuracy: 0.7505 - val_loss: 0.6006 - val_accuracy: 0.7495\n",
      "Epoch 91/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6005 - accuracy: 0.7504 - val_loss: 0.6005 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6004 - accuracy: 0.7502 - val_loss: 0.6002 - val_accuracy: 0.7501\n",
      "Epoch 93/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6003 - accuracy: 0.7501 - val_loss: 0.6002 - val_accuracy: 0.7499\n",
      "Epoch 94/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6000 - accuracy: 0.7503 - val_loss: 0.6015 - val_accuracy: 0.7491\n",
      "Epoch 95/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6000 - accuracy: 0.7505 - val_loss: 0.6014 - val_accuracy: 0.7472\n",
      "Epoch 96/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5999 - accuracy: 0.7508 - val_loss: 0.5998 - val_accuracy: 0.7504\n",
      "Epoch 97/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5998 - accuracy: 0.7505 - val_loss: 0.6005 - val_accuracy: 0.7477\n",
      "Epoch 98/200\n",
      "2498/2498 [==============================] - 2s 926us/step - loss: 0.5996 - accuracy: 0.7504 - val_loss: 0.6001 - val_accuracy: 0.7501\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 2s 827us/step - loss: 0.5995 - accuracy: 0.7507 - val_loss: 0.6007 - val_accuracy: 0.7471\n",
      "Epoch 100/200\n",
      "2498/2498 [==============================] - 2s 812us/step - loss: 0.5994 - accuracy: 0.7506 - val_loss: 0.5990 - val_accuracy: 0.7500\n",
      "Epoch 101/200\n",
      "2498/2498 [==============================] - 2s 859us/step - loss: 0.5993 - accuracy: 0.7502 - val_loss: 0.5999 - val_accuracy: 0.7503\n",
      "Epoch 102/200\n",
      "2498/2498 [==============================] - 2s 897us/step - loss: 0.5990 - accuracy: 0.7507 - val_loss: 0.5998 - val_accuracy: 0.7506\n",
      "Epoch 103/200\n",
      "2498/2498 [==============================] - 2s 849us/step - loss: 0.5990 - accuracy: 0.7505 - val_loss: 0.6019 - val_accuracy: 0.7518\n",
      "Epoch 104/200\n",
      "2498/2498 [==============================] - 2s 856us/step - loss: 0.5990 - accuracy: 0.7506 - val_loss: 0.5991 - val_accuracy: 0.7505\n",
      "Epoch 105/200\n",
      "2498/2498 [==============================] - 2s 950us/step - loss: 0.5988 - accuracy: 0.7506 - val_loss: 0.5998 - val_accuracy: 0.7512\n",
      "Epoch 106/200\n",
      "2498/2498 [==============================] - 2s 969us/step - loss: 0.5987 - accuracy: 0.7503 - val_loss: 0.6041 - val_accuracy: 0.7518\n",
      "Epoch 107/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5987 - accuracy: 0.7504 - val_loss: 0.5987 - val_accuracy: 0.7496\n",
      "Epoch 108/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5985 - accuracy: 0.7508 - val_loss: 0.5992 - val_accuracy: 0.7478\n",
      "Epoch 109/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5984 - accuracy: 0.7504 - val_loss: 0.5984 - val_accuracy: 0.7501\n",
      "Epoch 110/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5983 - accuracy: 0.7506 - val_loss: 0.5984 - val_accuracy: 0.7499\n",
      "Epoch 111/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5981 - accuracy: 0.7507 - val_loss: 0.5986 - val_accuracy: 0.7483\n",
      "Epoch 112/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5981 - accuracy: 0.7504 - val_loss: 0.5979 - val_accuracy: 0.7501\n",
      "Epoch 113/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5980 - accuracy: 0.7503 - val_loss: 0.6005 - val_accuracy: 0.7472\n",
      "Epoch 114/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5979 - accuracy: 0.7509 - val_loss: 0.6006 - val_accuracy: 0.7462\n",
      "Epoch 115/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5977 - accuracy: 0.7511 - val_loss: 0.6021 - val_accuracy: 0.7449\n",
      "Epoch 116/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5978 - accuracy: 0.7503 - val_loss: 0.5994 - val_accuracy: 0.7516\n",
      "Epoch 117/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5975 - accuracy: 0.7507 - val_loss: 0.6004 - val_accuracy: 0.7463\n",
      "Epoch 118/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5974 - accuracy: 0.7506 - val_loss: 0.5974 - val_accuracy: 0.7509\n",
      "Epoch 119/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5974 - accuracy: 0.7504 - val_loss: 0.5973 - val_accuracy: 0.7509\n",
      "Epoch 120/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5973 - accuracy: 0.7505 - val_loss: 0.5979 - val_accuracy: 0.7491\n",
      "Epoch 121/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5972 - accuracy: 0.7506 - val_loss: 0.5972 - val_accuracy: 0.7501\n",
      "Epoch 122/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5971 - accuracy: 0.7506 - val_loss: 0.5970 - val_accuracy: 0.7497\n",
      "Epoch 123/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5970 - accuracy: 0.7505 - val_loss: 0.5968 - val_accuracy: 0.7503\n",
      "Epoch 124/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5970 - accuracy: 0.7505 - val_loss: 0.5969 - val_accuracy: 0.7501\n",
      "Epoch 125/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5968 - accuracy: 0.7506 - val_loss: 0.5995 - val_accuracy: 0.7521\n",
      "Epoch 126/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5967 - accuracy: 0.7505 - val_loss: 0.5970 - val_accuracy: 0.7511\n",
      "Epoch 127/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5966 - accuracy: 0.7506 - val_loss: 0.5982 - val_accuracy: 0.7514\n",
      "Epoch 128/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5965 - accuracy: 0.7507 - val_loss: 0.6000 - val_accuracy: 0.7464\n",
      "Epoch 129/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5965 - accuracy: 0.7505 - val_loss: 0.5970 - val_accuracy: 0.7505\n",
      "Epoch 130/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5963 - accuracy: 0.7504 - val_loss: 0.5966 - val_accuracy: 0.7489\n",
      "Epoch 131/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5962 - accuracy: 0.7507 - val_loss: 0.5995 - val_accuracy: 0.7518\n",
      "Epoch 132/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5961 - accuracy: 0.7506 - val_loss: 0.5962 - val_accuracy: 0.7502\n",
      "Epoch 133/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5962 - accuracy: 0.7507 - val_loss: 0.5966 - val_accuracy: 0.7498\n",
      "Epoch 134/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5960 - accuracy: 0.7507 - val_loss: 0.5959 - val_accuracy: 0.7507\n",
      "Epoch 135/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5959 - accuracy: 0.7507 - val_loss: 0.5966 - val_accuracy: 0.7496\n",
      "Epoch 136/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5959 - accuracy: 0.7510 - val_loss: 0.5957 - val_accuracy: 0.7502\n",
      "Epoch 137/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5958 - accuracy: 0.7507 - val_loss: 0.5967 - val_accuracy: 0.7487\n",
      "Epoch 138/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5957 - accuracy: 0.7509 - val_loss: 0.5962 - val_accuracy: 0.7509\n",
      "Epoch 139/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5957 - accuracy: 0.7505 - val_loss: 0.5959 - val_accuracy: 0.7507\n",
      "Epoch 140/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5956 - accuracy: 0.7508 - val_loss: 0.5962 - val_accuracy: 0.7488\n",
      "Epoch 141/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5955 - accuracy: 0.7505 - val_loss: 0.5956 - val_accuracy: 0.7504\n",
      "Epoch 142/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5955 - accuracy: 0.7509 - val_loss: 0.5953 - val_accuracy: 0.7493\n",
      "Epoch 143/200\n",
      "2498/2498 [==============================] - 2s 976us/step - loss: 0.5953 - accuracy: 0.7507 - val_loss: 0.5955 - val_accuracy: 0.7505\n",
      "Epoch 144/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5953 - accuracy: 0.7508 - val_loss: 0.5964 - val_accuracy: 0.7513\n",
      "Epoch 145/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5952 - accuracy: 0.7511 - val_loss: 0.5962 - val_accuracy: 0.7490\n",
      "Epoch 146/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5951 - accuracy: 0.7506 - val_loss: 0.5951 - val_accuracy: 0.7507\n",
      "Epoch 147/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5951 - accuracy: 0.7509 - val_loss: 0.5955 - val_accuracy: 0.7485\n",
      "Epoch 148/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5951 - accuracy: 0.7505 - val_loss: 0.5979 - val_accuracy: 0.7517\n",
      "Epoch 149/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5949 - accuracy: 0.7505 - val_loss: 0.5968 - val_accuracy: 0.7485\n",
      "Epoch 150/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5948 - accuracy: 0.7509 - val_loss: 0.5966 - val_accuracy: 0.7514\n",
      "Epoch 151/200\n",
      "2498/2498 [==============================] - 2s 881us/step - loss: 0.5948 - accuracy: 0.7510 - val_loss: 0.5968 - val_accuracy: 0.7519\n",
      "Epoch 152/200\n",
      "2498/2498 [==============================] - 2s 984us/step - loss: 0.5947 - accuracy: 0.7509 - val_loss: 0.5959 - val_accuracy: 0.7515\n",
      "Epoch 153/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5946 - accuracy: 0.7510 - val_loss: 0.5990 - val_accuracy: 0.7455\n",
      "Epoch 154/200\n",
      "2498/2498 [==============================] - 2s 962us/step - loss: 0.5946 - accuracy: 0.7508 - val_loss: 0.5973 - val_accuracy: 0.7518\n",
      "Epoch 155/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5944 - accuracy: 0.7511 - val_loss: 0.5948 - val_accuracy: 0.7489\n",
      "Epoch 156/200\n",
      "2498/2498 [==============================] - 2s 976us/step - loss: 0.5943 - accuracy: 0.7510 - val_loss: 0.5955 - val_accuracy: 0.7487\n",
      "Epoch 157/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5943 - accuracy: 0.7506 - val_loss: 0.5946 - val_accuracy: 0.7493\n",
      "Epoch 158/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5943 - accuracy: 0.7512 - val_loss: 0.5950 - val_accuracy: 0.7510\n",
      "Epoch 159/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5943 - accuracy: 0.7509 - val_loss: 0.5945 - val_accuracy: 0.7498\n",
      "Epoch 160/200\n",
      "2498/2498 [==============================] - 2s 928us/step - loss: 0.5941 - accuracy: 0.7508 - val_loss: 0.5940 - val_accuracy: 0.7510\n",
      "Epoch 161/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5940 - accuracy: 0.7508 - val_loss: 0.5944 - val_accuracy: 0.7493\n",
      "Epoch 162/200\n",
      "2498/2498 [==============================] - 2s 958us/step - loss: 0.5941 - accuracy: 0.7510 - val_loss: 0.5952 - val_accuracy: 0.7515\n",
      "Epoch 163/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5939 - accuracy: 0.7509 - val_loss: 0.6025 - val_accuracy: 0.7523\n",
      "Epoch 164/200\n",
      "2498/2498 [==============================] - 2s 911us/step - loss: 0.5938 - accuracy: 0.7509 - val_loss: 0.5957 - val_accuracy: 0.7473\n",
      "Epoch 165/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5938 - accuracy: 0.7508 - val_loss: 0.5945 - val_accuracy: 0.7518\n",
      "Epoch 166/200\n",
      "2498/2498 [==============================] - 2s 962us/step - loss: 0.5939 - accuracy: 0.7510 - val_loss: 0.5941 - val_accuracy: 0.7487\n",
      "Epoch 167/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5936 - accuracy: 0.7509 - val_loss: 0.5940 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "2498/2498 [==============================] - 2s 871us/step - loss: 0.5937 - accuracy: 0.7506 - val_loss: 0.5944 - val_accuracy: 0.7520\n",
      "Epoch 169/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5935 - accuracy: 0.7508 - val_loss: 0.5935 - val_accuracy: 0.7511\n",
      "Epoch 170/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5936 - accuracy: 0.7507 - val_loss: 0.5930 - val_accuracy: 0.7505\n",
      "Epoch 171/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5935 - accuracy: 0.7511 - val_loss: 0.5939 - val_accuracy: 0.7497\n",
      "Epoch 172/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5934 - accuracy: 0.7511 - val_loss: 0.5987 - val_accuracy: 0.7523\n",
      "Epoch 173/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5934 - accuracy: 0.7510 - val_loss: 0.5932 - val_accuracy: 0.7508\n",
      "Epoch 174/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5933 - accuracy: 0.7508 - val_loss: 0.5939 - val_accuracy: 0.7482\n",
      "Epoch 175/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5932 - accuracy: 0.7511 - val_loss: 0.5949 - val_accuracy: 0.7509\n",
      "Epoch 176/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5932 - accuracy: 0.7512 - val_loss: 0.5934 - val_accuracy: 0.7493\n",
      "Epoch 177/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5932 - accuracy: 0.7509 - val_loss: 0.5932 - val_accuracy: 0.7501\n",
      "Epoch 178/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.7511 - val_loss: 0.5928 - val_accuracy: 0.7501\n",
      "Epoch 179/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5929 - accuracy: 0.7508 - val_loss: 0.5933 - val_accuracy: 0.7506\n",
      "Epoch 180/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5929 - accuracy: 0.7512 - val_loss: 0.5972 - val_accuracy: 0.7460\n",
      "Epoch 181/200\n",
      "2498/2498 [==============================] - 2s 983us/step - loss: 0.5929 - accuracy: 0.7512 - val_loss: 0.5943 - val_accuracy: 0.7482\n",
      "Epoch 182/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5928 - accuracy: 0.7509 - val_loss: 0.5933 - val_accuracy: 0.7482\n",
      "Epoch 183/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5927 - accuracy: 0.7511 - val_loss: 0.5936 - val_accuracy: 0.7522\n",
      "Epoch 184/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5929 - accuracy: 0.7511 - val_loss: 0.5925 - val_accuracy: 0.7499\n",
      "Epoch 185/200\n",
      "2498/2498 [==============================] - 2s 941us/step - loss: 0.5926 - accuracy: 0.7509 - val_loss: 0.5935 - val_accuracy: 0.7507\n",
      "Epoch 186/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5926 - accuracy: 0.7514 - val_loss: 0.5923 - val_accuracy: 0.7511\n",
      "Epoch 187/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5923 - accuracy: 0.7511 - val_loss: 0.5926 - val_accuracy: 0.7496\n",
      "Epoch 188/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5924 - accuracy: 0.7508 - val_loss: 0.5932 - val_accuracy: 0.7488\n",
      "Epoch 189/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5925 - accuracy: 0.7511 - val_loss: 0.5931 - val_accuracy: 0.7502\n",
      "Epoch 190/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5923 - accuracy: 0.7514 - val_loss: 0.5929 - val_accuracy: 0.7507\n",
      "Epoch 191/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5923 - accuracy: 0.7512 - val_loss: 0.5924 - val_accuracy: 0.7514\n",
      "Epoch 192/200\n",
      "2498/2498 [==============================] - 2s 994us/step - loss: 0.5922 - accuracy: 0.7511 - val_loss: 0.5931 - val_accuracy: 0.7511\n",
      "Epoch 193/200\n",
      "2498/2498 [==============================] - 2s 981us/step - loss: 0.5922 - accuracy: 0.7509 - val_loss: 0.5924 - val_accuracy: 0.7516\n",
      "Epoch 194/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5922 - accuracy: 0.7511 - val_loss: 0.5941 - val_accuracy: 0.7477\n",
      "Epoch 195/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5922 - accuracy: 0.7510 - val_loss: 0.5919 - val_accuracy: 0.7500\n",
      "Epoch 196/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5920 - accuracy: 0.7511 - val_loss: 0.5921 - val_accuracy: 0.7519\n",
      "Epoch 197/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5919 - accuracy: 0.7513 - val_loss: 0.5919 - val_accuracy: 0.7495\n",
      "Epoch 198/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5920 - accuracy: 0.7511 - val_loss: 0.5922 - val_accuracy: 0.7513\n",
      "Epoch 199/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5918 - accuracy: 0.7510 - val_loss: 0.5943 - val_accuracy: 0.7476\n",
      "Epoch 200/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5918 - accuracy: 0.7511 - val_loss: 0.5959 - val_accuracy: 0.7518\n",
      "4441/4441 [==============================] - 3s 678us/step - loss: 1.2647 - accuracy: 0.4474\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x0000019CAD688D30>\n",
      "Epoch Sizes:  200\n",
      "Neurons or Units:  64\n",
      "Test score: 1.2646678686141968\n",
      "Test accuracy: 0.4473735988140106\n",
      "\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.9727 - accuracy: 0.7013 - val_loss: 0.8028 - val_accuracy: 0.7371\n",
      "Epoch 2/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.7531 - accuracy: 0.7409 - val_loss: 0.7184 - val_accuracy: 0.7436\n",
      "Epoch 3/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6994 - accuracy: 0.7437 - val_loss: 0.6846 - val_accuracy: 0.7442\n",
      "Epoch 4/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6755 - accuracy: 0.7444 - val_loss: 0.6679 - val_accuracy: 0.7449\n",
      "Epoch 5/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6630 - accuracy: 0.7449 - val_loss: 0.6584 - val_accuracy: 0.7441\n",
      "Epoch 6/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6553 - accuracy: 0.7453 - val_loss: 0.6525 - val_accuracy: 0.7465\n",
      "Epoch 7/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6500 - accuracy: 0.7457 - val_loss: 0.6477 - val_accuracy: 0.7456\n",
      "Epoch 8/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6460 - accuracy: 0.7458 - val_loss: 0.6444 - val_accuracy: 0.7442\n",
      "Epoch 9/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6428 - accuracy: 0.7462 - val_loss: 0.6415 - val_accuracy: 0.7449\n",
      "Epoch 10/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6402 - accuracy: 0.7463 - val_loss: 0.6389 - val_accuracy: 0.7463\n",
      "Epoch 11/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6378 - accuracy: 0.7466 - val_loss: 0.6366 - val_accuracy: 0.7462\n",
      "Epoch 12/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6358 - accuracy: 0.7465 - val_loss: 0.6350 - val_accuracy: 0.7456\n",
      "Epoch 13/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6340 - accuracy: 0.7469 - val_loss: 0.6330 - val_accuracy: 0.7459\n",
      "Epoch 14/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6323 - accuracy: 0.7470 - val_loss: 0.6323 - val_accuracy: 0.7488\n",
      "Epoch 15/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6308 - accuracy: 0.7473 - val_loss: 0.6300 - val_accuracy: 0.7467\n",
      "Epoch 16/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6294 - accuracy: 0.7476 - val_loss: 0.6288 - val_accuracy: 0.7476\n",
      "Epoch 17/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6281 - accuracy: 0.7472 - val_loss: 0.6275 - val_accuracy: 0.7479\n",
      "Epoch 18/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6269 - accuracy: 0.7476 - val_loss: 0.6263 - val_accuracy: 0.7475\n",
      "Epoch 19/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6259 - accuracy: 0.7479 - val_loss: 0.6254 - val_accuracy: 0.7471\n",
      "Epoch 20/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6248 - accuracy: 0.7479 - val_loss: 0.6246 - val_accuracy: 0.7463\n",
      "Epoch 21/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6238 - accuracy: 0.7481 - val_loss: 0.6235 - val_accuracy: 0.7478\n",
      "Epoch 22/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6229 - accuracy: 0.7482 - val_loss: 0.6228 - val_accuracy: 0.7481\n",
      "Epoch 23/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6220 - accuracy: 0.7483 - val_loss: 0.6216 - val_accuracy: 0.7478\n",
      "Epoch 24/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6212 - accuracy: 0.7485 - val_loss: 0.6208 - val_accuracy: 0.7481\n",
      "Epoch 25/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6204 - accuracy: 0.7483 - val_loss: 0.6201 - val_accuracy: 0.7482\n",
      "Epoch 26/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6196 - accuracy: 0.7487 - val_loss: 0.6200 - val_accuracy: 0.7493\n",
      "Epoch 27/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6189 - accuracy: 0.7486 - val_loss: 0.6193 - val_accuracy: 0.7464\n",
      "Epoch 28/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6183 - accuracy: 0.7488 - val_loss: 0.6183 - val_accuracy: 0.7489\n",
      "Epoch 29/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6177 - accuracy: 0.7488 - val_loss: 0.6174 - val_accuracy: 0.7487\n",
      "Epoch 30/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6170 - accuracy: 0.7488 - val_loss: 0.6170 - val_accuracy: 0.7475\n",
      "Epoch 31/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6165 - accuracy: 0.7488 - val_loss: 0.6164 - val_accuracy: 0.7496\n",
      "Epoch 32/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6159 - accuracy: 0.7489 - val_loss: 0.6156 - val_accuracy: 0.7494\n",
      "Epoch 33/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6154 - accuracy: 0.7490 - val_loss: 0.6153 - val_accuracy: 0.7496\n",
      "Epoch 34/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6149 - accuracy: 0.7492 - val_loss: 0.6155 - val_accuracy: 0.7464\n",
      "Epoch 35/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6144 - accuracy: 0.7494 - val_loss: 0.6145 - val_accuracy: 0.7477\n",
      "Epoch 36/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6139 - accuracy: 0.7490 - val_loss: 0.6140 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6134 - accuracy: 0.7490 - val_loss: 0.6136 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6129 - accuracy: 0.7491 - val_loss: 0.6128 - val_accuracy: 0.7493\n",
      "Epoch 39/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6125 - accuracy: 0.7490 - val_loss: 0.6130 - val_accuracy: 0.7474\n",
      "Epoch 40/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6121 - accuracy: 0.7493 - val_loss: 0.6125 - val_accuracy: 0.7489\n",
      "Epoch 41/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6117 - accuracy: 0.7495 - val_loss: 0.6120 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6114 - accuracy: 0.7492 - val_loss: 0.6114 - val_accuracy: 0.7488\n",
      "Epoch 43/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6109 - accuracy: 0.7493 - val_loss: 0.6116 - val_accuracy: 0.7466\n",
      "Epoch 44/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6106 - accuracy: 0.7494 - val_loss: 0.6104 - val_accuracy: 0.7487\n",
      "Epoch 45/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6102 - accuracy: 0.7496 - val_loss: 0.6103 - val_accuracy: 0.7481\n",
      "Epoch 46/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6099 - accuracy: 0.7497 - val_loss: 0.6096 - val_accuracy: 0.7492\n",
      "Epoch 47/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6095 - accuracy: 0.7496 - val_loss: 0.6106 - val_accuracy: 0.7462\n",
      "Epoch 48/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6093 - accuracy: 0.7494 - val_loss: 0.6090 - val_accuracy: 0.7490\n",
      "Epoch 49/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6089 - accuracy: 0.7495 - val_loss: 0.6092 - val_accuracy: 0.7481\n",
      "Epoch 50/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6086 - accuracy: 0.7497 - val_loss: 0.6090 - val_accuracy: 0.7490\n",
      "Epoch 51/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6083 - accuracy: 0.7496 - val_loss: 0.6084 - val_accuracy: 0.7483\n",
      "Epoch 52/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6080 - accuracy: 0.7499 - val_loss: 0.6081 - val_accuracy: 0.7505\n",
      "Epoch 53/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.6077 - accuracy: 0.7499 - val_loss: 0.6077 - val_accuracy: 0.7486\n",
      "Epoch 54/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6074 - accuracy: 0.7498 - val_loss: 0.6072 - val_accuracy: 0.7494\n",
      "Epoch 55/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.6071 - accuracy: 0.7498 - val_loss: 0.6080 - val_accuracy: 0.7477\n",
      "Epoch 56/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6069 - accuracy: 0.7497 - val_loss: 0.6071 - val_accuracy: 0.7496\n",
      "Epoch 57/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6066 - accuracy: 0.7500 - val_loss: 0.6067 - val_accuracy: 0.7486\n",
      "Epoch 58/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6064 - accuracy: 0.7496 - val_loss: 0.6065 - val_accuracy: 0.7492\n",
      "Epoch 59/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6061 - accuracy: 0.7499 - val_loss: 0.6075 - val_accuracy: 0.7509\n",
      "Epoch 60/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6058 - accuracy: 0.7501 - val_loss: 0.6066 - val_accuracy: 0.7508\n",
      "Epoch 61/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6055 - accuracy: 0.7499 - val_loss: 0.6055 - val_accuracy: 0.7499\n",
      "Epoch 62/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6054 - accuracy: 0.7499 - val_loss: 0.6058 - val_accuracy: 0.7496\n",
      "Epoch 63/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6052 - accuracy: 0.7498 - val_loss: 0.6062 - val_accuracy: 0.7511\n",
      "Epoch 64/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6049 - accuracy: 0.7500 - val_loss: 0.6053 - val_accuracy: 0.7482\n",
      "Epoch 65/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6047 - accuracy: 0.7499 - val_loss: 0.6051 - val_accuracy: 0.7486\n",
      "Epoch 66/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6045 - accuracy: 0.7499 - val_loss: 0.6045 - val_accuracy: 0.7499\n",
      "Epoch 67/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6043 - accuracy: 0.7501 - val_loss: 0.6086 - val_accuracy: 0.7517\n",
      "Epoch 68/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6041 - accuracy: 0.7498 - val_loss: 0.6043 - val_accuracy: 0.7496\n",
      "Epoch 69/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6039 - accuracy: 0.7499 - val_loss: 0.6041 - val_accuracy: 0.7495\n",
      "Epoch 70/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6037 - accuracy: 0.7501 - val_loss: 0.6040 - val_accuracy: 0.7479\n",
      "Epoch 71/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6034 - accuracy: 0.7502 - val_loss: 0.6037 - val_accuracy: 0.7498\n",
      "Epoch 72/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6033 - accuracy: 0.7502 - val_loss: 0.6053 - val_accuracy: 0.7515\n",
      "Epoch 73/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6032 - accuracy: 0.7504 - val_loss: 0.6034 - val_accuracy: 0.7505\n",
      "Epoch 74/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6029 - accuracy: 0.7505 - val_loss: 0.6042 - val_accuracy: 0.7473\n",
      "Epoch 75/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6028 - accuracy: 0.7504 - val_loss: 0.6029 - val_accuracy: 0.7506\n",
      "Epoch 76/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6026 - accuracy: 0.7504 - val_loss: 0.6025 - val_accuracy: 0.7499\n",
      "Epoch 77/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6024 - accuracy: 0.7500 - val_loss: 0.6025 - val_accuracy: 0.7497\n",
      "Epoch 78/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6022 - accuracy: 0.7503 - val_loss: 0.6031 - val_accuracy: 0.7510\n",
      "Epoch 79/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6021 - accuracy: 0.7504 - val_loss: 0.6021 - val_accuracy: 0.7509\n",
      "Epoch 80/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6018 - accuracy: 0.7500 - val_loss: 0.6020 - val_accuracy: 0.7497\n",
      "Epoch 81/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6017 - accuracy: 0.7504 - val_loss: 0.6019 - val_accuracy: 0.7505\n",
      "Epoch 82/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6015 - accuracy: 0.7506 - val_loss: 0.6023 - val_accuracy: 0.7505\n",
      "Epoch 83/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6014 - accuracy: 0.7502 - val_loss: 0.6016 - val_accuracy: 0.7501\n",
      "Epoch 84/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6013 - accuracy: 0.7502 - val_loss: 0.6026 - val_accuracy: 0.7504\n",
      "Epoch 85/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6010 - accuracy: 0.7503 - val_loss: 0.6018 - val_accuracy: 0.7505\n",
      "Epoch 86/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6010 - accuracy: 0.7503 - val_loss: 0.6017 - val_accuracy: 0.7484\n",
      "Epoch 87/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6008 - accuracy: 0.7505 - val_loss: 0.6010 - val_accuracy: 0.7490\n",
      "Epoch 88/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6007 - accuracy: 0.7507 - val_loss: 0.6010 - val_accuracy: 0.7493\n",
      "Epoch 89/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6006 - accuracy: 0.7505 - val_loss: 0.6019 - val_accuracy: 0.7512\n",
      "Epoch 90/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6004 - accuracy: 0.7508 - val_loss: 0.6008 - val_accuracy: 0.7486\n",
      "Epoch 91/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6002 - accuracy: 0.7502 - val_loss: 0.6008 - val_accuracy: 0.7498\n",
      "Epoch 92/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6000 - accuracy: 0.7504 - val_loss: 0.6000 - val_accuracy: 0.7495\n",
      "Epoch 93/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6000 - accuracy: 0.7505 - val_loss: 0.6000 - val_accuracy: 0.7493\n",
      "Epoch 94/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5999 - accuracy: 0.7505 - val_loss: 0.6012 - val_accuracy: 0.7512\n",
      "Epoch 95/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5997 - accuracy: 0.7504 - val_loss: 0.5996 - val_accuracy: 0.7494\n",
      "Epoch 96/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5996 - accuracy: 0.7505 - val_loss: 0.6010 - val_accuracy: 0.7514\n",
      "Epoch 97/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5995 - accuracy: 0.7505 - val_loss: 0.5995 - val_accuracy: 0.7495\n",
      "Epoch 98/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5993 - accuracy: 0.7509 - val_loss: 0.6009 - val_accuracy: 0.7514\n",
      "Epoch 99/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5991 - accuracy: 0.7506 - val_loss: 0.5993 - val_accuracy: 0.7498\n",
      "Epoch 100/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5992 - accuracy: 0.7507 - val_loss: 0.5990 - val_accuracy: 0.7504\n",
      "Epoch 101/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5990 - accuracy: 0.7505 - val_loss: 0.6006 - val_accuracy: 0.7476\n",
      "Epoch 102/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5989 - accuracy: 0.7504 - val_loss: 0.5988 - val_accuracy: 0.7508\n",
      "Epoch 103/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5987 - accuracy: 0.7508 - val_loss: 0.5992 - val_accuracy: 0.7509\n",
      "Epoch 104/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5986 - accuracy: 0.7503 - val_loss: 0.5985 - val_accuracy: 0.7499\n",
      "Epoch 105/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5985 - accuracy: 0.7507 - val_loss: 0.5989 - val_accuracy: 0.7489\n",
      "Epoch 106/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5984 - accuracy: 0.7508 - val_loss: 0.5982 - val_accuracy: 0.7503\n",
      "Epoch 107/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5982 - accuracy: 0.7502 - val_loss: 0.5989 - val_accuracy: 0.7483\n",
      "Epoch 108/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5981 - accuracy: 0.7505 - val_loss: 0.5983 - val_accuracy: 0.7506\n",
      "Epoch 109/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5980 - accuracy: 0.7504 - val_loss: 0.5993 - val_accuracy: 0.7480\n",
      "Epoch 110/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5980 - accuracy: 0.7508 - val_loss: 0.5984 - val_accuracy: 0.7489\n",
      "Epoch 111/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5978 - accuracy: 0.7507 - val_loss: 0.5983 - val_accuracy: 0.7511\n",
      "Epoch 112/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5978 - accuracy: 0.7506 - val_loss: 0.5983 - val_accuracy: 0.7492\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5976 - accuracy: 0.7507 - val_loss: 0.5980 - val_accuracy: 0.7489\n",
      "Epoch 114/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5975 - accuracy: 0.7505 - val_loss: 0.5977 - val_accuracy: 0.7505\n",
      "Epoch 115/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5974 - accuracy: 0.7509 - val_loss: 0.5979 - val_accuracy: 0.7485\n",
      "Epoch 116/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5972 - accuracy: 0.7508 - val_loss: 0.5993 - val_accuracy: 0.7515\n",
      "Epoch 117/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5972 - accuracy: 0.7507 - val_loss: 0.5975 - val_accuracy: 0.7508\n",
      "Epoch 118/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5971 - accuracy: 0.7507 - val_loss: 0.5977 - val_accuracy: 0.7486\n",
      "Epoch 119/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5971 - accuracy: 0.7506 - val_loss: 0.5976 - val_accuracy: 0.7508\n",
      "Epoch 120/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5969 - accuracy: 0.7506 - val_loss: 0.5973 - val_accuracy: 0.7510\n",
      "Epoch 121/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5968 - accuracy: 0.7511 - val_loss: 0.5976 - val_accuracy: 0.7492\n",
      "Epoch 122/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5967 - accuracy: 0.7504 - val_loss: 0.5977 - val_accuracy: 0.7484\n",
      "Epoch 123/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5965 - accuracy: 0.7506 - val_loss: 0.6011 - val_accuracy: 0.7450\n",
      "Epoch 124/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5965 - accuracy: 0.7510 - val_loss: 0.5964 - val_accuracy: 0.7508\n",
      "Epoch 125/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5964 - accuracy: 0.7504 - val_loss: 0.5980 - val_accuracy: 0.7516\n",
      "Epoch 126/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5964 - accuracy: 0.7505 - val_loss: 0.5973 - val_accuracy: 0.7513\n",
      "Epoch 127/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5963 - accuracy: 0.7508 - val_loss: 0.5979 - val_accuracy: 0.7512\n",
      "Epoch 128/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5961 - accuracy: 0.7508 - val_loss: 0.5976 - val_accuracy: 0.7515\n",
      "Epoch 129/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5961 - accuracy: 0.7505 - val_loss: 0.5962 - val_accuracy: 0.7502\n",
      "Epoch 130/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5959 - accuracy: 0.7510 - val_loss: 0.5960 - val_accuracy: 0.7507\n",
      "Epoch 131/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5960 - accuracy: 0.7509 - val_loss: 0.5959 - val_accuracy: 0.7509\n",
      "Epoch 132/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5958 - accuracy: 0.7508 - val_loss: 0.5958 - val_accuracy: 0.7502\n",
      "Epoch 133/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5957 - accuracy: 0.7510 - val_loss: 0.5958 - val_accuracy: 0.7510\n",
      "Epoch 134/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5957 - accuracy: 0.7509 - val_loss: 0.5959 - val_accuracy: 0.7506\n",
      "Epoch 135/200\n",
      "2498/2498 [==============================] - 2s 989us/step - loss: 0.5956 - accuracy: 0.7506 - val_loss: 0.5962 - val_accuracy: 0.7510\n",
      "Epoch 136/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5954 - accuracy: 0.7506 - val_loss: 0.5974 - val_accuracy: 0.7514\n",
      "Epoch 137/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5954 - accuracy: 0.7508 - val_loss: 0.5971 - val_accuracy: 0.7472\n",
      "Epoch 138/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5954 - accuracy: 0.7506 - val_loss: 0.5952 - val_accuracy: 0.7504\n",
      "Epoch 139/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5952 - accuracy: 0.7509 - val_loss: 0.5986 - val_accuracy: 0.7517\n",
      "Epoch 140/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5951 - accuracy: 0.7511 - val_loss: 0.5957 - val_accuracy: 0.7501\n",
      "Epoch 141/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5951 - accuracy: 0.7507 - val_loss: 0.5948 - val_accuracy: 0.7499\n",
      "Epoch 142/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5950 - accuracy: 0.7507 - val_loss: 0.5966 - val_accuracy: 0.7481\n",
      "Epoch 143/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5950 - accuracy: 0.7505 - val_loss: 0.5962 - val_accuracy: 0.7512\n",
      "Epoch 144/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5949 - accuracy: 0.7508 - val_loss: 0.5977 - val_accuracy: 0.7465\n",
      "Epoch 145/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5948 - accuracy: 0.7508 - val_loss: 0.5957 - val_accuracy: 0.7481\n",
      "Epoch 146/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5948 - accuracy: 0.7505 - val_loss: 0.5960 - val_accuracy: 0.7514\n",
      "Epoch 147/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5946 - accuracy: 0.7509 - val_loss: 0.5942 - val_accuracy: 0.7505\n",
      "Epoch 148/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5945 - accuracy: 0.7512 - val_loss: 0.5954 - val_accuracy: 0.7517\n",
      "Epoch 149/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5945 - accuracy: 0.7511 - val_loss: 0.5949 - val_accuracy: 0.7492\n",
      "Epoch 150/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5944 - accuracy: 0.7504 - val_loss: 0.6006 - val_accuracy: 0.7441\n",
      "Epoch 151/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5943 - accuracy: 0.7509 - val_loss: 0.5946 - val_accuracy: 0.7514\n",
      "Epoch 152/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5943 - accuracy: 0.7512 - val_loss: 0.5951 - val_accuracy: 0.7483\n",
      "Epoch 153/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5942 - accuracy: 0.7511 - val_loss: 0.5960 - val_accuracy: 0.7505\n",
      "Epoch 154/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5941 - accuracy: 0.7508 - val_loss: 0.5955 - val_accuracy: 0.7514\n",
      "Epoch 155/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5941 - accuracy: 0.7509 - val_loss: 0.5948 - val_accuracy: 0.7493\n",
      "Epoch 156/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5940 - accuracy: 0.7511 - val_loss: 0.5940 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5939 - accuracy: 0.7511 - val_loss: 0.5939 - val_accuracy: 0.7496\n",
      "Epoch 158/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5938 - accuracy: 0.7510 - val_loss: 0.5946 - val_accuracy: 0.7488\n",
      "Epoch 159/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5939 - accuracy: 0.7508 - val_loss: 0.5956 - val_accuracy: 0.7515\n",
      "Epoch 160/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5938 - accuracy: 0.7507 - val_loss: 0.5947 - val_accuracy: 0.7514\n",
      "Epoch 161/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5938 - accuracy: 0.7508 - val_loss: 0.5935 - val_accuracy: 0.7498\n",
      "Epoch 162/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5936 - accuracy: 0.7512 - val_loss: 0.5933 - val_accuracy: 0.7506\n",
      "Epoch 163/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5935 - accuracy: 0.7511 - val_loss: 0.5938 - val_accuracy: 0.7497\n",
      "Epoch 164/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5935 - accuracy: 0.7507 - val_loss: 0.5939 - val_accuracy: 0.7499\n",
      "Epoch 165/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5934 - accuracy: 0.7510 - val_loss: 0.5958 - val_accuracy: 0.7479\n",
      "Epoch 166/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5934 - accuracy: 0.7513 - val_loss: 0.5937 - val_accuracy: 0.7512\n",
      "Epoch 167/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5933 - accuracy: 0.7511 - val_loss: 0.5934 - val_accuracy: 0.7514\n",
      "Epoch 168/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5932 - accuracy: 0.7512 - val_loss: 0.5930 - val_accuracy: 0.7506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5931 - accuracy: 0.7508 - val_loss: 0.5946 - val_accuracy: 0.7483\n",
      "Epoch 170/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5931 - accuracy: 0.7509 - val_loss: 0.6003 - val_accuracy: 0.7521\n",
      "Epoch 171/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5931 - accuracy: 0.7513 - val_loss: 0.5936 - val_accuracy: 0.7518\n",
      "Epoch 172/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.7512 - val_loss: 0.5938 - val_accuracy: 0.7511\n",
      "Epoch 173/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.7510 - val_loss: 0.5931 - val_accuracy: 0.7511\n",
      "Epoch 174/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5929 - accuracy: 0.7510 - val_loss: 0.5931 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5928 - accuracy: 0.7512 - val_loss: 0.5935 - val_accuracy: 0.7491\n",
      "Epoch 176/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5927 - accuracy: 0.7510 - val_loss: 0.5925 - val_accuracy: 0.7499\n",
      "Epoch 177/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5928 - accuracy: 0.7511 - val_loss: 0.5938 - val_accuracy: 0.7521\n",
      "Epoch 178/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5926 - accuracy: 0.7511 - val_loss: 0.5932 - val_accuracy: 0.7514\n",
      "Epoch 179/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5926 - accuracy: 0.7512 - val_loss: 0.5926 - val_accuracy: 0.7502\n",
      "Epoch 180/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5926 - accuracy: 0.7509 - val_loss: 0.5925 - val_accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5925 - accuracy: 0.7512 - val_loss: 0.5924 - val_accuracy: 0.7502\n",
      "Epoch 182/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5924 - accuracy: 0.7514 - val_loss: 0.5930 - val_accuracy: 0.7507\n",
      "Epoch 183/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5924 - accuracy: 0.7509 - val_loss: 0.5927 - val_accuracy: 0.7498\n",
      "Epoch 184/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5924 - accuracy: 0.7508 - val_loss: 0.5931 - val_accuracy: 0.7515\n",
      "Epoch 185/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5921 - accuracy: 0.7515 - val_loss: 0.5954 - val_accuracy: 0.7467\n",
      "Epoch 186/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5922 - accuracy: 0.7514 - val_loss: 0.5973 - val_accuracy: 0.7455\n",
      "Epoch 187/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5922 - accuracy: 0.7513 - val_loss: 0.5930 - val_accuracy: 0.7516\n",
      "Epoch 188/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5921 - accuracy: 0.7513 - val_loss: 0.5926 - val_accuracy: 0.7521\n",
      "Epoch 189/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5921 - accuracy: 0.7505 - val_loss: 0.5921 - val_accuracy: 0.7493\n",
      "Epoch 190/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5920 - accuracy: 0.7511 - val_loss: 0.5916 - val_accuracy: 0.7514\n",
      "Epoch 191/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5919 - accuracy: 0.7513 - val_loss: 0.5930 - val_accuracy: 0.7503\n",
      "Epoch 192/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5918 - accuracy: 0.7515 - val_loss: 0.5931 - val_accuracy: 0.7503\n",
      "Epoch 193/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5918 - accuracy: 0.7513 - val_loss: 0.5923 - val_accuracy: 0.7512\n",
      "Epoch 194/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5918 - accuracy: 0.7511 - val_loss: 0.5921 - val_accuracy: 0.7519\n",
      "Epoch 195/200\n",
      "2498/2498 [==============================] - 2s 922us/step - loss: 0.5917 - accuracy: 0.7510 - val_loss: 0.5921 - val_accuracy: 0.7507\n",
      "Epoch 196/200\n",
      "2498/2498 [==============================] - 2s 934us/step - loss: 0.5917 - accuracy: 0.7511 - val_loss: 0.5926 - val_accuracy: 0.7498\n",
      "Epoch 197/200\n",
      "2498/2498 [==============================] - 2s 979us/step - loss: 0.5917 - accuracy: 0.7515 - val_loss: 0.5946 - val_accuracy: 0.7525\n",
      "Epoch 198/200\n",
      "2498/2498 [==============================] - 2s 976us/step - loss: 0.5916 - accuracy: 0.7510 - val_loss: 0.5924 - val_accuracy: 0.7496\n",
      "Epoch 199/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5915 - accuracy: 0.7512 - val_loss: 0.5943 - val_accuracy: 0.7473\n",
      "Epoch 200/200\n",
      "2498/2498 [==============================] - 2s 832us/step - loss: 0.5915 - accuracy: 0.7510 - val_loss: 0.5968 - val_accuracy: 0.7510\n",
      "4441/4441 [==============================] - 3s 589us/step - loss: 1.2726 - accuracy: 0.4495\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x0000019CAD688D30>\n",
      "Epoch Sizes:  200\n",
      "Neurons or Units:  128\n",
      "Test score: 1.2726391553878784\n",
      "Test accuracy: 0.44945669174194336\n",
      "\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,667\n",
      "Trainable params: 4,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2495/2498 [============================>.] - ETA: 0s - loss: 1.0080 - accuracy: 0.6862WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0011s). Check your callbacks.\n",
      "2498/2498 [==============================] - 2s 860us/step - loss: 1.0078 - accuracy: 0.6862 - val_loss: 0.8180 - val_accuracy: 0.7337\n",
      "Epoch 2/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.7613 - accuracy: 0.7387 - val_loss: 0.7225 - val_accuracy: 0.7407\n",
      "Epoch 3/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.7022 - accuracy: 0.7423 - val_loss: 0.6864 - val_accuracy: 0.7442\n",
      "Epoch 4/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6767 - accuracy: 0.7438 - val_loss: 0.6691 - val_accuracy: 0.7453\n",
      "Epoch 5/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6636 - accuracy: 0.7447 - val_loss: 0.6592 - val_accuracy: 0.7434\n",
      "Epoch 6/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6558 - accuracy: 0.7452 - val_loss: 0.6528 - val_accuracy: 0.7464\n",
      "Epoch 7/200\n",
      "2498/2498 [==============================] - 2s 989us/step - loss: 0.6505 - accuracy: 0.7455 - val_loss: 0.6483 - val_accuracy: 0.7468\n",
      "Epoch 8/200\n",
      "2498/2498 [==============================] - 2s 986us/step - loss: 0.6465 - accuracy: 0.7460 - val_loss: 0.6450 - val_accuracy: 0.7439\n",
      "Epoch 9/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6433 - accuracy: 0.7464 - val_loss: 0.6417 - val_accuracy: 0.7460\n",
      "Epoch 10/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6406 - accuracy: 0.7464 - val_loss: 0.6393 - val_accuracy: 0.7458\n",
      "Epoch 11/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6382 - accuracy: 0.7468 - val_loss: 0.6371 - val_accuracy: 0.7457\n",
      "Epoch 12/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6361 - accuracy: 0.7469 - val_loss: 0.6351 - val_accuracy: 0.7463\n",
      "Epoch 13/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6342 - accuracy: 0.7469 - val_loss: 0.6332 - val_accuracy: 0.7468\n",
      "Epoch 14/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6325 - accuracy: 0.7472 - val_loss: 0.6319 - val_accuracy: 0.7477\n",
      "Epoch 15/200\n",
      "2498/2498 [==============================] - 2s 979us/step - loss: 0.6309 - accuracy: 0.7475 - val_loss: 0.6304 - val_accuracy: 0.7475\n",
      "Epoch 16/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6295 - accuracy: 0.7475 - val_loss: 0.6292 - val_accuracy: 0.7462\n",
      "Epoch 17/200\n",
      "2498/2498 [==============================] - 2s 985us/step - loss: 0.6282 - accuracy: 0.7475 - val_loss: 0.6282 - val_accuracy: 0.7486\n",
      "Epoch 18/200\n",
      "2498/2498 [==============================] - 2s 980us/step - loss: 0.6270 - accuracy: 0.7479 - val_loss: 0.6264 - val_accuracy: 0.7469\n",
      "Epoch 19/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6259 - accuracy: 0.7478 - val_loss: 0.6255 - val_accuracy: 0.7473\n",
      "Epoch 20/200\n",
      "2498/2498 [==============================] - 2s 835us/step - loss: 0.6248 - accuracy: 0.7480 - val_loss: 0.6246 - val_accuracy: 0.7483\n",
      "Epoch 21/200\n",
      "2498/2498 [==============================] - 2s 952us/step - loss: 0.6239 - accuracy: 0.7479 - val_loss: 0.6245 - val_accuracy: 0.7454\n",
      "Epoch 22/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6230 - accuracy: 0.7481 - val_loss: 0.6230 - val_accuracy: 0.7461\n",
      "Epoch 23/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6221 - accuracy: 0.7483 - val_loss: 0.6220 - val_accuracy: 0.7468\n",
      "Epoch 24/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6212 - accuracy: 0.7481 - val_loss: 0.6210 - val_accuracy: 0.7489\n",
      "Epoch 25/200\n",
      "2498/2498 [==============================] - 2s 942us/step - loss: 0.6205 - accuracy: 0.7485 - val_loss: 0.6203 - val_accuracy: 0.7473\n",
      "Epoch 26/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6198 - accuracy: 0.7487 - val_loss: 0.6200 - val_accuracy: 0.7464\n",
      "Epoch 27/200\n",
      "2498/2498 [==============================] - 2s 843us/step - loss: 0.6190 - accuracy: 0.7485 - val_loss: 0.6192 - val_accuracy: 0.7468\n",
      "Epoch 28/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6184 - accuracy: 0.7486 - val_loss: 0.6187 - val_accuracy: 0.7492\n",
      "Epoch 29/200\n",
      "2498/2498 [==============================] - 2s 1000us/step - loss: 0.6178 - accuracy: 0.7486 - val_loss: 0.6175 - val_accuracy: 0.7481\n",
      "Epoch 30/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6171 - accuracy: 0.7485 - val_loss: 0.6170 - val_accuracy: 0.7483\n",
      "Epoch 31/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6165 - accuracy: 0.7487 - val_loss: 0.6165 - val_accuracy: 0.7486\n",
      "Epoch 32/200\n",
      "2498/2498 [==============================] - 2s 920us/step - loss: 0.6160 - accuracy: 0.7488 - val_loss: 0.6165 - val_accuracy: 0.7496\n",
      "Epoch 33/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6155 - accuracy: 0.7490 - val_loss: 0.6162 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6150 - accuracy: 0.7490 - val_loss: 0.6155 - val_accuracy: 0.7499\n",
      "Epoch 35/200\n",
      "2498/2498 [==============================] - 2s 834us/step - loss: 0.6145 - accuracy: 0.7489 - val_loss: 0.6147 - val_accuracy: 0.7498\n",
      "Epoch 36/200\n",
      "2498/2498 [==============================] - 2s 903us/step - loss: 0.6140 - accuracy: 0.7490 - val_loss: 0.6140 - val_accuracy: 0.7487\n",
      "Epoch 37/200\n",
      "2498/2498 [==============================] - 2s 894us/step - loss: 0.6136 - accuracy: 0.7490 - val_loss: 0.6136 - val_accuracy: 0.7482\n",
      "Epoch 38/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6131 - accuracy: 0.7490 - val_loss: 0.6132 - val_accuracy: 0.7482\n",
      "Epoch 39/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6127 - accuracy: 0.7493 - val_loss: 0.6127 - val_accuracy: 0.7493\n",
      "Epoch 40/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6123 - accuracy: 0.7491 - val_loss: 0.6124 - val_accuracy: 0.7486\n",
      "Epoch 41/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6118 - accuracy: 0.7492 - val_loss: 0.6118 - val_accuracy: 0.7490\n",
      "Epoch 42/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6115 - accuracy: 0.7493 - val_loss: 0.6133 - val_accuracy: 0.7511\n",
      "Epoch 43/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6111 - accuracy: 0.7493 - val_loss: 0.6111 - val_accuracy: 0.7491\n",
      "Epoch 44/200\n",
      "2498/2498 [==============================] - 2s 995us/step - loss: 0.6108 - accuracy: 0.7494 - val_loss: 0.6110 - val_accuracy: 0.7498\n",
      "Epoch 45/200\n",
      "2498/2498 [==============================] - 2s 866us/step - loss: 0.6105 - accuracy: 0.7496 - val_loss: 0.6108 - val_accuracy: 0.7503\n",
      "Epoch 46/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6101 - accuracy: 0.7492 - val_loss: 0.6111 - val_accuracy: 0.7464\n",
      "Epoch 47/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6097 - accuracy: 0.7496 - val_loss: 0.6100 - val_accuracy: 0.7497\n",
      "Epoch 48/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6095 - accuracy: 0.7493 - val_loss: 0.6098 - val_accuracy: 0.7473\n",
      "Epoch 49/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6091 - accuracy: 0.7496 - val_loss: 0.6097 - val_accuracy: 0.7469\n",
      "Epoch 50/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6088 - accuracy: 0.7494 - val_loss: 0.6097 - val_accuracy: 0.7501\n",
      "Epoch 51/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6086 - accuracy: 0.7496 - val_loss: 0.6085 - val_accuracy: 0.7497\n",
      "Epoch 52/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6083 - accuracy: 0.7497 - val_loss: 0.6086 - val_accuracy: 0.7478\n",
      "Epoch 53/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6080 - accuracy: 0.7494 - val_loss: 0.6080 - val_accuracy: 0.7493\n",
      "Epoch 54/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6077 - accuracy: 0.7496 - val_loss: 0.6079 - val_accuracy: 0.7495\n",
      "Epoch 55/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6075 - accuracy: 0.7498 - val_loss: 0.6079 - val_accuracy: 0.7503\n",
      "Epoch 56/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6071 - accuracy: 0.7496 - val_loss: 0.6080 - val_accuracy: 0.7505\n",
      "Epoch 57/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6069 - accuracy: 0.7499 - val_loss: 0.6084 - val_accuracy: 0.7504\n",
      "Epoch 58/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6067 - accuracy: 0.7497 - val_loss: 0.6069 - val_accuracy: 0.7484\n",
      "Epoch 59/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6065 - accuracy: 0.7498 - val_loss: 0.6068 - val_accuracy: 0.7498\n",
      "Epoch 60/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6062 - accuracy: 0.7497 - val_loss: 0.6064 - val_accuracy: 0.7495\n",
      "Epoch 61/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6059 - accuracy: 0.7500 - val_loss: 0.6062 - val_accuracy: 0.7494\n",
      "Epoch 62/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6057 - accuracy: 0.7496 - val_loss: 0.6057 - val_accuracy: 0.7494\n",
      "Epoch 63/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6055 - accuracy: 0.7500 - val_loss: 0.6062 - val_accuracy: 0.7505\n",
      "Epoch 64/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6053 - accuracy: 0.7501 - val_loss: 0.6058 - val_accuracy: 0.7503\n",
      "Epoch 65/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6051 - accuracy: 0.7498 - val_loss: 0.6053 - val_accuracy: 0.7492\n",
      "Epoch 66/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6049 - accuracy: 0.7502 - val_loss: 0.6069 - val_accuracy: 0.7508\n",
      "Epoch 67/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6046 - accuracy: 0.7497 - val_loss: 0.6054 - val_accuracy: 0.7508\n",
      "Epoch 68/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6045 - accuracy: 0.7498 - val_loss: 0.6055 - val_accuracy: 0.7473\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6043 - accuracy: 0.7500 - val_loss: 0.6043 - val_accuracy: 0.7491\n",
      "Epoch 70/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6041 - accuracy: 0.7499 - val_loss: 0.6041 - val_accuracy: 0.7498\n",
      "Epoch 71/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6038 - accuracy: 0.7499 - val_loss: 0.6051 - val_accuracy: 0.7497\n",
      "Epoch 72/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6037 - accuracy: 0.7498 - val_loss: 0.6041 - val_accuracy: 0.7480\n",
      "Epoch 73/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6036 - accuracy: 0.7502 - val_loss: 0.6041 - val_accuracy: 0.7482\n",
      "Epoch 74/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6033 - accuracy: 0.7501 - val_loss: 0.6045 - val_accuracy: 0.7508\n",
      "Epoch 75/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6032 - accuracy: 0.7502 - val_loss: 0.6032 - val_accuracy: 0.7499\n",
      "Epoch 76/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6030 - accuracy: 0.7501 - val_loss: 0.6031 - val_accuracy: 0.7499\n",
      "Epoch 77/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6028 - accuracy: 0.7503 - val_loss: 0.6044 - val_accuracy: 0.7472\n",
      "Epoch 78/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6027 - accuracy: 0.7501 - val_loss: 0.6027 - val_accuracy: 0.7490\n",
      "Epoch 79/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6025 - accuracy: 0.7501 - val_loss: 0.6023 - val_accuracy: 0.7501\n",
      "Epoch 80/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6023 - accuracy: 0.7502 - val_loss: 0.6025 - val_accuracy: 0.7488\n",
      "Epoch 81/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6022 - accuracy: 0.7503 - val_loss: 0.6022 - val_accuracy: 0.7501\n",
      "Epoch 82/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6020 - accuracy: 0.7502 - val_loss: 0.6019 - val_accuracy: 0.7499\n",
      "Epoch 83/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6018 - accuracy: 0.7501 - val_loss: 0.6029 - val_accuracy: 0.7512\n",
      "Epoch 84/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6017 - accuracy: 0.7496 - val_loss: 0.6021 - val_accuracy: 0.7500\n",
      "Epoch 85/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6016 - accuracy: 0.7503 - val_loss: 0.6017 - val_accuracy: 0.7506\n",
      "Epoch 86/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6015 - accuracy: 0.7501 - val_loss: 0.6028 - val_accuracy: 0.7469\n",
      "Epoch 87/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6013 - accuracy: 0.7499 - val_loss: 0.6040 - val_accuracy: 0.7516\n",
      "Epoch 88/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6011 - accuracy: 0.7502 - val_loss: 0.6013 - val_accuracy: 0.7489\n",
      "Epoch 89/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6010 - accuracy: 0.7503 - val_loss: 0.6017 - val_accuracy: 0.7479\n",
      "Epoch 90/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6008 - accuracy: 0.7505 - val_loss: 0.6010 - val_accuracy: 0.7501\n",
      "Epoch 91/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6008 - accuracy: 0.7502 - val_loss: 0.6014 - val_accuracy: 0.7507\n",
      "Epoch 92/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6006 - accuracy: 0.7500 - val_loss: 0.6007 - val_accuracy: 0.7505\n",
      "Epoch 93/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6005 - accuracy: 0.7505 - val_loss: 0.6004 - val_accuracy: 0.7495\n",
      "Epoch 94/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6003 - accuracy: 0.7501 - val_loss: 0.6013 - val_accuracy: 0.7514\n",
      "Epoch 95/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6002 - accuracy: 0.7504 - val_loss: 0.6013 - val_accuracy: 0.7504\n",
      "Epoch 96/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6001 - accuracy: 0.7502 - val_loss: 0.5999 - val_accuracy: 0.7505\n",
      "Epoch 97/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6001 - accuracy: 0.7504 - val_loss: 0.6002 - val_accuracy: 0.7495\n",
      "Epoch 98/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5998 - accuracy: 0.7504 - val_loss: 0.5999 - val_accuracy: 0.7492\n",
      "Epoch 99/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5997 - accuracy: 0.7500 - val_loss: 0.5997 - val_accuracy: 0.7499\n",
      "Epoch 100/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5996 - accuracy: 0.7502 - val_loss: 0.6003 - val_accuracy: 0.7495\n",
      "Epoch 101/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5995 - accuracy: 0.7505 - val_loss: 0.6009 - val_accuracy: 0.7513\n",
      "Epoch 102/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5994 - accuracy: 0.7506 - val_loss: 0.5996 - val_accuracy: 0.7485\n",
      "Epoch 103/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5992 - accuracy: 0.7501 - val_loss: 0.5994 - val_accuracy: 0.7495\n",
      "Epoch 104/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5992 - accuracy: 0.7506 - val_loss: 0.6010 - val_accuracy: 0.7520\n",
      "Epoch 105/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5990 - accuracy: 0.7501 - val_loss: 0.6024 - val_accuracy: 0.7461\n",
      "Epoch 106/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5989 - accuracy: 0.7502 - val_loss: 0.6011 - val_accuracy: 0.7511\n",
      "Epoch 107/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5987 - accuracy: 0.7503 - val_loss: 0.6009 - val_accuracy: 0.7509\n",
      "Epoch 108/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5987 - accuracy: 0.7503 - val_loss: 0.5988 - val_accuracy: 0.7500\n",
      "Epoch 109/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5985 - accuracy: 0.7505 - val_loss: 0.5989 - val_accuracy: 0.7505\n",
      "Epoch 110/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5985 - accuracy: 0.7502 - val_loss: 0.5986 - val_accuracy: 0.7508\n",
      "Epoch 111/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5984 - accuracy: 0.7504 - val_loss: 0.5991 - val_accuracy: 0.7475\n",
      "Epoch 112/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5982 - accuracy: 0.7508 - val_loss: 0.5983 - val_accuracy: 0.7492\n",
      "Epoch 113/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5981 - accuracy: 0.7504 - val_loss: 0.5983 - val_accuracy: 0.7489\n",
      "Epoch 114/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5980 - accuracy: 0.7508 - val_loss: 0.5984 - val_accuracy: 0.7503\n",
      "Epoch 115/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5979 - accuracy: 0.7506 - val_loss: 0.5979 - val_accuracy: 0.7498\n",
      "Epoch 116/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5979 - accuracy: 0.7505 - val_loss: 0.5984 - val_accuracy: 0.7508\n",
      "Epoch 117/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5977 - accuracy: 0.7505 - val_loss: 0.5979 - val_accuracy: 0.7504\n",
      "Epoch 118/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5976 - accuracy: 0.7508 - val_loss: 0.5976 - val_accuracy: 0.7494\n",
      "Epoch 119/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5976 - accuracy: 0.7505 - val_loss: 0.5987 - val_accuracy: 0.7499\n",
      "Epoch 120/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5975 - accuracy: 0.7509 - val_loss: 0.5988 - val_accuracy: 0.7486\n",
      "Epoch 121/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5973 - accuracy: 0.7505 - val_loss: 0.5976 - val_accuracy: 0.7495\n",
      "Epoch 122/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5974 - accuracy: 0.7507 - val_loss: 0.5972 - val_accuracy: 0.7502\n",
      "Epoch 123/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5972 - accuracy: 0.7502 - val_loss: 0.5977 - val_accuracy: 0.7509\n",
      "Epoch 124/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5971 - accuracy: 0.7506 - val_loss: 0.5974 - val_accuracy: 0.7488\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5969 - accuracy: 0.7507 - val_loss: 0.5976 - val_accuracy: 0.7506\n",
      "Epoch 126/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5969 - accuracy: 0.7506 - val_loss: 0.5968 - val_accuracy: 0.7506\n",
      "Epoch 127/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5968 - accuracy: 0.7504 - val_loss: 0.5965 - val_accuracy: 0.7504\n",
      "Epoch 128/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5967 - accuracy: 0.7505 - val_loss: 0.5967 - val_accuracy: 0.7497\n",
      "Epoch 129/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5967 - accuracy: 0.7503 - val_loss: 0.5967 - val_accuracy: 0.7494\n",
      "Epoch 130/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5965 - accuracy: 0.7505 - val_loss: 0.5975 - val_accuracy: 0.7514\n",
      "Epoch 131/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5965 - accuracy: 0.7510 - val_loss: 0.5998 - val_accuracy: 0.7457\n",
      "Epoch 132/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5963 - accuracy: 0.7507 - val_loss: 0.5964 - val_accuracy: 0.7497\n",
      "Epoch 133/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5963 - accuracy: 0.7503 - val_loss: 0.5960 - val_accuracy: 0.7505\n",
      "Epoch 134/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5962 - accuracy: 0.7508 - val_loss: 0.5975 - val_accuracy: 0.7510\n",
      "Epoch 135/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5962 - accuracy: 0.7508 - val_loss: 0.5959 - val_accuracy: 0.7506\n",
      "Epoch 136/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5960 - accuracy: 0.7506 - val_loss: 0.5960 - val_accuracy: 0.7502\n",
      "Epoch 137/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5960 - accuracy: 0.7505 - val_loss: 0.5959 - val_accuracy: 0.7501\n",
      "Epoch 138/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5959 - accuracy: 0.7504 - val_loss: 0.5964 - val_accuracy: 0.7487\n",
      "Epoch 139/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5958 - accuracy: 0.7506 - val_loss: 0.5971 - val_accuracy: 0.7484\n",
      "Epoch 140/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5956 - accuracy: 0.7509 - val_loss: 0.5970 - val_accuracy: 0.7518\n",
      "Epoch 141/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5957 - accuracy: 0.7505 - val_loss: 0.5956 - val_accuracy: 0.7504\n",
      "Epoch 142/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5956 - accuracy: 0.7509 - val_loss: 0.5955 - val_accuracy: 0.7505\n",
      "Epoch 143/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5956 - accuracy: 0.7506 - val_loss: 0.5956 - val_accuracy: 0.7508\n",
      "Epoch 144/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5954 - accuracy: 0.7509 - val_loss: 0.5956 - val_accuracy: 0.7507\n",
      "Epoch 145/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5953 - accuracy: 0.7508 - val_loss: 0.5954 - val_accuracy: 0.7506\n",
      "Epoch 146/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5953 - accuracy: 0.7507 - val_loss: 0.5964 - val_accuracy: 0.7515\n",
      "Epoch 147/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5952 - accuracy: 0.7509 - val_loss: 0.5958 - val_accuracy: 0.7510\n",
      "Epoch 148/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5952 - accuracy: 0.7507 - val_loss: 0.5969 - val_accuracy: 0.7480\n",
      "Epoch 149/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5950 - accuracy: 0.7510 - val_loss: 0.5950 - val_accuracy: 0.7510\n",
      "Epoch 150/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5949 - accuracy: 0.7507 - val_loss: 0.5953 - val_accuracy: 0.7489\n",
      "Epoch 151/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5949 - accuracy: 0.7510 - val_loss: 0.5973 - val_accuracy: 0.7509\n",
      "Epoch 152/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5948 - accuracy: 0.7509 - val_loss: 0.5954 - val_accuracy: 0.7516\n",
      "Epoch 153/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5947 - accuracy: 0.7507 - val_loss: 0.5942 - val_accuracy: 0.7507\n",
      "Epoch 154/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5947 - accuracy: 0.7507 - val_loss: 0.5945 - val_accuracy: 0.7505\n",
      "Epoch 155/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5946 - accuracy: 0.7510 - val_loss: 0.5953 - val_accuracy: 0.7489\n",
      "Epoch 156/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5945 - accuracy: 0.7505 - val_loss: 0.5982 - val_accuracy: 0.7468\n",
      "Epoch 157/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5945 - accuracy: 0.7508 - val_loss: 0.5958 - val_accuracy: 0.7489\n",
      "Epoch 158/200\n",
      "2498/2498 [==============================] - 2s 949us/step - loss: 0.5944 - accuracy: 0.7507 - val_loss: 0.5945 - val_accuracy: 0.7502\n",
      "Epoch 159/200\n",
      "2498/2498 [==============================] - 2s 881us/step - loss: 0.5944 - accuracy: 0.7507 - val_loss: 0.5951 - val_accuracy: 0.7502\n",
      "Epoch 160/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5943 - accuracy: 0.7511 - val_loss: 0.5955 - val_accuracy: 0.7482\n",
      "Epoch 161/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5942 - accuracy: 0.7508 - val_loss: 0.5955 - val_accuracy: 0.7508\n",
      "Epoch 162/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5942 - accuracy: 0.7507 - val_loss: 0.5942 - val_accuracy: 0.7514\n",
      "Epoch 163/200\n",
      "2498/2498 [==============================] - 2s 963us/step - loss: 0.5941 - accuracy: 0.7509 - val_loss: 0.5949 - val_accuracy: 0.7517\n",
      "Epoch 164/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5940 - accuracy: 0.7509 - val_loss: 0.5937 - val_accuracy: 0.7505\n",
      "Epoch 165/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5940 - accuracy: 0.7509 - val_loss: 0.5939 - val_accuracy: 0.7503\n",
      "Epoch 166/200\n",
      "2498/2498 [==============================] - 2s 991us/step - loss: 0.5940 - accuracy: 0.7507 - val_loss: 0.5946 - val_accuracy: 0.7487\n",
      "Epoch 167/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5938 - accuracy: 0.7511 - val_loss: 0.5942 - val_accuracy: 0.7511\n",
      "Epoch 168/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5939 - accuracy: 0.7507 - val_loss: 0.5933 - val_accuracy: 0.7504\n",
      "Epoch 169/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5937 - accuracy: 0.7507 - val_loss: 0.5935 - val_accuracy: 0.7501\n",
      "Epoch 170/200\n",
      "2498/2498 [==============================] - 2s 894us/step - loss: 0.5937 - accuracy: 0.7507 - val_loss: 0.5941 - val_accuracy: 0.7498\n",
      "Epoch 171/200\n",
      "2498/2498 [==============================] - 2s 914us/step - loss: 0.5937 - accuracy: 0.7507 - val_loss: 0.5941 - val_accuracy: 0.7490\n",
      "Epoch 172/200\n",
      "2498/2498 [==============================] - 2s 931us/step - loss: 0.5936 - accuracy: 0.7508 - val_loss: 0.5937 - val_accuracy: 0.7515\n",
      "Epoch 173/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5935 - accuracy: 0.7510 - val_loss: 0.5934 - val_accuracy: 0.7497\n",
      "Epoch 174/200\n",
      "2498/2498 [==============================] - 2s 920us/step - loss: 0.5935 - accuracy: 0.7508 - val_loss: 0.5939 - val_accuracy: 0.7489\n",
      "Epoch 175/200\n",
      "2498/2498 [==============================] - 2s 927us/step - loss: 0.5933 - accuracy: 0.7507 - val_loss: 0.5931 - val_accuracy: 0.7511\n",
      "Epoch 176/200\n",
      "2498/2498 [==============================] - 2s 901us/step - loss: 0.5934 - accuracy: 0.7508 - val_loss: 0.5932 - val_accuracy: 0.7505\n",
      "Epoch 177/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5933 - accuracy: 0.7507 - val_loss: 0.5957 - val_accuracy: 0.7469\n",
      "Epoch 178/200\n",
      "2498/2498 [==============================] - 2s 924us/step - loss: 0.5932 - accuracy: 0.7510 - val_loss: 0.5930 - val_accuracy: 0.7514\n",
      "Epoch 179/200\n",
      "2498/2498 [==============================] - 2s 907us/step - loss: 0.5933 - accuracy: 0.7510 - val_loss: 0.5929 - val_accuracy: 0.7511\n",
      "Epoch 180/200\n",
      "2498/2498 [==============================] - 2s 859us/step - loss: 0.5931 - accuracy: 0.7508 - val_loss: 0.5932 - val_accuracy: 0.7503\n",
      "Epoch 181/200\n",
      "2498/2498 [==============================] - 2s 869us/step - loss: 0.5931 - accuracy: 0.7506 - val_loss: 0.5963 - val_accuracy: 0.7524\n",
      "Epoch 182/200\n",
      "2498/2498 [==============================] - 2s 854us/step - loss: 0.5931 - accuracy: 0.7507 - val_loss: 0.5925 - val_accuracy: 0.7508\n",
      "Epoch 183/200\n",
      "2498/2498 [==============================] - 2s 869us/step - loss: 0.5930 - accuracy: 0.7508 - val_loss: 0.5931 - val_accuracy: 0.7509\n",
      "Epoch 184/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.7508 - val_loss: 0.5928 - val_accuracy: 0.7503\n",
      "Epoch 185/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5929 - accuracy: 0.7505 - val_loss: 0.5940 - val_accuracy: 0.7486\n",
      "Epoch 186/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5928 - accuracy: 0.7508 - val_loss: 0.5929 - val_accuracy: 0.7493\n",
      "Epoch 187/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5927 - accuracy: 0.7508 - val_loss: 0.5942 - val_accuracy: 0.7478\n",
      "Epoch 188/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5928 - accuracy: 0.7512 - val_loss: 0.5924 - val_accuracy: 0.7505\n",
      "Epoch 189/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5927 - accuracy: 0.7508 - val_loss: 0.5925 - val_accuracy: 0.7507\n",
      "Epoch 190/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5925 - accuracy: 0.7511 - val_loss: 0.5955 - val_accuracy: 0.7515\n",
      "Epoch 191/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5925 - accuracy: 0.7511 - val_loss: 0.5945 - val_accuracy: 0.7478\n",
      "Epoch 192/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5926 - accuracy: 0.7511 - val_loss: 0.5936 - val_accuracy: 0.7486\n",
      "Epoch 193/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5925 - accuracy: 0.7508 - val_loss: 0.5919 - val_accuracy: 0.7504\n",
      "Epoch 194/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5924 - accuracy: 0.7508 - val_loss: 0.5932 - val_accuracy: 0.7507\n",
      "Epoch 195/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5923 - accuracy: 0.7509 - val_loss: 0.5932 - val_accuracy: 0.7492\n",
      "Epoch 196/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5922 - accuracy: 0.7509 - val_loss: 0.5921 - val_accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5922 - accuracy: 0.7510 - val_loss: 0.5925 - val_accuracy: 0.7511\n",
      "Epoch 198/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5922 - accuracy: 0.7509 - val_loss: 0.5921 - val_accuracy: 0.7506\n",
      "Epoch 199/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5922 - accuracy: 0.7508 - val_loss: 0.5933 - val_accuracy: 0.7484\n",
      "Epoch 200/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5920 - accuracy: 0.7510 - val_loss: 0.5969 - val_accuracy: 0.7457\n",
      "4441/4441 [==============================] - 3s 639us/step - loss: 1.2670 - accuracy: 0.4585\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x0000019CAD688D30>\n",
      "Epoch Sizes:  200\n",
      "Neurons or Units:  256\n",
      "Test score: 1.266982078552246\n",
      "Test accuracy: 0.45847174525260925\n",
      "\n",
      "[0.45332029461860657, 0.45748648047447205, 0.4546433389186859, 0.4510471820831299, 0.4514060914516449, 0.45284879207611084, 0.4473735988140106, 0.44945669174194336, 0.45847174525260925]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Time 2852.6570343971252 seconds: \n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,211\n",
      "Trainable params: 1,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2498/2498 [==============================] - 2s 964us/step - loss: 0.6720 - accuracy: 0.7415 - val_loss: 0.6174 - val_accuracy: 0.7478\n",
      "Epoch 2/50\n",
      "2498/2498 [==============================] - 2s 758us/step - loss: 0.6096 - accuracy: 0.7488 - val_loss: 0.6040 - val_accuracy: 0.7466\n",
      "Epoch 3/50\n",
      "2498/2498 [==============================] - 2s 839us/step - loss: 0.6007 - accuracy: 0.7487 - val_loss: 0.6063 - val_accuracy: 0.7508\n",
      "Epoch 4/50\n",
      "2498/2498 [==============================] - 2s 982us/step - loss: 0.5960 - accuracy: 0.7500 - val_loss: 0.5960 - val_accuracy: 0.7487\n",
      "Epoch 5/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.7496 - val_loss: 0.5899 - val_accuracy: 0.7512\n",
      "Epoch 6/50\n",
      "2498/2498 [==============================] - 2s 965us/step - loss: 0.5908 - accuracy: 0.7496 - val_loss: 0.5907 - val_accuracy: 0.7494\n",
      "Epoch 7/50\n",
      "2498/2498 [==============================] - 2s 996us/step - loss: 0.5893 - accuracy: 0.7498 - val_loss: 0.5914 - val_accuracy: 0.7452\n",
      "Epoch 8/50\n",
      "2498/2498 [==============================] - 2s 974us/step - loss: 0.5878 - accuracy: 0.7502 - val_loss: 0.5857 - val_accuracy: 0.7506\n",
      "Epoch 9/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5868 - accuracy: 0.7500 - val_loss: 0.5887 - val_accuracy: 0.7508\n",
      "Epoch 10/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5859 - accuracy: 0.7498 - val_loss: 0.5983 - val_accuracy: 0.7489\n",
      "Epoch 11/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5850 - accuracy: 0.7505 - val_loss: 0.5875 - val_accuracy: 0.7458\n",
      "Epoch 12/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5843 - accuracy: 0.7500 - val_loss: 0.5828 - val_accuracy: 0.7507\n",
      "Epoch 13/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5835 - accuracy: 0.7503 - val_loss: 0.5851 - val_accuracy: 0.7519\n",
      "Epoch 14/50\n",
      "2498/2498 [==============================] - 2s 960us/step - loss: 0.5829 - accuracy: 0.7503 - val_loss: 0.5818 - val_accuracy: 0.7488\n",
      "Epoch 15/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5823 - accuracy: 0.7505 - val_loss: 0.5812 - val_accuracy: 0.7516\n",
      "Epoch 16/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5815 - accuracy: 0.7502 - val_loss: 0.5810 - val_accuracy: 0.7516\n",
      "Epoch 17/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5809 - accuracy: 0.7507 - val_loss: 0.5795 - val_accuracy: 0.7529\n",
      "Epoch 18/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5807 - accuracy: 0.7507 - val_loss: 0.5835 - val_accuracy: 0.7467\n",
      "Epoch 19/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5798 - accuracy: 0.7505 - val_loss: 0.5780 - val_accuracy: 0.7523\n",
      "Epoch 20/50\n",
      "2498/2498 [==============================] - 2s 964us/step - loss: 0.5795 - accuracy: 0.7508 - val_loss: 0.5769 - val_accuracy: 0.7530\n",
      "Epoch 21/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7509 - val_loss: 0.5820 - val_accuracy: 0.7526\n",
      "Epoch 22/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5784 - accuracy: 0.7513 - val_loss: 0.5760 - val_accuracy: 0.7524\n",
      "Epoch 23/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5780 - accuracy: 0.7512 - val_loss: 0.5752 - val_accuracy: 0.7516\n",
      "Epoch 24/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5779 - accuracy: 0.7508 - val_loss: 0.5745 - val_accuracy: 0.7523\n",
      "Epoch 25/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5773 - accuracy: 0.7512 - val_loss: 0.5745 - val_accuracy: 0.7520\n",
      "Epoch 26/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5769 - accuracy: 0.7520 - val_loss: 0.5761 - val_accuracy: 0.7502\n",
      "Epoch 27/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5767 - accuracy: 0.7516 - val_loss: 0.5740 - val_accuracy: 0.7525\n",
      "Epoch 28/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5762 - accuracy: 0.7515 - val_loss: 0.5829 - val_accuracy: 0.7504\n",
      "Epoch 29/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5760 - accuracy: 0.7518 - val_loss: 0.5732 - val_accuracy: 0.7517\n",
      "Epoch 30/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5758 - accuracy: 0.7516 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5755 - accuracy: 0.7519 - val_loss: 0.5770 - val_accuracy: 0.7494\n",
      "Epoch 32/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5750 - accuracy: 0.7516 - val_loss: 0.5733 - val_accuracy: 0.7516\n",
      "Epoch 33/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5750 - accuracy: 0.7520 - val_loss: 0.5744 - val_accuracy: 0.7506\n",
      "Epoch 34/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5749 - accuracy: 0.7516 - val_loss: 0.5764 - val_accuracy: 0.7495\n",
      "Epoch 35/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5745 - accuracy: 0.7519 - val_loss: 0.5749 - val_accuracy: 0.7497\n",
      "Epoch 36/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7520 - val_loss: 0.5762 - val_accuracy: 0.7491\n",
      "Epoch 37/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5739 - accuracy: 0.7522 - val_loss: 0.5728 - val_accuracy: 0.7523\n",
      "Epoch 38/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7518 - val_loss: 0.5712 - val_accuracy: 0.7516\n",
      "Epoch 39/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5738 - accuracy: 0.7523 - val_loss: 0.5728 - val_accuracy: 0.7529\n",
      "Epoch 40/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7518 - val_loss: 0.5747 - val_accuracy: 0.7503\n",
      "Epoch 41/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5732 - accuracy: 0.7522 - val_loss: 0.5726 - val_accuracy: 0.7514\n",
      "Epoch 42/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5730 - accuracy: 0.7522 - val_loss: 0.5758 - val_accuracy: 0.7519\n",
      "Epoch 43/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5727 - accuracy: 0.7520 - val_loss: 0.5731 - val_accuracy: 0.7503\n",
      "Epoch 44/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5726 - accuracy: 0.7526 - val_loss: 0.5702 - val_accuracy: 0.7526\n",
      "Epoch 45/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5725 - accuracy: 0.7525 - val_loss: 0.5705 - val_accuracy: 0.7539\n",
      "Epoch 46/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5726 - accuracy: 0.7521 - val_loss: 0.5695 - val_accuracy: 0.7528\n",
      "Epoch 47/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7521 - val_loss: 0.5724 - val_accuracy: 0.7517\n",
      "Epoch 48/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7524 - val_loss: 0.5710 - val_accuracy: 0.7521\n",
      "Epoch 49/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5720 - accuracy: 0.7527 - val_loss: 0.5706 - val_accuracy: 0.7526\n",
      "Epoch 50/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5716 - accuracy: 0.7524 - val_loss: 0.5717 - val_accuracy: 0.7518\n",
      "4441/4441 [==============================] - 3s 664us/step - loss: 1.2915 - accuracy: 0.4522\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x0000019CAD688DC0>\n",
      "Epoch Sizes:  50\n",
      "Neurons or Units:  64\n",
      "Test score: 1.2915496826171875\n",
      "Test accuracy: 0.4521661400794983\n",
      "\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6612 - accuracy: 0.7404 - val_loss: 0.6128 - val_accuracy: 0.7459\n",
      "Epoch 2/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6065 - accuracy: 0.7477 - val_loss: 0.6045 - val_accuracy: 0.7420\n",
      "Epoch 3/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5986 - accuracy: 0.7488 - val_loss: 0.5939 - val_accuracy: 0.7510\n",
      "Epoch 4/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5949 - accuracy: 0.7488 - val_loss: 0.5955 - val_accuracy: 0.7460\n",
      "Epoch 5/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5926 - accuracy: 0.7491 - val_loss: 0.5892 - val_accuracy: 0.7499\n",
      "Epoch 6/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5909 - accuracy: 0.7492 - val_loss: 0.5900 - val_accuracy: 0.7458\n",
      "Epoch 7/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5895 - accuracy: 0.7495 - val_loss: 0.5998 - val_accuracy: 0.7490\n",
      "Epoch 8/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5888 - accuracy: 0.7494 - val_loss: 0.5869 - val_accuracy: 0.7507\n",
      "Epoch 9/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5881 - accuracy: 0.7499 - val_loss: 0.5878 - val_accuracy: 0.7522\n",
      "Epoch 10/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5875 - accuracy: 0.7495 - val_loss: 0.6016 - val_accuracy: 0.7387\n",
      "Epoch 11/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5870 - accuracy: 0.7499 - val_loss: 0.5850 - val_accuracy: 0.7495\n",
      "Epoch 12/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5867 - accuracy: 0.7495 - val_loss: 0.5883 - val_accuracy: 0.7448\n",
      "Epoch 13/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5862 - accuracy: 0.7492 - val_loss: 0.5858 - val_accuracy: 0.7515\n",
      "Epoch 14/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5858 - accuracy: 0.7500 - val_loss: 0.5842 - val_accuracy: 0.7489\n",
      "Epoch 15/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5855 - accuracy: 0.7499 - val_loss: 0.5858 - val_accuracy: 0.7497\n",
      "Epoch 16/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5854 - accuracy: 0.7497 - val_loss: 0.5836 - val_accuracy: 0.7521\n",
      "Epoch 17/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5850 - accuracy: 0.7497 - val_loss: 0.5834 - val_accuracy: 0.7512\n",
      "Epoch 18/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5848 - accuracy: 0.7501 - val_loss: 0.5801 - val_accuracy: 0.7501\n",
      "Epoch 19/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5846 - accuracy: 0.7493 - val_loss: 0.5798 - val_accuracy: 0.7512\n",
      "Epoch 20/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5844 - accuracy: 0.7497 - val_loss: 0.5848 - val_accuracy: 0.7478\n",
      "Epoch 21/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5839 - accuracy: 0.7498 - val_loss: 0.5893 - val_accuracy: 0.7514\n",
      "Epoch 22/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5838 - accuracy: 0.7492 - val_loss: 0.5957 - val_accuracy: 0.7513\n",
      "Epoch 23/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5835 - accuracy: 0.7498 - val_loss: 0.5863 - val_accuracy: 0.7449\n",
      "Epoch 24/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5835 - accuracy: 0.7499 - val_loss: 0.5802 - val_accuracy: 0.7528\n",
      "Epoch 25/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5830 - accuracy: 0.7505 - val_loss: 0.5795 - val_accuracy: 0.7526\n",
      "Epoch 26/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5829 - accuracy: 0.7501 - val_loss: 0.5865 - val_accuracy: 0.7508\n",
      "Epoch 27/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5826 - accuracy: 0.7501 - val_loss: 0.5821 - val_accuracy: 0.7527\n",
      "Epoch 28/50\n",
      "2498/2498 [==============================] - 2s 991us/step - loss: 0.5822 - accuracy: 0.7499 - val_loss: 0.5787 - val_accuracy: 0.7495\n",
      "Epoch 29/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5818 - accuracy: 0.7502 - val_loss: 0.5848 - val_accuracy: 0.7467\n",
      "Epoch 30/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5816 - accuracy: 0.7498 - val_loss: 0.5907 - val_accuracy: 0.7409\n",
      "Epoch 31/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5813 - accuracy: 0.7506 - val_loss: 0.5887 - val_accuracy: 0.7512\n",
      "Epoch 32/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5808 - accuracy: 0.7501 - val_loss: 0.5818 - val_accuracy: 0.7460\n",
      "Epoch 33/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5807 - accuracy: 0.7509 - val_loss: 0.5847 - val_accuracy: 0.7472\n",
      "Epoch 34/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5803 - accuracy: 0.7508 - val_loss: 0.5873 - val_accuracy: 0.7444\n",
      "Epoch 35/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5800 - accuracy: 0.7507 - val_loss: 0.5826 - val_accuracy: 0.7522\n",
      "Epoch 36/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5796 - accuracy: 0.7507 - val_loss: 0.5818 - val_accuracy: 0.7472\n",
      "Epoch 37/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5794 - accuracy: 0.7506 - val_loss: 0.5767 - val_accuracy: 0.7521\n",
      "Epoch 38/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7514 - val_loss: 0.5788 - val_accuracy: 0.7494\n",
      "Epoch 39/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5787 - accuracy: 0.7512 - val_loss: 0.5802 - val_accuracy: 0.7486\n",
      "Epoch 40/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5784 - accuracy: 0.7514 - val_loss: 0.6008 - val_accuracy: 0.7401\n",
      "Epoch 41/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5782 - accuracy: 0.7510 - val_loss: 0.5860 - val_accuracy: 0.7529\n",
      "Epoch 42/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5779 - accuracy: 0.7511 - val_loss: 0.5750 - val_accuracy: 0.7523\n",
      "Epoch 43/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5778 - accuracy: 0.7512 - val_loss: 0.6154 - val_accuracy: 0.7397\n",
      "Epoch 44/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5774 - accuracy: 0.7517 - val_loss: 0.5756 - val_accuracy: 0.7508\n",
      "Epoch 45/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5770 - accuracy: 0.7518 - val_loss: 0.5748 - val_accuracy: 0.7511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5768 - accuracy: 0.7512 - val_loss: 0.5779 - val_accuracy: 0.7519\n",
      "Epoch 47/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5767 - accuracy: 0.7521 - val_loss: 0.5781 - val_accuracy: 0.7492\n",
      "Epoch 48/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5762 - accuracy: 0.7517 - val_loss: 0.5770 - val_accuracy: 0.7501\n",
      "Epoch 49/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5761 - accuracy: 0.7516 - val_loss: 0.5738 - val_accuracy: 0.7525\n",
      "Epoch 50/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5760 - accuracy: 0.7517 - val_loss: 0.5741 - val_accuracy: 0.7511\n",
      "4441/4441 [==============================] - 3s 588us/step - loss: 1.2773 - accuracy: 0.4522\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x0000019CAD688DC0>\n",
      "Epoch Sizes:  50\n",
      "Neurons or Units:  128\n",
      "Test score: 1.2773311138153076\n",
      "Test accuracy: 0.45222947001457214\n",
      "\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,667\n",
      "Trainable params: 4,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6470 - accuracy: 0.7437 - val_loss: 0.6076 - val_accuracy: 0.7469\n",
      "Epoch 2/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6033 - accuracy: 0.7482 - val_loss: 0.5960 - val_accuracy: 0.7487\n",
      "Epoch 3/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5965 - accuracy: 0.7481 - val_loss: 0.5907 - val_accuracy: 0.7478\n",
      "Epoch 4/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5930 - accuracy: 0.7484 - val_loss: 0.5903 - val_accuracy: 0.7518\n",
      "Epoch 5/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5903 - accuracy: 0.7489 - val_loss: 0.5848 - val_accuracy: 0.7519\n",
      "Epoch 6/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5887 - accuracy: 0.7496 - val_loss: 0.5884 - val_accuracy: 0.7513\n",
      "Epoch 7/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5866 - accuracy: 0.7495 - val_loss: 0.5893 - val_accuracy: 0.7504\n",
      "Epoch 8/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5853 - accuracy: 0.7496 - val_loss: 0.5922 - val_accuracy: 0.7489\n",
      "Epoch 9/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5843 - accuracy: 0.7497 - val_loss: 0.5827 - val_accuracy: 0.7483\n",
      "Epoch 10/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5829 - accuracy: 0.7508 - val_loss: 0.5832 - val_accuracy: 0.7482\n",
      "Epoch 11/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5820 - accuracy: 0.7504 - val_loss: 0.5792 - val_accuracy: 0.7509\n",
      "Epoch 12/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5812 - accuracy: 0.7501 - val_loss: 0.5801 - val_accuracy: 0.7497\n",
      "Epoch 13/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5802 - accuracy: 0.7502 - val_loss: 0.5773 - val_accuracy: 0.7525\n",
      "Epoch 14/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5795 - accuracy: 0.7506 - val_loss: 0.5761 - val_accuracy: 0.7516\n",
      "Epoch 15/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7515 - val_loss: 0.5824 - val_accuracy: 0.7485\n",
      "Epoch 16/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5783 - accuracy: 0.7512 - val_loss: 0.5760 - val_accuracy: 0.7514\n",
      "Epoch 17/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5776 - accuracy: 0.7514 - val_loss: 0.5904 - val_accuracy: 0.7438\n",
      "Epoch 18/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5771 - accuracy: 0.7515 - val_loss: 0.5774 - val_accuracy: 0.7494\n",
      "Epoch 19/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5766 - accuracy: 0.7514 - val_loss: 0.5972 - val_accuracy: 0.7420\n",
      "Epoch 20/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5760 - accuracy: 0.7513 - val_loss: 0.5791 - val_accuracy: 0.7527\n",
      "Epoch 21/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5756 - accuracy: 0.7515 - val_loss: 0.5930 - val_accuracy: 0.7448\n",
      "Epoch 22/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5752 - accuracy: 0.7520 - val_loss: 0.5739 - val_accuracy: 0.7510\n",
      "Epoch 23/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5750 - accuracy: 0.7518 - val_loss: 0.5783 - val_accuracy: 0.7523\n",
      "Epoch 24/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5747 - accuracy: 0.7517 - val_loss: 0.5759 - val_accuracy: 0.7525\n",
      "Epoch 25/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5744 - accuracy: 0.7523 - val_loss: 0.5729 - val_accuracy: 0.7530\n",
      "Epoch 26/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5741 - accuracy: 0.7519 - val_loss: 0.5713 - val_accuracy: 0.7519\n",
      "Epoch 27/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5737 - accuracy: 0.7519 - val_loss: 0.5793 - val_accuracy: 0.7489\n",
      "Epoch 28/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5736 - accuracy: 0.7517 - val_loss: 0.5759 - val_accuracy: 0.7486\n",
      "Epoch 29/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5732 - accuracy: 0.7521 - val_loss: 0.5715 - val_accuracy: 0.7520\n",
      "Epoch 30/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5730 - accuracy: 0.7520 - val_loss: 0.5723 - val_accuracy: 0.7512\n",
      "Epoch 31/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5725 - accuracy: 0.7520 - val_loss: 0.5761 - val_accuracy: 0.7496\n",
      "Epoch 32/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5726 - accuracy: 0.7516 - val_loss: 0.5711 - val_accuracy: 0.7524\n",
      "Epoch 33/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5724 - accuracy: 0.7517 - val_loss: 0.5693 - val_accuracy: 0.7522\n",
      "Epoch 34/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7526 - val_loss: 0.5738 - val_accuracy: 0.7506\n",
      "Epoch 35/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7522 - val_loss: 0.5758 - val_accuracy: 0.7488\n",
      "Epoch 36/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5718 - accuracy: 0.7521 - val_loss: 0.5717 - val_accuracy: 0.7516\n",
      "Epoch 37/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5715 - accuracy: 0.7525 - val_loss: 0.5822 - val_accuracy: 0.7502\n",
      "Epoch 38/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5713 - accuracy: 0.7520 - val_loss: 0.5783 - val_accuracy: 0.7489\n",
      "Epoch 39/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5709 - accuracy: 0.7517 - val_loss: 0.5771 - val_accuracy: 0.7505\n",
      "Epoch 40/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5709 - accuracy: 0.7523 - val_loss: 0.5696 - val_accuracy: 0.7512\n",
      "Epoch 41/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5708 - accuracy: 0.7521 - val_loss: 0.5766 - val_accuracy: 0.7475\n",
      "Epoch 42/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5708 - accuracy: 0.7522 - val_loss: 0.5733 - val_accuracy: 0.7517\n",
      "Epoch 43/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5703 - accuracy: 0.7523 - val_loss: 0.5717 - val_accuracy: 0.7530\n",
      "Epoch 44/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7522 - val_loss: 0.5692 - val_accuracy: 0.7526\n",
      "Epoch 45/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5702 - accuracy: 0.7526 - val_loss: 0.5802 - val_accuracy: 0.7480\n",
      "Epoch 46/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5702 - accuracy: 0.7520 - val_loss: 0.5709 - val_accuracy: 0.7513\n",
      "Epoch 47/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7522 - val_loss: 0.5776 - val_accuracy: 0.7488\n",
      "Epoch 48/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5700 - accuracy: 0.7521 - val_loss: 0.5784 - val_accuracy: 0.7496\n",
      "Epoch 49/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5696 - accuracy: 0.7523 - val_loss: 0.5724 - val_accuracy: 0.7499\n",
      "Epoch 50/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7522 - val_loss: 0.5800 - val_accuracy: 0.7481\n",
      "4441/4441 [==============================] - 2s 545us/step - loss: 1.3041 - accuracy: 0.4320\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x0000019CAD688DC0>\n",
      "Epoch Sizes:  50\n",
      "Neurons or Units:  256\n",
      "Test score: 1.3041476011276245\n",
      "Test accuracy: 0.43204593658447266\n",
      "\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,211\n",
      "Trainable params: 1,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6709 - accuracy: 0.7395 - val_loss: 0.6172 - val_accuracy: 0.7453\n",
      "Epoch 2/100\n",
      "2498/2498 [==============================] - 2s 947us/step - loss: 0.6101 - accuracy: 0.7484 - val_loss: 0.6073 - val_accuracy: 0.7430\n",
      "Epoch 3/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6015 - accuracy: 0.7486 - val_loss: 0.5986 - val_accuracy: 0.7470\n",
      "Epoch 4/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5966 - accuracy: 0.7490 - val_loss: 0.5948 - val_accuracy: 0.7519\n",
      "Epoch 5/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5935 - accuracy: 0.7499 - val_loss: 0.5938 - val_accuracy: 0.7506\n",
      "Epoch 6/100\n",
      "2498/2498 [==============================] - 2s 952us/step - loss: 0.5914 - accuracy: 0.7499 - val_loss: 0.5979 - val_accuracy: 0.7428\n",
      "Epoch 7/100\n",
      "2498/2498 [==============================] - 2s 841us/step - loss: 0.5901 - accuracy: 0.7495 - val_loss: 0.5896 - val_accuracy: 0.7482\n",
      "Epoch 8/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5890 - accuracy: 0.7493 - val_loss: 0.5911 - val_accuracy: 0.7447\n",
      "Epoch 9/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5878 - accuracy: 0.7500 - val_loss: 0.5862 - val_accuracy: 0.7488\n",
      "Epoch 10/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5869 - accuracy: 0.7501 - val_loss: 0.5992 - val_accuracy: 0.7506\n",
      "Epoch 11/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5865 - accuracy: 0.7497 - val_loss: 0.5872 - val_accuracy: 0.7484\n",
      "Epoch 12/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5858 - accuracy: 0.7505 - val_loss: 0.5846 - val_accuracy: 0.7482\n",
      "Epoch 13/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5855 - accuracy: 0.7497 - val_loss: 0.5886 - val_accuracy: 0.7454\n",
      "Epoch 14/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5850 - accuracy: 0.7502 - val_loss: 0.5926 - val_accuracy: 0.7414\n",
      "Epoch 15/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5845 - accuracy: 0.7497 - val_loss: 0.5881 - val_accuracy: 0.7461\n",
      "Epoch 16/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5844 - accuracy: 0.7500 - val_loss: 0.5855 - val_accuracy: 0.7519\n",
      "Epoch 17/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5841 - accuracy: 0.7500 - val_loss: 0.5856 - val_accuracy: 0.7502\n",
      "Epoch 18/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5835 - accuracy: 0.7500 - val_loss: 0.5992 - val_accuracy: 0.7491\n",
      "Epoch 19/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5836 - accuracy: 0.7505 - val_loss: 0.5868 - val_accuracy: 0.7514\n",
      "Epoch 20/100\n",
      "2498/2498 [==============================] - 2s 974us/step - loss: 0.5832 - accuracy: 0.7501 - val_loss: 0.5875 - val_accuracy: 0.7465\n",
      "Epoch 21/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5826 - accuracy: 0.7505 - val_loss: 0.5814 - val_accuracy: 0.7520\n",
      "Epoch 22/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5828 - accuracy: 0.7504 - val_loss: 0.5791 - val_accuracy: 0.7511\n",
      "Epoch 23/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5824 - accuracy: 0.7500 - val_loss: 0.5795 - val_accuracy: 0.7503\n",
      "Epoch 24/100\n",
      "2498/2498 [==============================] - 2s 969us/step - loss: 0.5819 - accuracy: 0.7501 - val_loss: 0.5784 - val_accuracy: 0.7512\n",
      "Epoch 25/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5817 - accuracy: 0.7504 - val_loss: 0.5860 - val_accuracy: 0.7513\n",
      "Epoch 26/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5815 - accuracy: 0.7504 - val_loss: 0.5805 - val_accuracy: 0.7510\n",
      "Epoch 27/100\n",
      "2498/2498 [==============================] - 2s 858us/step - loss: 0.5812 - accuracy: 0.7508 - val_loss: 0.5866 - val_accuracy: 0.7449\n",
      "Epoch 28/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5809 - accuracy: 0.7505 - val_loss: 0.5824 - val_accuracy: 0.7473\n",
      "Epoch 29/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5804 - accuracy: 0.7506 - val_loss: 0.5778 - val_accuracy: 0.7517\n",
      "Epoch 30/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5802 - accuracy: 0.7501 - val_loss: 0.5771 - val_accuracy: 0.7514\n",
      "Epoch 31/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5799 - accuracy: 0.7504 - val_loss: 0.5773 - val_accuracy: 0.7519\n",
      "Epoch 32/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5794 - accuracy: 0.7507 - val_loss: 0.5835 - val_accuracy: 0.7452\n",
      "Epoch 33/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5792 - accuracy: 0.7508 - val_loss: 0.5806 - val_accuracy: 0.7529\n",
      "Epoch 34/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7506 - val_loss: 0.5834 - val_accuracy: 0.7513\n",
      "Epoch 35/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5785 - accuracy: 0.7510 - val_loss: 0.5762 - val_accuracy: 0.7516\n",
      "Epoch 36/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5783 - accuracy: 0.7514 - val_loss: 0.5864 - val_accuracy: 0.7495\n",
      "Epoch 37/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5779 - accuracy: 0.7509 - val_loss: 0.5749 - val_accuracy: 0.7528\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5776 - accuracy: 0.7518 - val_loss: 0.5769 - val_accuracy: 0.7497\n",
      "Epoch 39/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5774 - accuracy: 0.7513 - val_loss: 0.5754 - val_accuracy: 0.7520\n",
      "Epoch 40/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5769 - accuracy: 0.7513 - val_loss: 0.5753 - val_accuracy: 0.7524\n",
      "Epoch 41/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5765 - accuracy: 0.7516 - val_loss: 0.5851 - val_accuracy: 0.7505\n",
      "Epoch 42/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5764 - accuracy: 0.7516 - val_loss: 0.5766 - val_accuracy: 0.7495\n",
      "Epoch 43/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5760 - accuracy: 0.7519 - val_loss: 0.5739 - val_accuracy: 0.7509\n",
      "Epoch 44/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5758 - accuracy: 0.7514 - val_loss: 0.5730 - val_accuracy: 0.7528\n",
      "Epoch 45/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5755 - accuracy: 0.7520 - val_loss: 0.5726 - val_accuracy: 0.7515\n",
      "Epoch 46/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5755 - accuracy: 0.7519 - val_loss: 0.5727 - val_accuracy: 0.7529\n",
      "Epoch 47/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5752 - accuracy: 0.7516 - val_loss: 0.5863 - val_accuracy: 0.7458\n",
      "Epoch 48/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5750 - accuracy: 0.7522 - val_loss: 0.5784 - val_accuracy: 0.7520\n",
      "Epoch 49/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5744 - accuracy: 0.7522 - val_loss: 0.5712 - val_accuracy: 0.7527\n",
      "Epoch 50/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5744 - accuracy: 0.7522 - val_loss: 0.5732 - val_accuracy: 0.7520\n",
      "Epoch 51/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5743 - accuracy: 0.7518 - val_loss: 0.5728 - val_accuracy: 0.7506\n",
      "Epoch 52/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7522 - val_loss: 0.5831 - val_accuracy: 0.7509\n",
      "Epoch 53/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7521 - val_loss: 0.5734 - val_accuracy: 0.7522\n",
      "Epoch 54/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5736 - accuracy: 0.7520 - val_loss: 0.5721 - val_accuracy: 0.7528\n",
      "Epoch 55/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5736 - accuracy: 0.7522 - val_loss: 0.5724 - val_accuracy: 0.7519\n",
      "Epoch 56/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5735 - accuracy: 0.7524 - val_loss: 0.5741 - val_accuracy: 0.7507\n",
      "Epoch 57/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5732 - accuracy: 0.7524 - val_loss: 0.5747 - val_accuracy: 0.7490\n",
      "Epoch 58/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5730 - accuracy: 0.7522 - val_loss: 0.5851 - val_accuracy: 0.7456\n",
      "Epoch 59/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7523 - val_loss: 0.5702 - val_accuracy: 0.7512\n",
      "Epoch 60/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7518 - val_loss: 0.5775 - val_accuracy: 0.7473\n",
      "Epoch 61/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5725 - accuracy: 0.7523 - val_loss: 0.5765 - val_accuracy: 0.7497\n",
      "Epoch 62/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5725 - accuracy: 0.7522 - val_loss: 0.5705 - val_accuracy: 0.7527\n",
      "Epoch 63/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7526 - val_loss: 0.5751 - val_accuracy: 0.7489\n",
      "Epoch 64/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5725 - accuracy: 0.7519 - val_loss: 0.5705 - val_accuracy: 0.7519\n",
      "Epoch 65/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5722 - accuracy: 0.7522 - val_loss: 0.5736 - val_accuracy: 0.7498\n",
      "Epoch 66/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7523 - val_loss: 0.5722 - val_accuracy: 0.7529\n",
      "Epoch 67/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5720 - accuracy: 0.7525 - val_loss: 0.5701 - val_accuracy: 0.7526\n",
      "Epoch 68/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5718 - accuracy: 0.7525 - val_loss: 0.5709 - val_accuracy: 0.7524\n",
      "Epoch 69/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5716 - accuracy: 0.7524 - val_loss: 0.5700 - val_accuracy: 0.7531\n",
      "Epoch 70/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5718 - accuracy: 0.7527 - val_loss: 0.5850 - val_accuracy: 0.7465\n",
      "Epoch 71/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5717 - accuracy: 0.7523 - val_loss: 0.5712 - val_accuracy: 0.7525\n",
      "Epoch 72/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5716 - accuracy: 0.7529 - val_loss: 0.5740 - val_accuracy: 0.7518\n",
      "Epoch 73/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5713 - accuracy: 0.7528 - val_loss: 0.5708 - val_accuracy: 0.7514\n",
      "Epoch 74/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5713 - accuracy: 0.7523 - val_loss: 0.5688 - val_accuracy: 0.7529\n",
      "Epoch 75/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7520 - val_loss: 0.5677 - val_accuracy: 0.7532\n",
      "Epoch 76/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5711 - accuracy: 0.7523 - val_loss: 0.5680 - val_accuracy: 0.7533\n",
      "Epoch 77/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5708 - accuracy: 0.7523 - val_loss: 0.5696 - val_accuracy: 0.7522\n",
      "Epoch 78/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5707 - accuracy: 0.7531 - val_loss: 0.5705 - val_accuracy: 0.7509\n",
      "Epoch 79/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5707 - accuracy: 0.7528 - val_loss: 0.5723 - val_accuracy: 0.7507\n",
      "Epoch 80/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7529 - val_loss: 0.5733 - val_accuracy: 0.7499\n",
      "Epoch 81/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7527 - val_loss: 0.5725 - val_accuracy: 0.7512\n",
      "Epoch 82/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7527 - val_loss: 0.5699 - val_accuracy: 0.7511\n",
      "Epoch 83/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7527 - val_loss: 0.5733 - val_accuracy: 0.7503\n",
      "Epoch 84/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5705 - accuracy: 0.7526 - val_loss: 0.5698 - val_accuracy: 0.7517\n",
      "Epoch 85/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7525 - val_loss: 0.5700 - val_accuracy: 0.7522\n",
      "Epoch 86/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7530 - val_loss: 0.5712 - val_accuracy: 0.7513\n",
      "Epoch 87/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7525 - val_loss: 0.5716 - val_accuracy: 0.7511\n",
      "Epoch 88/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7524 - val_loss: 0.5672 - val_accuracy: 0.7529\n",
      "Epoch 89/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7525 - val_loss: 0.5809 - val_accuracy: 0.7501\n",
      "Epoch 90/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7528 - val_loss: 0.5726 - val_accuracy: 0.7515\n",
      "Epoch 91/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7527 - val_loss: 0.5690 - val_accuracy: 0.7535\n",
      "Epoch 92/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5698 - accuracy: 0.7528 - val_loss: 0.5761 - val_accuracy: 0.7499\n",
      "Epoch 93/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7527 - val_loss: 0.5673 - val_accuracy: 0.7521\n",
      "Epoch 94/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5696 - accuracy: 0.7526 - val_loss: 0.5671 - val_accuracy: 0.7533\n",
      "Epoch 95/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5695 - accuracy: 0.7528 - val_loss: 0.5678 - val_accuracy: 0.7518\n",
      "Epoch 96/100\n",
      "2498/2498 [==============================] - 2s 991us/step - loss: 0.5693 - accuracy: 0.7529 - val_loss: 0.5684 - val_accuracy: 0.7535\n",
      "Epoch 97/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5692 - accuracy: 0.7524 - val_loss: 0.5938 - val_accuracy: 0.7432\n",
      "Epoch 98/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5693 - accuracy: 0.7528 - val_loss: 0.5679 - val_accuracy: 0.7533\n",
      "Epoch 99/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5692 - accuracy: 0.7526 - val_loss: 0.5700 - val_accuracy: 0.7530\n",
      "Epoch 100/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5689 - accuracy: 0.7527 - val_loss: 0.5686 - val_accuracy: 0.7533\n",
      "4441/4441 [==============================] - 4s 839us/step - loss: 1.3181 - accuracy: 0.4422\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x0000019CAD688DC0>\n",
      "Epoch Sizes:  100\n",
      "Neurons or Units:  64\n",
      "Test score: 1.318095088005066\n",
      "Test accuracy: 0.4422292113304138\n",
      "\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.6570 - accuracy: 0.7425 - val_loss: 0.6110 - val_accuracy: 0.7498\n",
      "Epoch 2/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6046 - accuracy: 0.7486 - val_loss: 0.5988 - val_accuracy: 0.7492\n",
      "Epoch 3/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5968 - accuracy: 0.7488 - val_loss: 0.5928 - val_accuracy: 0.7494\n",
      "Epoch 4/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5925 - accuracy: 0.7495 - val_loss: 0.5927 - val_accuracy: 0.7493\n",
      "Epoch 5/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5899 - accuracy: 0.7497 - val_loss: 0.5864 - val_accuracy: 0.7504\n",
      "Epoch 6/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5881 - accuracy: 0.7496 - val_loss: 0.5845 - val_accuracy: 0.7514\n",
      "Epoch 7/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5864 - accuracy: 0.7498 - val_loss: 0.5940 - val_accuracy: 0.7509\n",
      "Epoch 8/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5849 - accuracy: 0.7500 - val_loss: 0.5851 - val_accuracy: 0.7472\n",
      "Epoch 9/100\n",
      "2498/2498 [==============================] - 2s 964us/step - loss: 0.5841 - accuracy: 0.7501 - val_loss: 0.5859 - val_accuracy: 0.7508\n",
      "Epoch 10/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5830 - accuracy: 0.7506 - val_loss: 0.5813 - val_accuracy: 0.7493\n",
      "Epoch 11/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5822 - accuracy: 0.7499 - val_loss: 0.5824 - val_accuracy: 0.7486\n",
      "Epoch 12/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5814 - accuracy: 0.7505 - val_loss: 0.5796 - val_accuracy: 0.7511\n",
      "Epoch 13/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5806 - accuracy: 0.7502 - val_loss: 0.5760 - val_accuracy: 0.7519\n",
      "Epoch 14/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5801 - accuracy: 0.7512 - val_loss: 0.5760 - val_accuracy: 0.7509\n",
      "Epoch 15/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5795 - accuracy: 0.7513 - val_loss: 0.5828 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7509 - val_loss: 0.5817 - val_accuracy: 0.7463\n",
      "Epoch 17/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5786 - accuracy: 0.7506 - val_loss: 0.5860 - val_accuracy: 0.7494\n",
      "Epoch 18/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5782 - accuracy: 0.7512 - val_loss: 0.6007 - val_accuracy: 0.7451\n",
      "Epoch 19/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5777 - accuracy: 0.7512 - val_loss: 0.5937 - val_accuracy: 0.7477\n",
      "Epoch 20/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5773 - accuracy: 0.7514 - val_loss: 0.5790 - val_accuracy: 0.7531\n",
      "Epoch 21/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5770 - accuracy: 0.7513 - val_loss: 0.5744 - val_accuracy: 0.7514\n",
      "Epoch 22/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5766 - accuracy: 0.7517 - val_loss: 0.5741 - val_accuracy: 0.7518\n",
      "Epoch 23/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5764 - accuracy: 0.7510 - val_loss: 0.5740 - val_accuracy: 0.7525\n",
      "Epoch 24/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5758 - accuracy: 0.7521 - val_loss: 0.5962 - val_accuracy: 0.7472\n",
      "Epoch 25/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5756 - accuracy: 0.7516 - val_loss: 0.5755 - val_accuracy: 0.7513\n",
      "Epoch 26/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5753 - accuracy: 0.7516 - val_loss: 0.5777 - val_accuracy: 0.7502\n",
      "Epoch 27/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5750 - accuracy: 0.7517 - val_loss: 0.5754 - val_accuracy: 0.7522\n",
      "Epoch 28/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5746 - accuracy: 0.7523 - val_loss: 0.5735 - val_accuracy: 0.7538\n",
      "Epoch 29/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5741 - accuracy: 0.7513 - val_loss: 0.5744 - val_accuracy: 0.7503\n",
      "Epoch 30/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5742 - accuracy: 0.7522 - val_loss: 0.5742 - val_accuracy: 0.7511\n",
      "Epoch 31/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7517 - val_loss: 0.5814 - val_accuracy: 0.7514\n",
      "Epoch 32/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5735 - accuracy: 0.7519 - val_loss: 0.5719 - val_accuracy: 0.7515\n",
      "Epoch 33/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5733 - accuracy: 0.7521 - val_loss: 0.5751 - val_accuracy: 0.7524\n",
      "Epoch 34/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7524 - val_loss: 0.5730 - val_accuracy: 0.7516\n",
      "Epoch 35/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7518 - val_loss: 0.5802 - val_accuracy: 0.7482\n",
      "Epoch 36/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5727 - accuracy: 0.7524 - val_loss: 0.5703 - val_accuracy: 0.7527\n",
      "Epoch 37/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7521 - val_loss: 0.5776 - val_accuracy: 0.7517\n",
      "Epoch 38/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5722 - accuracy: 0.7528 - val_loss: 0.5714 - val_accuracy: 0.7524\n",
      "Epoch 39/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7521 - val_loss: 0.5730 - val_accuracy: 0.7529\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5720 - accuracy: 0.7522 - val_loss: 0.5702 - val_accuracy: 0.7527\n",
      "Epoch 41/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5718 - accuracy: 0.7522 - val_loss: 0.5735 - val_accuracy: 0.7507\n",
      "Epoch 42/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5715 - accuracy: 0.7523 - val_loss: 0.5762 - val_accuracy: 0.7519\n",
      "Epoch 43/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5716 - accuracy: 0.7521 - val_loss: 0.5732 - val_accuracy: 0.7516\n",
      "Epoch 44/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7521 - val_loss: 0.5708 - val_accuracy: 0.7525\n",
      "Epoch 45/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7524 - val_loss: 0.5692 - val_accuracy: 0.7532\n",
      "Epoch 46/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5710 - accuracy: 0.7522 - val_loss: 0.5710 - val_accuracy: 0.7520\n",
      "Epoch 47/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7523 - val_loss: 0.5682 - val_accuracy: 0.7524\n",
      "Epoch 48/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7525 - val_loss: 0.5909 - val_accuracy: 0.7468\n",
      "Epoch 49/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7520 - val_loss: 0.5715 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5703 - accuracy: 0.7524 - val_loss: 0.5726 - val_accuracy: 0.7508\n",
      "Epoch 51/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5703 - accuracy: 0.7525 - val_loss: 0.5793 - val_accuracy: 0.7492\n",
      "Epoch 52/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7527 - val_loss: 0.5719 - val_accuracy: 0.7526\n",
      "Epoch 53/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7526 - val_loss: 0.5825 - val_accuracy: 0.7482\n",
      "Epoch 54/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7524 - val_loss: 0.5687 - val_accuracy: 0.7511\n",
      "Epoch 55/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7522 - val_loss: 0.5699 - val_accuracy: 0.7514\n",
      "Epoch 56/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7525 - val_loss: 0.5690 - val_accuracy: 0.7513\n",
      "Epoch 57/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5696 - accuracy: 0.7524 - val_loss: 0.5700 - val_accuracy: 0.7520\n",
      "Epoch 58/100\n",
      "2498/2498 [==============================] - 227s 91ms/step - loss: 0.5694 - accuracy: 0.7522 - val_loss: 0.5684 - val_accuracy: 0.7522\n",
      "Epoch 59/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5693 - accuracy: 0.7526 - val_loss: 0.5680 - val_accuracy: 0.7532\n",
      "Epoch 60/100\n",
      "2498/2498 [==============================] - 2s 856us/step - loss: 0.5692 - accuracy: 0.7526 - val_loss: 0.5697 - val_accuracy: 0.7509\n",
      "Epoch 61/100\n",
      "2498/2498 [==============================] - 2s 925us/step - loss: 0.5690 - accuracy: 0.7527 - val_loss: 0.5675 - val_accuracy: 0.7524\n",
      "Epoch 62/100\n",
      "2498/2498 [==============================] - 2s 962us/step - loss: 0.5691 - accuracy: 0.7526 - val_loss: 0.5708 - val_accuracy: 0.7509\n",
      "Epoch 63/100\n",
      "2498/2498 [==============================] - 2s 787us/step - loss: 0.5689 - accuracy: 0.7529 - val_loss: 0.5688 - val_accuracy: 0.7521\n",
      "Epoch 64/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5688 - accuracy: 0.7530 - val_loss: 0.5743 - val_accuracy: 0.7499\n",
      "Epoch 65/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7529 - val_loss: 0.5704 - val_accuracy: 0.7502\n",
      "Epoch 66/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7527 - val_loss: 0.5678 - val_accuracy: 0.7519\n",
      "Epoch 67/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7525 - val_loss: 0.5681 - val_accuracy: 0.7520\n",
      "Epoch 68/100\n",
      "2498/2498 [==============================] - 2s 996us/step - loss: 0.5684 - accuracy: 0.7528 - val_loss: 0.5745 - val_accuracy: 0.7512\n",
      "Epoch 69/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5684 - accuracy: 0.7530 - val_loss: 0.5676 - val_accuracy: 0.7522\n",
      "Epoch 70/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7529 - val_loss: 0.5708 - val_accuracy: 0.7507\n",
      "Epoch 71/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7532 - val_loss: 0.5715 - val_accuracy: 0.7519\n",
      "Epoch 72/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7526 - val_loss: 0.5673 - val_accuracy: 0.7527\n",
      "Epoch 73/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7529 - val_loss: 0.5667 - val_accuracy: 0.7522\n",
      "Epoch 74/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7525 - val_loss: 0.5669 - val_accuracy: 0.7527\n",
      "Epoch 75/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7525 - val_loss: 0.5667 - val_accuracy: 0.7532\n",
      "Epoch 76/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7528 - val_loss: 0.5709 - val_accuracy: 0.7516\n",
      "Epoch 77/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7527 - val_loss: 0.5669 - val_accuracy: 0.7519\n",
      "Epoch 78/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7527 - val_loss: 0.5686 - val_accuracy: 0.7525\n",
      "Epoch 79/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7527 - val_loss: 0.5672 - val_accuracy: 0.7519\n",
      "Epoch 80/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7527 - val_loss: 0.5663 - val_accuracy: 0.7522\n",
      "Epoch 81/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7526 - val_loss: 0.5749 - val_accuracy: 0.7502\n",
      "Epoch 82/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5674 - accuracy: 0.7529 - val_loss: 0.5698 - val_accuracy: 0.7491\n",
      "Epoch 83/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7530 - val_loss: 0.5665 - val_accuracy: 0.7523\n",
      "Epoch 84/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7529 - val_loss: 0.5654 - val_accuracy: 0.7532\n",
      "Epoch 85/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5673 - accuracy: 0.7530 - val_loss: 0.5670 - val_accuracy: 0.7518\n",
      "Epoch 86/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5671 - accuracy: 0.7525 - val_loss: 0.5672 - val_accuracy: 0.7525\n",
      "Epoch 87/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5672 - accuracy: 0.7526 - val_loss: 0.5654 - val_accuracy: 0.7524\n",
      "Epoch 88/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7532 - val_loss: 0.5697 - val_accuracy: 0.7514\n",
      "Epoch 89/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5671 - accuracy: 0.7530 - val_loss: 0.5671 - val_accuracy: 0.7513\n",
      "Epoch 90/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7525 - val_loss: 0.5688 - val_accuracy: 0.7510\n",
      "Epoch 91/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5669 - accuracy: 0.7529 - val_loss: 0.5665 - val_accuracy: 0.7529\n",
      "Epoch 92/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7529 - val_loss: 0.5711 - val_accuracy: 0.7517\n",
      "Epoch 93/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7528 - val_loss: 0.5667 - val_accuracy: 0.7522\n",
      "Epoch 94/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7533 - val_loss: 0.5651 - val_accuracy: 0.7530\n",
      "Epoch 95/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5669 - accuracy: 0.7532 - val_loss: 0.5679 - val_accuracy: 0.7525\n",
      "Epoch 96/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7527 - val_loss: 0.5650 - val_accuracy: 0.7530\n",
      "Epoch 97/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7530 - val_loss: 0.5658 - val_accuracy: 0.7523\n",
      "Epoch 98/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7525 - val_loss: 0.5656 - val_accuracy: 0.7534\n",
      "Epoch 99/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7528 - val_loss: 0.5684 - val_accuracy: 0.7519\n",
      "Epoch 100/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7531 - val_loss: 0.5645 - val_accuracy: 0.7529\n",
      "4441/4441 [==============================] - 3s 666us/step - loss: 1.3044 - accuracy: 0.4448\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x0000019CAD688DC0>\n",
      "Epoch Sizes:  100\n",
      "Neurons or Units:  128\n",
      "Test score: 1.304381251335144\n",
      "Test accuracy: 0.4447838068008423\n",
      "\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,667\n",
      "Trainable params: 4,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6478 - accuracy: 0.7435 - val_loss: 0.6100 - val_accuracy: 0.7431\n",
      "Epoch 2/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6035 - accuracy: 0.7478 - val_loss: 0.6063 - val_accuracy: 0.7503\n",
      "Epoch 3/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5974 - accuracy: 0.7480 - val_loss: 0.5924 - val_accuracy: 0.7498\n",
      "Epoch 4/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5946 - accuracy: 0.7479 - val_loss: 0.5898 - val_accuracy: 0.7489\n",
      "Epoch 5/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5926 - accuracy: 0.7487 - val_loss: 0.6088 - val_accuracy: 0.7492\n",
      "Epoch 6/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5912 - accuracy: 0.7482 - val_loss: 0.5885 - val_accuracy: 0.7483\n",
      "Epoch 7/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5901 - accuracy: 0.7486 - val_loss: 0.5930 - val_accuracy: 0.7497\n",
      "Epoch 8/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5892 - accuracy: 0.7488 - val_loss: 0.5996 - val_accuracy: 0.7389\n",
      "Epoch 9/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5877 - accuracy: 0.7488 - val_loss: 0.5838 - val_accuracy: 0.7501\n",
      "Epoch 10/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5869 - accuracy: 0.7488 - val_loss: 0.5908 - val_accuracy: 0.7438\n",
      "Epoch 11/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5857 - accuracy: 0.7498 - val_loss: 0.5859 - val_accuracy: 0.7512\n",
      "Epoch 12/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5846 - accuracy: 0.7501 - val_loss: 0.5795 - val_accuracy: 0.7507\n",
      "Epoch 13/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5836 - accuracy: 0.7501 - val_loss: 0.5802 - val_accuracy: 0.7507\n",
      "Epoch 14/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5828 - accuracy: 0.7501 - val_loss: 0.5815 - val_accuracy: 0.7497\n",
      "Epoch 15/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5822 - accuracy: 0.7502 - val_loss: 0.5824 - val_accuracy: 0.7509\n",
      "Epoch 16/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5811 - accuracy: 0.7501 - val_loss: 0.5805 - val_accuracy: 0.7496\n",
      "Epoch 17/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5809 - accuracy: 0.7501 - val_loss: 0.5788 - val_accuracy: 0.7521\n",
      "Epoch 18/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5796 - accuracy: 0.7507 - val_loss: 0.5820 - val_accuracy: 0.7487\n",
      "Epoch 19/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5793 - accuracy: 0.7509 - val_loss: 0.5762 - val_accuracy: 0.7502\n",
      "Epoch 20/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5783 - accuracy: 0.7513 - val_loss: 0.5783 - val_accuracy: 0.7486\n",
      "Epoch 21/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5775 - accuracy: 0.7511 - val_loss: 0.6054 - val_accuracy: 0.7435\n",
      "Epoch 22/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5771 - accuracy: 0.7509 - val_loss: 0.5727 - val_accuracy: 0.7529\n",
      "Epoch 23/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5768 - accuracy: 0.7513 - val_loss: 0.5727 - val_accuracy: 0.7531\n",
      "Epoch 24/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5759 - accuracy: 0.7512 - val_loss: 0.5746 - val_accuracy: 0.7516\n",
      "Epoch 25/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5756 - accuracy: 0.7518 - val_loss: 0.5765 - val_accuracy: 0.7497\n",
      "Epoch 26/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5749 - accuracy: 0.7519 - val_loss: 0.5736 - val_accuracy: 0.7505\n",
      "Epoch 27/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5750 - accuracy: 0.7513 - val_loss: 0.5749 - val_accuracy: 0.7515\n",
      "Epoch 28/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5744 - accuracy: 0.7515 - val_loss: 0.5780 - val_accuracy: 0.7507\n",
      "Epoch 29/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5742 - accuracy: 0.7518 - val_loss: 0.5729 - val_accuracy: 0.7502\n",
      "Epoch 30/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7513 - val_loss: 0.5812 - val_accuracy: 0.7459\n",
      "Epoch 31/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7515 - val_loss: 0.5764 - val_accuracy: 0.7488\n",
      "Epoch 32/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5733 - accuracy: 0.7521 - val_loss: 0.5730 - val_accuracy: 0.7504\n",
      "Epoch 33/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7520 - val_loss: 0.5741 - val_accuracy: 0.7508\n",
      "Epoch 34/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5727 - accuracy: 0.7520 - val_loss: 0.5750 - val_accuracy: 0.7523\n",
      "Epoch 35/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7519 - val_loss: 0.5720 - val_accuracy: 0.7515\n",
      "Epoch 36/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7520 - val_loss: 0.5738 - val_accuracy: 0.7529\n",
      "Epoch 37/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7518 - val_loss: 0.5741 - val_accuracy: 0.7507\n",
      "Epoch 38/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5718 - accuracy: 0.7518 - val_loss: 0.5723 - val_accuracy: 0.7502\n",
      "Epoch 39/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5714 - accuracy: 0.7524 - val_loss: 0.5731 - val_accuracy: 0.7516\n",
      "Epoch 40/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7525 - val_loss: 0.5875 - val_accuracy: 0.7443\n",
      "Epoch 41/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5709 - accuracy: 0.7525 - val_loss: 0.5713 - val_accuracy: 0.7514\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5708 - accuracy: 0.7520 - val_loss: 0.5719 - val_accuracy: 0.7521\n",
      "Epoch 43/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5708 - accuracy: 0.7522 - val_loss: 0.5747 - val_accuracy: 0.7496\n",
      "Epoch 44/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7520 - val_loss: 0.5720 - val_accuracy: 0.7492\n",
      "Epoch 45/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5701 - accuracy: 0.7523 - val_loss: 0.5793 - val_accuracy: 0.7492\n",
      "Epoch 46/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5701 - accuracy: 0.7519 - val_loss: 0.5777 - val_accuracy: 0.7503\n",
      "Epoch 47/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7524 - val_loss: 0.5717 - val_accuracy: 0.7503\n",
      "Epoch 48/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7522 - val_loss: 0.5732 - val_accuracy: 0.7527\n",
      "Epoch 49/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7523 - val_loss: 0.5670 - val_accuracy: 0.7524\n",
      "Epoch 50/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5694 - accuracy: 0.7522 - val_loss: 0.5726 - val_accuracy: 0.7513\n",
      "Epoch 51/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5693 - accuracy: 0.7525 - val_loss: 0.5676 - val_accuracy: 0.7524\n",
      "Epoch 52/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5693 - accuracy: 0.7523 - val_loss: 0.5851 - val_accuracy: 0.7431\n",
      "Epoch 53/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5694 - accuracy: 0.7523 - val_loss: 0.5789 - val_accuracy: 0.7502\n",
      "Epoch 54/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5692 - accuracy: 0.7525 - val_loss: 0.5743 - val_accuracy: 0.7505\n",
      "Epoch 55/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7518 - val_loss: 0.5787 - val_accuracy: 0.7492\n",
      "Epoch 56/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7522 - val_loss: 0.5735 - val_accuracy: 0.7513\n",
      "Epoch 57/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5688 - accuracy: 0.7521 - val_loss: 0.5797 - val_accuracy: 0.7495\n",
      "Epoch 58/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5688 - accuracy: 0.7530 - val_loss: 0.5683 - val_accuracy: 0.7521\n",
      "Epoch 59/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5687 - accuracy: 0.7521 - val_loss: 0.5791 - val_accuracy: 0.7483\n",
      "Epoch 60/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7526 - val_loss: 0.5673 - val_accuracy: 0.7525\n",
      "Epoch 61/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5685 - accuracy: 0.7525 - val_loss: 0.5700 - val_accuracy: 0.7518\n",
      "Epoch 62/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7524 - val_loss: 0.5817 - val_accuracy: 0.7477\n",
      "Epoch 63/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5684 - accuracy: 0.7526 - val_loss: 0.5665 - val_accuracy: 0.7532\n",
      "Epoch 64/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5684 - accuracy: 0.7524 - val_loss: 0.5966 - val_accuracy: 0.7404\n",
      "Epoch 65/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7527 - val_loss: 0.5671 - val_accuracy: 0.7518\n",
      "Epoch 66/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7523 - val_loss: 0.5687 - val_accuracy: 0.7518\n",
      "Epoch 67/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7525 - val_loss: 0.5674 - val_accuracy: 0.7530\n",
      "Epoch 68/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5678 - accuracy: 0.7526 - val_loss: 0.5841 - val_accuracy: 0.7459\n",
      "Epoch 69/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7525 - val_loss: 0.5658 - val_accuracy: 0.7526\n",
      "Epoch 70/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5679 - accuracy: 0.7523 - val_loss: 0.5677 - val_accuracy: 0.7523\n",
      "Epoch 71/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5679 - accuracy: 0.7525 - val_loss: 0.5680 - val_accuracy: 0.7504\n",
      "Epoch 72/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5678 - accuracy: 0.7525 - val_loss: 0.5802 - val_accuracy: 0.7486\n",
      "Epoch 73/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7525 - val_loss: 0.5704 - val_accuracy: 0.7509\n",
      "Epoch 74/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5677 - accuracy: 0.7528 - val_loss: 0.5680 - val_accuracy: 0.7512\n",
      "Epoch 75/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7528 - val_loss: 0.5667 - val_accuracy: 0.7520\n",
      "Epoch 76/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5678 - accuracy: 0.7522 - val_loss: 0.5669 - val_accuracy: 0.7519\n",
      "Epoch 77/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7527 - val_loss: 0.5666 - val_accuracy: 0.7517\n",
      "Epoch 78/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7525 - val_loss: 0.5655 - val_accuracy: 0.7524\n",
      "Epoch 79/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5674 - accuracy: 0.7527 - val_loss: 0.5680 - val_accuracy: 0.7531\n",
      "Epoch 80/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5672 - accuracy: 0.7528 - val_loss: 0.5774 - val_accuracy: 0.7498\n",
      "Epoch 81/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5672 - accuracy: 0.7524 - val_loss: 0.5664 - val_accuracy: 0.7514\n",
      "Epoch 82/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5674 - accuracy: 0.7522 - val_loss: 0.5667 - val_accuracy: 0.7514\n",
      "Epoch 83/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5673 - accuracy: 0.7525 - val_loss: 0.5693 - val_accuracy: 0.7505\n",
      "Epoch 84/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5672 - accuracy: 0.7528 - val_loss: 0.5688 - val_accuracy: 0.7518\n",
      "Epoch 85/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5672 - accuracy: 0.7529 - val_loss: 0.5690 - val_accuracy: 0.7521\n",
      "Epoch 86/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5669 - accuracy: 0.7522 - val_loss: 0.5671 - val_accuracy: 0.7524\n",
      "Epoch 87/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7526 - val_loss: 0.5688 - val_accuracy: 0.7508\n",
      "Epoch 88/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7526 - val_loss: 0.5645 - val_accuracy: 0.7534\n",
      "Epoch 89/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7527 - val_loss: 0.5658 - val_accuracy: 0.7528\n",
      "Epoch 90/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5669 - accuracy: 0.7527 - val_loss: 0.5669 - val_accuracy: 0.7513\n",
      "Epoch 91/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7527 - val_loss: 0.5670 - val_accuracy: 0.7521\n",
      "Epoch 92/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7527 - val_loss: 0.5671 - val_accuracy: 0.7509\n",
      "Epoch 93/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7531 - val_loss: 0.5644 - val_accuracy: 0.7523\n",
      "Epoch 94/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7524 - val_loss: 0.5646 - val_accuracy: 0.7528\n",
      "Epoch 95/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7530 - val_loss: 0.5710 - val_accuracy: 0.7502\n",
      "Epoch 96/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7526 - val_loss: 0.5786 - val_accuracy: 0.7502\n",
      "Epoch 97/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7528 - val_loss: 0.5659 - val_accuracy: 0.7528\n",
      "Epoch 98/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7532 - val_loss: 0.5639 - val_accuracy: 0.7526\n",
      "Epoch 99/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7528 - val_loss: 0.5653 - val_accuracy: 0.7536\n",
      "Epoch 100/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7530 - val_loss: 0.5670 - val_accuracy: 0.7504\n",
      "4441/4441 [==============================] - 3s 596us/step - loss: 1.3051 - accuracy: 0.4492\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x0000019CAD688DC0>\n",
      "Epoch Sizes:  100\n",
      "Neurons or Units:  256\n",
      "Test score: 1.305086612701416\n",
      "Test accuracy: 0.44921743869781494\n",
      "\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,211\n",
      "Trainable params: 1,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2498/2498 [==============================] - 2s 866us/step - loss: 0.6788 - accuracy: 0.7396 - val_loss: 0.6209 - val_accuracy: 0.7487\n",
      "Epoch 2/200\n",
      "2498/2498 [==============================] - 2s 960us/step - loss: 0.6101 - accuracy: 0.7478 - val_loss: 0.6028 - val_accuracy: 0.7479\n",
      "Epoch 3/200\n",
      "2498/2498 [==============================] - 2s 981us/step - loss: 0.6009 - accuracy: 0.7488 - val_loss: 0.5997 - val_accuracy: 0.7506\n",
      "Epoch 4/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5963 - accuracy: 0.7490 - val_loss: 0.5948 - val_accuracy: 0.7477\n",
      "Epoch 5/200\n",
      "2498/2498 [==============================] - 2s 983us/step - loss: 0.5935 - accuracy: 0.7489 - val_loss: 0.5905 - val_accuracy: 0.7498\n",
      "Epoch 6/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5914 - accuracy: 0.7495 - val_loss: 0.5931 - val_accuracy: 0.7501\n",
      "Epoch 7/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5898 - accuracy: 0.7493 - val_loss: 0.5877 - val_accuracy: 0.7491\n",
      "Epoch 8/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5887 - accuracy: 0.7494 - val_loss: 0.5954 - val_accuracy: 0.7517\n",
      "Epoch 9/200\n",
      "2498/2498 [==============================] - 2s 824us/step - loss: 0.5878 - accuracy: 0.7500 - val_loss: 0.5868 - val_accuracy: 0.7515\n",
      "Epoch 10/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5871 - accuracy: 0.7499 - val_loss: 0.5850 - val_accuracy: 0.7489\n",
      "Epoch 11/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5864 - accuracy: 0.7501 - val_loss: 0.5836 - val_accuracy: 0.7501\n",
      "Epoch 12/200\n",
      "2498/2498 [==============================] - 2s 873us/step - loss: 0.5859 - accuracy: 0.7502 - val_loss: 0.5835 - val_accuracy: 0.7511\n",
      "Epoch 13/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5854 - accuracy: 0.7495 - val_loss: 0.5823 - val_accuracy: 0.7509\n",
      "Epoch 14/200\n",
      "2498/2498 [==============================] - 2s 983us/step - loss: 0.5854 - accuracy: 0.7499 - val_loss: 0.5840 - val_accuracy: 0.7515\n",
      "Epoch 15/200\n",
      "2498/2498 [==============================] - 2s 951us/step - loss: 0.5847 - accuracy: 0.7500 - val_loss: 0.5843 - val_accuracy: 0.7501\n",
      "Epoch 16/200\n",
      "2498/2498 [==============================] - 2s 869us/step - loss: 0.5844 - accuracy: 0.7496 - val_loss: 0.5844 - val_accuracy: 0.7518\n",
      "Epoch 17/200\n",
      "2498/2498 [==============================] - 2s 989us/step - loss: 0.5842 - accuracy: 0.7497 - val_loss: 0.5832 - val_accuracy: 0.7484\n",
      "Epoch 18/200\n",
      "2498/2498 [==============================] - 2s 1ms/step - loss: 0.5838 - accuracy: 0.7500 - val_loss: 0.5841 - val_accuracy: 0.7523\n",
      "Epoch 19/200\n",
      "2498/2498 [==============================] - 2s 913us/step - loss: 0.5833 - accuracy: 0.7496 - val_loss: 0.5885 - val_accuracy: 0.7516\n",
      "Epoch 20/200\n",
      "2498/2498 [==============================] - 2s 934us/step - loss: 0.5831 - accuracy: 0.7505 - val_loss: 0.5836 - val_accuracy: 0.7474\n",
      "Epoch 21/200\n",
      "2498/2498 [==============================] - 2s 954us/step - loss: 0.5830 - accuracy: 0.7501 - val_loss: 0.5811 - val_accuracy: 0.7522\n",
      "Epoch 22/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5827 - accuracy: 0.7502 - val_loss: 0.5793 - val_accuracy: 0.7512\n",
      "Epoch 23/200\n",
      "2498/2498 [==============================] - 2s 924us/step - loss: 0.5828 - accuracy: 0.7501 - val_loss: 0.5833 - val_accuracy: 0.7466\n",
      "Epoch 24/200\n",
      "2498/2498 [==============================] - 2s 845us/step - loss: 0.5825 - accuracy: 0.7502 - val_loss: 0.5845 - val_accuracy: 0.7462\n",
      "Epoch 25/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5822 - accuracy: 0.7502 - val_loss: 0.5806 - val_accuracy: 0.7497\n",
      "Epoch 26/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5821 - accuracy: 0.7502 - val_loss: 0.5802 - val_accuracy: 0.7509\n",
      "Epoch 27/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5818 - accuracy: 0.7503 - val_loss: 0.5798 - val_accuracy: 0.7493\n",
      "Epoch 28/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5817 - accuracy: 0.7498 - val_loss: 0.5841 - val_accuracy: 0.7506\n",
      "Epoch 29/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5814 - accuracy: 0.7502 - val_loss: 0.5791 - val_accuracy: 0.7496\n",
      "Epoch 30/200\n",
      "2498/2498 [==============================] - 2s 966us/step - loss: 0.5811 - accuracy: 0.7507 - val_loss: 0.5814 - val_accuracy: 0.7507\n",
      "Epoch 31/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5809 - accuracy: 0.7509 - val_loss: 0.5800 - val_accuracy: 0.7516\n",
      "Epoch 32/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5810 - accuracy: 0.7505 - val_loss: 0.5805 - val_accuracy: 0.7515\n",
      "Epoch 33/200\n",
      "2498/2498 [==============================] - 2s 901us/step - loss: 0.5808 - accuracy: 0.7506 - val_loss: 0.5821 - val_accuracy: 0.7531\n",
      "Epoch 34/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5807 - accuracy: 0.7505 - val_loss: 0.5786 - val_accuracy: 0.7508\n",
      "Epoch 35/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5804 - accuracy: 0.7505 - val_loss: 0.5790 - val_accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5803 - accuracy: 0.7510 - val_loss: 0.5789 - val_accuracy: 0.7491\n",
      "Epoch 37/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5801 - accuracy: 0.7505 - val_loss: 0.5778 - val_accuracy: 0.7523\n",
      "Epoch 38/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5800 - accuracy: 0.7508 - val_loss: 0.5801 - val_accuracy: 0.7480\n",
      "Epoch 39/200\n",
      "2498/2498 [==============================] - 2s 824us/step - loss: 0.5797 - accuracy: 0.7507 - val_loss: 0.5768 - val_accuracy: 0.7516\n",
      "Epoch 40/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5796 - accuracy: 0.7511 - val_loss: 0.5780 - val_accuracy: 0.7503\n",
      "Epoch 41/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5792 - accuracy: 0.7511 - val_loss: 0.5812 - val_accuracy: 0.7477\n",
      "Epoch 42/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5790 - accuracy: 0.7507 - val_loss: 0.5849 - val_accuracy: 0.7517\n",
      "Epoch 43/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7509 - val_loss: 0.5865 - val_accuracy: 0.7506\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 2s 993us/step - loss: 0.5789 - accuracy: 0.7510 - val_loss: 0.5764 - val_accuracy: 0.7516\n",
      "Epoch 45/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5787 - accuracy: 0.7510 - val_loss: 0.5775 - val_accuracy: 0.7489\n",
      "Epoch 46/200\n",
      "2498/2498 [==============================] - 2s 943us/step - loss: 0.5781 - accuracy: 0.7513 - val_loss: 0.5796 - val_accuracy: 0.7529\n",
      "Epoch 47/200\n",
      "2498/2498 [==============================] - 2s 931us/step - loss: 0.5780 - accuracy: 0.7512 - val_loss: 0.5781 - val_accuracy: 0.7489\n",
      "Epoch 48/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5779 - accuracy: 0.7512 - val_loss: 0.5768 - val_accuracy: 0.7522\n",
      "Epoch 49/200\n",
      "2498/2498 [==============================] - 2s 820us/step - loss: 0.5775 - accuracy: 0.7514 - val_loss: 0.5758 - val_accuracy: 0.7511\n",
      "Epoch 50/200\n",
      "2498/2498 [==============================] - 2s 746us/step - loss: 0.5774 - accuracy: 0.7520 - val_loss: 0.5749 - val_accuracy: 0.7503\n",
      "Epoch 51/200\n",
      "2498/2498 [==============================] - 2s 900us/step - loss: 0.5773 - accuracy: 0.7513 - val_loss: 0.5927 - val_accuracy: 0.7411\n",
      "Epoch 52/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5770 - accuracy: 0.7508 - val_loss: 0.5744 - val_accuracy: 0.7524\n",
      "Epoch 53/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5770 - accuracy: 0.7516 - val_loss: 0.5744 - val_accuracy: 0.7513\n",
      "Epoch 54/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5769 - accuracy: 0.7511 - val_loss: 0.5768 - val_accuracy: 0.7493\n",
      "Epoch 55/200\n",
      "2498/2498 [==============================] - 2s 959us/step - loss: 0.5768 - accuracy: 0.7513 - val_loss: 0.5747 - val_accuracy: 0.7522\n",
      "Epoch 56/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5764 - accuracy: 0.7513 - val_loss: 0.5798 - val_accuracy: 0.7517\n",
      "Epoch 57/200\n",
      "2498/2498 [==============================] - 2s 973us/step - loss: 0.5764 - accuracy: 0.7520 - val_loss: 0.5895 - val_accuracy: 0.7494\n",
      "Epoch 58/200\n",
      "2498/2498 [==============================] - 2s 987us/step - loss: 0.5762 - accuracy: 0.7518 - val_loss: 0.5797 - val_accuracy: 0.7525\n",
      "Epoch 59/200\n",
      "2498/2498 [==============================] - 2s 929us/step - loss: 0.5760 - accuracy: 0.7514 - val_loss: 0.5741 - val_accuracy: 0.7524\n",
      "Epoch 60/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5756 - accuracy: 0.7521 - val_loss: 0.5839 - val_accuracy: 0.7504\n",
      "Epoch 61/200\n",
      "2498/2498 [==============================] - 2s 800us/step - loss: 0.5760 - accuracy: 0.7512 - val_loss: 0.5758 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5756 - accuracy: 0.7518 - val_loss: 0.5740 - val_accuracy: 0.7519\n",
      "Epoch 63/200\n",
      "2498/2498 [==============================] - 2s 1000us/step - loss: 0.5756 - accuracy: 0.7521 - val_loss: 0.5760 - val_accuracy: 0.7504\n",
      "Epoch 64/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5754 - accuracy: 0.7518 - val_loss: 0.5750 - val_accuracy: 0.7517\n",
      "Epoch 65/200\n",
      "2498/2498 [==============================] - 2s 889us/step - loss: 0.5754 - accuracy: 0.7522 - val_loss: 0.5773 - val_accuracy: 0.7495\n",
      "Epoch 66/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5753 - accuracy: 0.7520 - val_loss: 0.5761 - val_accuracy: 0.7526\n",
      "Epoch 67/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5750 - accuracy: 0.7516 - val_loss: 0.5785 - val_accuracy: 0.7485\n",
      "Epoch 68/200\n",
      "2498/2498 [==============================] - 2s 969us/step - loss: 0.5749 - accuracy: 0.7517 - val_loss: 0.5769 - val_accuracy: 0.7524\n",
      "Epoch 69/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5746 - accuracy: 0.7524 - val_loss: 0.5772 - val_accuracy: 0.7526\n",
      "Epoch 70/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5744 - accuracy: 0.7521 - val_loss: 0.5816 - val_accuracy: 0.7459\n",
      "Epoch 71/200\n",
      "2498/2498 [==============================] - 2s 857us/step - loss: 0.5744 - accuracy: 0.7521 - val_loss: 0.5859 - val_accuracy: 0.7451\n",
      "Epoch 72/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5741 - accuracy: 0.7518 - val_loss: 0.5761 - val_accuracy: 0.7526\n",
      "Epoch 73/200\n",
      "2498/2498 [==============================] - 2s 910us/step - loss: 0.5742 - accuracy: 0.7520 - val_loss: 0.5919 - val_accuracy: 0.7429\n",
      "Epoch 74/200\n",
      "2498/2498 [==============================] - 2s 977us/step - loss: 0.5742 - accuracy: 0.7523 - val_loss: 0.5779 - val_accuracy: 0.7491\n",
      "Epoch 75/200\n",
      "2498/2498 [==============================] - 2s 830us/step - loss: 0.5740 - accuracy: 0.7525 - val_loss: 0.5829 - val_accuracy: 0.7511\n",
      "Epoch 76/200\n",
      "2498/2498 [==============================] - 2s 979us/step - loss: 0.5741 - accuracy: 0.7517 - val_loss: 0.5719 - val_accuracy: 0.7511\n",
      "Epoch 77/200\n",
      "2498/2498 [==============================] - 2s 925us/step - loss: 0.5738 - accuracy: 0.7521 - val_loss: 0.5797 - val_accuracy: 0.7471\n",
      "Epoch 78/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5738 - accuracy: 0.7522 - val_loss: 0.5771 - val_accuracy: 0.7492\n",
      "Epoch 79/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5735 - accuracy: 0.7526 - val_loss: 0.5700 - val_accuracy: 0.7527\n",
      "Epoch 80/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7519 - val_loss: 0.5741 - val_accuracy: 0.7510\n",
      "Epoch 81/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5733 - accuracy: 0.7524 - val_loss: 0.5763 - val_accuracy: 0.7515\n",
      "Epoch 82/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7521 - val_loss: 0.5743 - val_accuracy: 0.7502\n",
      "Epoch 83/200\n",
      "2498/2498 [==============================] - 2s 992us/step - loss: 0.5733 - accuracy: 0.7520 - val_loss: 0.5716 - val_accuracy: 0.7535\n",
      "Epoch 84/200\n",
      "2498/2498 [==============================] - 2s 921us/step - loss: 0.5732 - accuracy: 0.7520 - val_loss: 0.5710 - val_accuracy: 0.7532\n",
      "Epoch 85/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5729 - accuracy: 0.7524 - val_loss: 0.5753 - val_accuracy: 0.7505\n",
      "Epoch 86/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7521 - val_loss: 0.5739 - val_accuracy: 0.7530\n",
      "Epoch 87/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5731 - accuracy: 0.7519 - val_loss: 0.5745 - val_accuracy: 0.7494\n",
      "Epoch 88/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7524 - val_loss: 0.5706 - val_accuracy: 0.7524\n",
      "Epoch 89/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5729 - accuracy: 0.7522 - val_loss: 0.5709 - val_accuracy: 0.7517\n",
      "Epoch 90/200\n",
      "2498/2498 [==============================] - 2s 914us/step - loss: 0.5728 - accuracy: 0.7524 - val_loss: 0.5740 - val_accuracy: 0.7498\n",
      "Epoch 91/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5726 - accuracy: 0.7519 - val_loss: 0.5711 - val_accuracy: 0.7517\n",
      "Epoch 92/200\n",
      "2498/2498 [==============================] - 2s 902us/step - loss: 0.5726 - accuracy: 0.7519 - val_loss: 0.5773 - val_accuracy: 0.7487\n",
      "Epoch 93/200\n",
      "2498/2498 [==============================] - 2s 933us/step - loss: 0.5724 - accuracy: 0.7518 - val_loss: 0.5738 - val_accuracy: 0.7533\n",
      "Epoch 94/200\n",
      "2498/2498 [==============================] - 2s 959us/step - loss: 0.5724 - accuracy: 0.7524 - val_loss: 0.5870 - val_accuracy: 0.7442\n",
      "Epoch 95/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5722 - accuracy: 0.7520 - val_loss: 0.5707 - val_accuracy: 0.7521\n",
      "Epoch 96/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7522 - val_loss: 0.5847 - val_accuracy: 0.7449\n",
      "Epoch 97/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7523 - val_loss: 0.5760 - val_accuracy: 0.7505\n",
      "Epoch 98/200\n",
      "2498/2498 [==============================] - 2s 981us/step - loss: 0.5720 - accuracy: 0.7521 - val_loss: 0.5756 - val_accuracy: 0.7517\n",
      "Epoch 99/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7524 - val_loss: 0.5711 - val_accuracy: 0.7529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "2498/2498 [==============================] - 2s 899us/step - loss: 0.5719 - accuracy: 0.7529 - val_loss: 0.5713 - val_accuracy: 0.7519\n",
      "Epoch 101/200\n",
      "2498/2498 [==============================] - 2s 930us/step - loss: 0.5719 - accuracy: 0.7520 - val_loss: 0.5776 - val_accuracy: 0.7484\n",
      "Epoch 102/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5718 - accuracy: 0.7523 - val_loss: 0.5712 - val_accuracy: 0.7521\n",
      "Epoch 103/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5718 - accuracy: 0.7525 - val_loss: 0.5752 - val_accuracy: 0.7498\n",
      "Epoch 104/200\n",
      "2498/2498 [==============================] - 2s 938us/step - loss: 0.5716 - accuracy: 0.7524 - val_loss: 0.6055 - val_accuracy: 0.7421\n",
      "Epoch 105/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5716 - accuracy: 0.7521 - val_loss: 0.5736 - val_accuracy: 0.7502\n",
      "Epoch 106/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5715 - accuracy: 0.7524 - val_loss: 0.5690 - val_accuracy: 0.7516\n",
      "Epoch 107/200\n",
      "2498/2498 [==============================] - 2s 844us/step - loss: 0.5714 - accuracy: 0.7526 - val_loss: 0.5684 - val_accuracy: 0.7518\n",
      "Epoch 108/200\n",
      "2498/2498 [==============================] - 2s 971us/step - loss: 0.5717 - accuracy: 0.7526 - val_loss: 0.5752 - val_accuracy: 0.7485\n",
      "Epoch 109/200\n",
      "2498/2498 [==============================] - 2s 855us/step - loss: 0.5714 - accuracy: 0.7527 - val_loss: 0.5810 - val_accuracy: 0.7504\n",
      "Epoch 110/200\n",
      "2498/2498 [==============================] - 2s 913us/step - loss: 0.5712 - accuracy: 0.7522 - val_loss: 0.5698 - val_accuracy: 0.7525\n",
      "Epoch 111/200\n",
      "2498/2498 [==============================] - 2s 882us/step - loss: 0.5711 - accuracy: 0.7524 - val_loss: 0.5738 - val_accuracy: 0.7501\n",
      "Epoch 112/200\n",
      "2498/2498 [==============================] - 2s 951us/step - loss: 0.5711 - accuracy: 0.7518 - val_loss: 0.5733 - val_accuracy: 0.7520\n",
      "Epoch 113/200\n",
      "2498/2498 [==============================] - 2s 921us/step - loss: 0.5712 - accuracy: 0.7519 - val_loss: 0.5723 - val_accuracy: 0.7515\n",
      "Epoch 114/200\n",
      "2498/2498 [==============================] - 2s 949us/step - loss: 0.5710 - accuracy: 0.7525 - val_loss: 0.5710 - val_accuracy: 0.7523\n",
      "Epoch 115/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5710 - accuracy: 0.7528 - val_loss: 0.5682 - val_accuracy: 0.7526\n",
      "Epoch 116/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7529 - val_loss: 0.5694 - val_accuracy: 0.7523\n",
      "Epoch 117/200\n",
      "2498/2498 [==============================] - 2s 829us/step - loss: 0.5709 - accuracy: 0.7527 - val_loss: 0.5710 - val_accuracy: 0.7512\n",
      "Epoch 118/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5707 - accuracy: 0.7525 - val_loss: 0.5714 - val_accuracy: 0.7529\n",
      "Epoch 119/200\n",
      "2498/2498 [==============================] - 2s 881us/step - loss: 0.5705 - accuracy: 0.7525 - val_loss: 0.5720 - val_accuracy: 0.7498\n",
      "Epoch 120/200\n",
      "2498/2498 [==============================] - 2s 989us/step - loss: 0.5707 - accuracy: 0.7524 - val_loss: 0.5756 - val_accuracy: 0.7517\n",
      "Epoch 121/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5705 - accuracy: 0.7530 - val_loss: 0.5691 - val_accuracy: 0.7514\n",
      "Epoch 122/200\n",
      "2498/2498 [==============================] - 2s 939us/step - loss: 0.5703 - accuracy: 0.7524 - val_loss: 0.5684 - val_accuracy: 0.7528\n",
      "Epoch 123/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7522 - val_loss: 0.5702 - val_accuracy: 0.7515\n",
      "Epoch 124/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7525 - val_loss: 0.5690 - val_accuracy: 0.7514\n",
      "Epoch 125/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5705 - accuracy: 0.7527 - val_loss: 0.5730 - val_accuracy: 0.7505\n",
      "Epoch 126/200\n",
      "2498/2498 [==============================] - 2s 921us/step - loss: 0.5704 - accuracy: 0.7528 - val_loss: 0.5686 - val_accuracy: 0.7528\n",
      "Epoch 127/200\n",
      "2498/2498 [==============================] - 2s 961us/step - loss: 0.5701 - accuracy: 0.7528 - val_loss: 0.5678 - val_accuracy: 0.7526\n",
      "Epoch 128/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5702 - accuracy: 0.7523 - val_loss: 0.5691 - val_accuracy: 0.7525\n",
      "Epoch 129/200\n",
      "2498/2498 [==============================] - 2s 967us/step - loss: 0.5701 - accuracy: 0.7522 - val_loss: 0.5680 - val_accuracy: 0.7523\n",
      "Epoch 130/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5701 - accuracy: 0.7525 - val_loss: 0.5691 - val_accuracy: 0.7518\n",
      "Epoch 131/200\n",
      "2498/2498 [==============================] - 2s 997us/step - loss: 0.5701 - accuracy: 0.7521 - val_loss: 0.5788 - val_accuracy: 0.7478\n",
      "Epoch 132/200\n",
      "2498/2498 [==============================] - 2s 906us/step - loss: 0.5700 - accuracy: 0.7529 - val_loss: 0.5724 - val_accuracy: 0.7529\n",
      "Epoch 133/200\n",
      "2498/2498 [==============================] - 2s 933us/step - loss: 0.5699 - accuracy: 0.7523 - val_loss: 0.5691 - val_accuracy: 0.7534\n",
      "Epoch 134/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7522 - val_loss: 0.5743 - val_accuracy: 0.7514\n",
      "Epoch 135/200\n",
      "2498/2498 [==============================] - 2s 977us/step - loss: 0.5698 - accuracy: 0.7525 - val_loss: 0.5684 - val_accuracy: 0.7526\n",
      "Epoch 136/200\n",
      "2498/2498 [==============================] - 2s 982us/step - loss: 0.5699 - accuracy: 0.7523 - val_loss: 0.5757 - val_accuracy: 0.7522\n",
      "Epoch 137/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7525 - val_loss: 0.5690 - val_accuracy: 0.7515\n",
      "Epoch 138/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7523 - val_loss: 0.5715 - val_accuracy: 0.7524\n",
      "Epoch 139/200\n",
      "2498/2498 [==============================] - 2s 784us/step - loss: 0.5698 - accuracy: 0.7525 - val_loss: 0.5712 - val_accuracy: 0.7494\n",
      "Epoch 140/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7524 - val_loss: 0.5680 - val_accuracy: 0.7521\n",
      "Epoch 141/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5696 - accuracy: 0.7530 - val_loss: 0.5675 - val_accuracy: 0.7516\n",
      "Epoch 142/200\n",
      "2498/2498 [==============================] - 2s 942us/step - loss: 0.5697 - accuracy: 0.7527 - val_loss: 0.5711 - val_accuracy: 0.7520\n",
      "Epoch 143/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5696 - accuracy: 0.7525 - val_loss: 0.5689 - val_accuracy: 0.7520\n",
      "Epoch 144/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5696 - accuracy: 0.7524 - val_loss: 0.5680 - val_accuracy: 0.7519\n",
      "Epoch 145/200\n",
      "2498/2498 [==============================] - 2s 978us/step - loss: 0.5696 - accuracy: 0.7525 - val_loss: 0.5679 - val_accuracy: 0.7520\n",
      "Epoch 146/200\n",
      "2498/2498 [==============================] - 2s 877us/step - loss: 0.5695 - accuracy: 0.7527 - val_loss: 0.5700 - val_accuracy: 0.7514\n",
      "Epoch 147/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5693 - accuracy: 0.7526 - val_loss: 0.5680 - val_accuracy: 0.7524\n",
      "Epoch 148/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5693 - accuracy: 0.7524 - val_loss: 0.5795 - val_accuracy: 0.7513\n",
      "Epoch 149/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5696 - accuracy: 0.7525 - val_loss: 0.5707 - val_accuracy: 0.7512\n",
      "Epoch 150/200\n",
      "2498/2498 [==============================] - 2s 957us/step - loss: 0.5694 - accuracy: 0.7527 - val_loss: 0.5813 - val_accuracy: 0.7508\n",
      "Epoch 151/200\n",
      "2498/2498 [==============================] - 2s 852us/step - loss: 0.5694 - accuracy: 0.7527 - val_loss: 0.5678 - val_accuracy: 0.7529\n",
      "Epoch 152/200\n",
      "2498/2498 [==============================] - 2s 828us/step - loss: 0.5692 - accuracy: 0.7526 - val_loss: 0.5683 - val_accuracy: 0.7513\n",
      "Epoch 153/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5692 - accuracy: 0.7529 - val_loss: 0.5692 - val_accuracy: 0.7519\n",
      "Epoch 154/200\n",
      "2498/2498 [==============================] - 2s 912us/step - loss: 0.5692 - accuracy: 0.7527 - val_loss: 0.5673 - val_accuracy: 0.7524\n",
      "Epoch 155/200\n",
      "2498/2498 [==============================] - 2s 999us/step - loss: 0.5691 - accuracy: 0.7525 - val_loss: 0.5676 - val_accuracy: 0.7513\n",
      "Epoch 156/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5691 - accuracy: 0.7525 - val_loss: 0.5799 - val_accuracy: 0.7503\n",
      "Epoch 157/200\n",
      "2498/2498 [==============================] - 2s 895us/step - loss: 0.5691 - accuracy: 0.7526 - val_loss: 0.5676 - val_accuracy: 0.7524\n",
      "Epoch 158/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5691 - accuracy: 0.7527 - val_loss: 0.5673 - val_accuracy: 0.7533\n",
      "Epoch 159/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5691 - accuracy: 0.7528 - val_loss: 0.5708 - val_accuracy: 0.7531\n",
      "Epoch 160/200\n",
      "2498/2498 [==============================] - 2s 931us/step - loss: 0.5689 - accuracy: 0.7527 - val_loss: 0.5797 - val_accuracy: 0.7477\n",
      "Epoch 161/200\n",
      "2498/2498 [==============================] - 2s 985us/step - loss: 0.5689 - accuracy: 0.7527 - val_loss: 0.5705 - val_accuracy: 0.7507\n",
      "Epoch 162/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5688 - accuracy: 0.7527 - val_loss: 0.5685 - val_accuracy: 0.7523\n",
      "Epoch 163/200\n",
      "2498/2498 [==============================] - 2s 917us/step - loss: 0.5689 - accuracy: 0.7524 - val_loss: 0.5672 - val_accuracy: 0.7518\n",
      "Epoch 164/200\n",
      "2498/2498 [==============================] - 2s 927us/step - loss: 0.5687 - accuracy: 0.7525 - val_loss: 0.5719 - val_accuracy: 0.7520\n",
      "Epoch 165/200\n",
      "2498/2498 [==============================] - 2s 809us/step - loss: 0.5687 - accuracy: 0.7525 - val_loss: 0.5669 - val_accuracy: 0.7521\n",
      "Epoch 166/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7524 - val_loss: 0.5676 - val_accuracy: 0.7518\n",
      "Epoch 167/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5688 - accuracy: 0.7524 - val_loss: 0.5696 - val_accuracy: 0.7509\n",
      "Epoch 168/200\n",
      "2498/2498 [==============================] - 2s 799us/step - loss: 0.5686 - accuracy: 0.7532 - val_loss: 0.5689 - val_accuracy: 0.7508\n",
      "Epoch 169/200\n",
      "2498/2498 [==============================] - 2s 835us/step - loss: 0.5687 - accuracy: 0.7529 - val_loss: 0.5717 - val_accuracy: 0.7530\n",
      "Epoch 170/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7527 - val_loss: 0.5685 - val_accuracy: 0.7505\n",
      "Epoch 171/200\n",
      "2498/2498 [==============================] - 2s 980us/step - loss: 0.5686 - accuracy: 0.7528 - val_loss: 0.5681 - val_accuracy: 0.7517\n",
      "Epoch 172/200\n",
      "2498/2498 [==============================] - 2s 830us/step - loss: 0.5686 - accuracy: 0.7528 - val_loss: 0.5759 - val_accuracy: 0.7518\n",
      "Epoch 173/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7526 - val_loss: 0.5678 - val_accuracy: 0.7518\n",
      "Epoch 174/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7525 - val_loss: 0.5681 - val_accuracy: 0.7526\n",
      "Epoch 175/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7528 - val_loss: 0.5727 - val_accuracy: 0.7528\n",
      "Epoch 176/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7528 - val_loss: 0.5688 - val_accuracy: 0.7506\n",
      "Epoch 177/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7528 - val_loss: 0.5669 - val_accuracy: 0.7521\n",
      "Epoch 178/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7527 - val_loss: 0.5674 - val_accuracy: 0.7515\n",
      "Epoch 179/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7525 - val_loss: 0.5665 - val_accuracy: 0.7525\n",
      "Epoch 180/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7524 - val_loss: 0.5745 - val_accuracy: 0.7485\n",
      "Epoch 181/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7526 - val_loss: 0.5694 - val_accuracy: 0.7517\n",
      "Epoch 182/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7527 - val_loss: 0.5671 - val_accuracy: 0.7520\n",
      "Epoch 183/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7529 - val_loss: 0.5668 - val_accuracy: 0.7526\n",
      "Epoch 184/200\n",
      "2498/2498 [==============================] - 2s 861us/step - loss: 0.5681 - accuracy: 0.7528 - val_loss: 0.5664 - val_accuracy: 0.7520\n",
      "Epoch 185/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7526 - val_loss: 0.5675 - val_accuracy: 0.7525\n",
      "Epoch 186/200\n",
      "2498/2498 [==============================] - 2s 937us/step - loss: 0.5683 - accuracy: 0.7528 - val_loss: 0.5672 - val_accuracy: 0.7528\n",
      "Epoch 187/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7530 - val_loss: 0.5683 - val_accuracy: 0.7503\n",
      "Epoch 188/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7529 - val_loss: 0.5692 - val_accuracy: 0.7512\n",
      "Epoch 189/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7527 - val_loss: 0.5661 - val_accuracy: 0.7528\n",
      "Epoch 190/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7529 - val_loss: 0.5720 - val_accuracy: 0.7515\n",
      "Epoch 191/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7528 - val_loss: 0.5677 - val_accuracy: 0.7513\n",
      "Epoch 192/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7533 - val_loss: 0.5666 - val_accuracy: 0.7528\n",
      "Epoch 193/200\n",
      "2498/2498 [==============================] - 2s 972us/step - loss: 0.5682 - accuracy: 0.7527 - val_loss: 0.5682 - val_accuracy: 0.7522\n",
      "Epoch 194/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7521 - val_loss: 0.5701 - val_accuracy: 0.7526\n",
      "Epoch 195/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7527 - val_loss: 0.5693 - val_accuracy: 0.7508\n",
      "Epoch 196/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7525 - val_loss: 0.5663 - val_accuracy: 0.7526\n",
      "Epoch 197/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7529 - val_loss: 0.5683 - val_accuracy: 0.7522\n",
      "Epoch 198/200\n",
      "2498/2498 [==============================] - 2s 890us/step - loss: 0.5680 - accuracy: 0.7526 - val_loss: 0.5700 - val_accuracy: 0.7505\n",
      "Epoch 199/200\n",
      "2498/2498 [==============================] - 2s 998us/step - loss: 0.5679 - accuracy: 0.7528 - val_loss: 0.5671 - val_accuracy: 0.7529\n",
      "Epoch 200/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7531 - val_loss: 0.5694 - val_accuracy: 0.7527\n",
      "4441/4441 [==============================] - 2s 466us/step - loss: 1.3028 - accuracy: 0.4431\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x0000019CAD688DC0>\n",
      "Epoch Sizes:  200\n",
      "Neurons or Units:  64\n",
      "Test score: 1.3027691841125488\n",
      "Test accuracy: 0.44308072328567505\n",
      "\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6569 - accuracy: 0.7418 - val_loss: 0.6130 - val_accuracy: 0.7433\n",
      "Epoch 2/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6060 - accuracy: 0.7479 - val_loss: 0.6012 - val_accuracy: 0.7502\n",
      "Epoch 3/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5983 - accuracy: 0.7486 - val_loss: 0.5982 - val_accuracy: 0.7495\n",
      "Epoch 4/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5943 - accuracy: 0.7488 - val_loss: 0.5932 - val_accuracy: 0.7515\n",
      "Epoch 5/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5917 - accuracy: 0.7490 - val_loss: 0.5905 - val_accuracy: 0.7455\n",
      "Epoch 6/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5901 - accuracy: 0.7495 - val_loss: 0.5917 - val_accuracy: 0.7488\n",
      "Epoch 7/200\n",
      "2498/2498 [==============================] - 2s 969us/step - loss: 0.5887 - accuracy: 0.7490 - val_loss: 0.5967 - val_accuracy: 0.7517\n",
      "Epoch 8/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5875 - accuracy: 0.7492 - val_loss: 0.5852 - val_accuracy: 0.7491\n",
      "Epoch 9/200\n",
      "2498/2498 [==============================] - 2s 890us/step - loss: 0.5865 - accuracy: 0.7493 - val_loss: 0.5839 - val_accuracy: 0.7490\n",
      "Epoch 10/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5853 - accuracy: 0.7499 - val_loss: 0.5858 - val_accuracy: 0.7510\n",
      "Epoch 11/200\n",
      "2498/2498 [==============================] - 2s 886us/step - loss: 0.5846 - accuracy: 0.7495 - val_loss: 0.5817 - val_accuracy: 0.7495\n",
      "Epoch 12/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5834 - accuracy: 0.7501 - val_loss: 0.5807 - val_accuracy: 0.7510\n",
      "Epoch 13/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5825 - accuracy: 0.7501 - val_loss: 0.5883 - val_accuracy: 0.7516\n",
      "Epoch 14/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5818 - accuracy: 0.7508 - val_loss: 0.6006 - val_accuracy: 0.7395\n",
      "Epoch 15/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5810 - accuracy: 0.7511 - val_loss: 0.5844 - val_accuracy: 0.7468\n",
      "Epoch 16/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5802 - accuracy: 0.7503 - val_loss: 0.5770 - val_accuracy: 0.7513\n",
      "Epoch 17/200\n",
      "2498/2498 [==============================] - 2s 992us/step - loss: 0.5796 - accuracy: 0.7509 - val_loss: 0.5750 - val_accuracy: 0.7521\n",
      "Epoch 18/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7507 - val_loss: 0.5801 - val_accuracy: 0.7488\n",
      "Epoch 19/200\n",
      "2498/2498 [==============================] - 2s 984us/step - loss: 0.5784 - accuracy: 0.7509 - val_loss: 0.5766 - val_accuracy: 0.7507\n",
      "Epoch 20/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5780 - accuracy: 0.7511 - val_loss: 0.5742 - val_accuracy: 0.7517\n",
      "Epoch 21/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5773 - accuracy: 0.7510 - val_loss: 0.5777 - val_accuracy: 0.7495\n",
      "Epoch 22/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5773 - accuracy: 0.7510 - val_loss: 0.5750 - val_accuracy: 0.7521\n",
      "Epoch 23/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5765 - accuracy: 0.7511 - val_loss: 0.5775 - val_accuracy: 0.7488\n",
      "Epoch 24/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5763 - accuracy: 0.7509 - val_loss: 0.5725 - val_accuracy: 0.7519\n",
      "Epoch 25/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5759 - accuracy: 0.7513 - val_loss: 0.5721 - val_accuracy: 0.7522\n",
      "Epoch 26/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5754 - accuracy: 0.7517 - val_loss: 0.5739 - val_accuracy: 0.7514\n",
      "Epoch 27/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5751 - accuracy: 0.7512 - val_loss: 0.5740 - val_accuracy: 0.7507\n",
      "Epoch 28/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5750 - accuracy: 0.7511 - val_loss: 0.5729 - val_accuracy: 0.7525\n",
      "Epoch 29/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5747 - accuracy: 0.7511 - val_loss: 0.5726 - val_accuracy: 0.7525\n",
      "Epoch 30/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5742 - accuracy: 0.7521 - val_loss: 0.5717 - val_accuracy: 0.7526\n",
      "Epoch 31/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5741 - accuracy: 0.7519 - val_loss: 0.5729 - val_accuracy: 0.7505\n",
      "Epoch 32/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7515 - val_loss: 0.5701 - val_accuracy: 0.7517\n",
      "Epoch 33/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5735 - accuracy: 0.7521 - val_loss: 0.5768 - val_accuracy: 0.7510\n",
      "Epoch 34/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5732 - accuracy: 0.7522 - val_loss: 0.5765 - val_accuracy: 0.7499\n",
      "Epoch 35/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5729 - accuracy: 0.7519 - val_loss: 0.5711 - val_accuracy: 0.7534\n",
      "Epoch 36/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5729 - accuracy: 0.7514 - val_loss: 0.5717 - val_accuracy: 0.7514\n",
      "Epoch 37/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5726 - accuracy: 0.7523 - val_loss: 0.5698 - val_accuracy: 0.7521\n",
      "Epoch 38/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5726 - accuracy: 0.7516 - val_loss: 0.5705 - val_accuracy: 0.7528\n",
      "Epoch 39/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5722 - accuracy: 0.7519 - val_loss: 0.5701 - val_accuracy: 0.7527\n",
      "Epoch 40/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5719 - accuracy: 0.7518 - val_loss: 0.5874 - val_accuracy: 0.7458\n",
      "Epoch 41/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5719 - accuracy: 0.7520 - val_loss: 0.5707 - val_accuracy: 0.7523\n",
      "Epoch 42/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5716 - accuracy: 0.7518 - val_loss: 0.5713 - val_accuracy: 0.7516\n",
      "Epoch 43/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5716 - accuracy: 0.7519 - val_loss: 0.5696 - val_accuracy: 0.7514\n",
      "Epoch 44/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7523 - val_loss: 0.5696 - val_accuracy: 0.7523\n",
      "Epoch 45/200\n",
      "2498/2498 [==============================] - 2s 887us/step - loss: 0.5712 - accuracy: 0.7519 - val_loss: 0.5704 - val_accuracy: 0.7516\n",
      "Epoch 46/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5710 - accuracy: 0.7520 - val_loss: 0.5767 - val_accuracy: 0.7486\n",
      "Epoch 47/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5708 - accuracy: 0.7522 - val_loss: 0.5675 - val_accuracy: 0.7525\n",
      "Epoch 48/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5705 - accuracy: 0.7522 - val_loss: 0.5706 - val_accuracy: 0.7514\n",
      "Epoch 49/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5705 - accuracy: 0.7520 - val_loss: 0.5731 - val_accuracy: 0.7496\n",
      "Epoch 50/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5702 - accuracy: 0.7520 - val_loss: 0.5703 - val_accuracy: 0.7528\n",
      "Epoch 51/200\n",
      "2498/2498 [==============================] - 2s 991us/step - loss: 0.5703 - accuracy: 0.7526 - val_loss: 0.5678 - val_accuracy: 0.7525\n",
      "Epoch 52/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7522 - val_loss: 0.5865 - val_accuracy: 0.7462\n",
      "Epoch 53/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7521 - val_loss: 0.5702 - val_accuracy: 0.7505\n",
      "Epoch 54/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7522 - val_loss: 0.5698 - val_accuracy: 0.7517\n",
      "Epoch 55/200\n",
      "2498/2498 [==============================] - 2s 880us/step - loss: 0.5699 - accuracy: 0.7524 - val_loss: 0.5674 - val_accuracy: 0.7524\n",
      "Epoch 56/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7524 - val_loss: 0.5686 - val_accuracy: 0.7530\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7521 - val_loss: 0.5725 - val_accuracy: 0.7510\n",
      "Epoch 58/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5695 - accuracy: 0.7522 - val_loss: 0.5879 - val_accuracy: 0.7468\n",
      "Epoch 59/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5694 - accuracy: 0.7522 - val_loss: 0.5718 - val_accuracy: 0.7512\n",
      "Epoch 60/200\n",
      "2498/2498 [==============================] - 2s 952us/step - loss: 0.5695 - accuracy: 0.7521 - val_loss: 0.5717 - val_accuracy: 0.7516\n",
      "Epoch 61/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5692 - accuracy: 0.7525 - val_loss: 0.5917 - val_accuracy: 0.7442\n",
      "Epoch 62/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7515 - val_loss: 0.5712 - val_accuracy: 0.7505\n",
      "Epoch 63/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7526 - val_loss: 0.5674 - val_accuracy: 0.7519\n",
      "Epoch 64/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5689 - accuracy: 0.7524 - val_loss: 0.5695 - val_accuracy: 0.7521\n",
      "Epoch 65/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5689 - accuracy: 0.7523 - val_loss: 0.5684 - val_accuracy: 0.7516\n",
      "Epoch 66/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7523 - val_loss: 0.5748 - val_accuracy: 0.7506\n",
      "Epoch 67/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7522 - val_loss: 0.5669 - val_accuracy: 0.7520\n",
      "Epoch 68/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7522 - val_loss: 0.5678 - val_accuracy: 0.7520\n",
      "Epoch 69/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5688 - accuracy: 0.7521 - val_loss: 0.5713 - val_accuracy: 0.7515\n",
      "Epoch 70/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7526 - val_loss: 0.5687 - val_accuracy: 0.7508\n",
      "Epoch 71/200\n",
      "2498/2498 [==============================] - 2s 947us/step - loss: 0.5686 - accuracy: 0.7524 - val_loss: 0.5666 - val_accuracy: 0.7521\n",
      "Epoch 72/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7519 - val_loss: 0.5921 - val_accuracy: 0.7458\n",
      "Epoch 73/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5684 - accuracy: 0.7523 - val_loss: 0.5659 - val_accuracy: 0.7521\n",
      "Epoch 74/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5684 - accuracy: 0.7522 - val_loss: 0.5671 - val_accuracy: 0.7514\n",
      "Epoch 75/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7519 - val_loss: 0.5780 - val_accuracy: 0.7457\n",
      "Epoch 76/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7527 - val_loss: 0.5777 - val_accuracy: 0.7493\n",
      "Epoch 77/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7524 - val_loss: 0.5735 - val_accuracy: 0.7496\n",
      "Epoch 78/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5678 - accuracy: 0.7521 - val_loss: 0.5696 - val_accuracy: 0.7510\n",
      "Epoch 79/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7523 - val_loss: 0.5908 - val_accuracy: 0.7439\n",
      "Epoch 80/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7520 - val_loss: 0.5729 - val_accuracy: 0.7509\n",
      "Epoch 81/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7522 - val_loss: 0.5714 - val_accuracy: 0.7507\n",
      "Epoch 82/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7522 - val_loss: 0.5718 - val_accuracy: 0.7508\n",
      "Epoch 83/200\n",
      "2498/2498 [==============================] - 2s 903us/step - loss: 0.5679 - accuracy: 0.7525 - val_loss: 0.5663 - val_accuracy: 0.7512\n",
      "Epoch 84/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7521 - val_loss: 0.5659 - val_accuracy: 0.7522\n",
      "Epoch 85/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7521 - val_loss: 0.5681 - val_accuracy: 0.7516\n",
      "Epoch 86/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7523 - val_loss: 0.5742 - val_accuracy: 0.7492\n",
      "Epoch 87/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7524 - val_loss: 0.5658 - val_accuracy: 0.7518\n",
      "Epoch 88/200\n",
      "2498/2498 [==============================] - 2s 941us/step - loss: 0.5675 - accuracy: 0.7522 - val_loss: 0.5673 - val_accuracy: 0.7509\n",
      "Epoch 89/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7523 - val_loss: 0.5642 - val_accuracy: 0.7528\n",
      "Epoch 90/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7525 - val_loss: 0.5696 - val_accuracy: 0.7513\n",
      "Epoch 91/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7523 - val_loss: 0.5766 - val_accuracy: 0.7479\n",
      "Epoch 92/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7520 - val_loss: 0.5651 - val_accuracy: 0.7525\n",
      "Epoch 93/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5674 - accuracy: 0.7518 - val_loss: 0.5678 - val_accuracy: 0.7509\n",
      "Epoch 94/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5674 - accuracy: 0.7520 - val_loss: 0.5660 - val_accuracy: 0.7514\n",
      "Epoch 95/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5673 - accuracy: 0.7522 - val_loss: 0.5676 - val_accuracy: 0.7519\n",
      "Epoch 96/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5673 - accuracy: 0.7517 - val_loss: 0.5664 - val_accuracy: 0.7520\n",
      "Epoch 97/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5673 - accuracy: 0.7520 - val_loss: 0.5781 - val_accuracy: 0.7491\n",
      "Epoch 98/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5673 - accuracy: 0.7521 - val_loss: 0.5673 - val_accuracy: 0.7514\n",
      "Epoch 99/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5670 - accuracy: 0.7523 - val_loss: 0.5678 - val_accuracy: 0.7499\n",
      "Epoch 100/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5672 - accuracy: 0.7518 - val_loss: 0.5658 - val_accuracy: 0.7514\n",
      "Epoch 101/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5670 - accuracy: 0.7522 - val_loss: 0.5725 - val_accuracy: 0.7501\n",
      "Epoch 102/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5671 - accuracy: 0.7519 - val_loss: 0.5660 - val_accuracy: 0.7521\n",
      "Epoch 103/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5670 - accuracy: 0.7522 - val_loss: 0.5646 - val_accuracy: 0.7517\n",
      "Epoch 104/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5670 - accuracy: 0.7521 - val_loss: 0.5856 - val_accuracy: 0.7459\n",
      "Epoch 105/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5670 - accuracy: 0.7520 - val_loss: 0.5809 - val_accuracy: 0.7466\n",
      "Epoch 106/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5668 - accuracy: 0.7524 - val_loss: 0.5713 - val_accuracy: 0.7500\n",
      "Epoch 107/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5669 - accuracy: 0.7520 - val_loss: 0.5654 - val_accuracy: 0.7520\n",
      "Epoch 108/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5669 - accuracy: 0.7523 - val_loss: 0.5660 - val_accuracy: 0.7515\n",
      "Epoch 109/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5668 - accuracy: 0.7522 - val_loss: 0.5660 - val_accuracy: 0.7518\n",
      "Epoch 110/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7520 - val_loss: 0.5938 - val_accuracy: 0.7397\n",
      "Epoch 111/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7524 - val_loss: 0.5648 - val_accuracy: 0.7522\n",
      "Epoch 112/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7515 - val_loss: 0.5684 - val_accuracy: 0.7515\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7523 - val_loss: 0.5653 - val_accuracy: 0.7513\n",
      "Epoch 114/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7520 - val_loss: 0.5698 - val_accuracy: 0.7509\n",
      "Epoch 115/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7519 - val_loss: 0.5652 - val_accuracy: 0.7514\n",
      "Epoch 116/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7521 - val_loss: 0.5635 - val_accuracy: 0.7516\n",
      "Epoch 117/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7521 - val_loss: 0.5643 - val_accuracy: 0.7526\n",
      "Epoch 118/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7520 - val_loss: 0.5768 - val_accuracy: 0.7485\n",
      "Epoch 119/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7524 - val_loss: 0.5681 - val_accuracy: 0.7518\n",
      "Epoch 120/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7523 - val_loss: 0.5652 - val_accuracy: 0.7514\n",
      "Epoch 121/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7521 - val_loss: 0.5761 - val_accuracy: 0.7485\n",
      "Epoch 122/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7525 - val_loss: 0.5695 - val_accuracy: 0.7511\n",
      "Epoch 123/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7528 - val_loss: 0.5643 - val_accuracy: 0.7533\n",
      "Epoch 124/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7526 - val_loss: 0.5861 - val_accuracy: 0.7452\n",
      "Epoch 125/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7523 - val_loss: 0.5709 - val_accuracy: 0.7505\n",
      "Epoch 126/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7521 - val_loss: 0.5767 - val_accuracy: 0.7489\n",
      "Epoch 127/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7523 - val_loss: 0.5639 - val_accuracy: 0.7525\n",
      "Epoch 128/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7518 - val_loss: 0.5663 - val_accuracy: 0.7505\n",
      "Epoch 129/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7520 - val_loss: 0.5653 - val_accuracy: 0.7507\n",
      "Epoch 130/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7523 - val_loss: 0.5652 - val_accuracy: 0.7536\n",
      "Epoch 131/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7520 - val_loss: 0.5695 - val_accuracy: 0.7501\n",
      "Epoch 132/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7520 - val_loss: 0.5725 - val_accuracy: 0.7496\n",
      "Epoch 133/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7519 - val_loss: 0.5668 - val_accuracy: 0.7509\n",
      "Epoch 134/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7520 - val_loss: 0.5719 - val_accuracy: 0.7466\n",
      "Epoch 135/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7525 - val_loss: 0.5675 - val_accuracy: 0.7498\n",
      "Epoch 136/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7523 - val_loss: 0.5661 - val_accuracy: 0.7523\n",
      "Epoch 137/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7522 - val_loss: 0.5656 - val_accuracy: 0.7523\n",
      "Epoch 138/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7529 - val_loss: 0.5684 - val_accuracy: 0.7492\n",
      "Epoch 139/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7524 - val_loss: 0.5675 - val_accuracy: 0.7511\n",
      "Epoch 140/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7524 - val_loss: 0.5648 - val_accuracy: 0.7518\n",
      "Epoch 141/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7525 - val_loss: 0.5647 - val_accuracy: 0.7516\n",
      "Epoch 142/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5659 - accuracy: 0.7525 - val_loss: 0.5688 - val_accuracy: 0.7506\n",
      "Epoch 143/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5659 - accuracy: 0.7527 - val_loss: 0.5643 - val_accuracy: 0.7525\n",
      "Epoch 144/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7523 - val_loss: 0.5659 - val_accuracy: 0.7527\n",
      "Epoch 145/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5657 - accuracy: 0.7524 - val_loss: 0.5684 - val_accuracy: 0.7511\n",
      "Epoch 146/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7523 - val_loss: 0.5646 - val_accuracy: 0.7514\n",
      "Epoch 147/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7520 - val_loss: 0.5674 - val_accuracy: 0.7523\n",
      "Epoch 148/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5656 - accuracy: 0.7522 - val_loss: 0.5654 - val_accuracy: 0.7522\n",
      "Epoch 149/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7521 - val_loss: 0.5646 - val_accuracy: 0.7523\n",
      "Epoch 150/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5656 - accuracy: 0.7525 - val_loss: 0.5661 - val_accuracy: 0.7512\n",
      "Epoch 151/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5656 - accuracy: 0.7526 - val_loss: 0.5657 - val_accuracy: 0.7505\n",
      "Epoch 152/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5656 - accuracy: 0.7527 - val_loss: 0.5653 - val_accuracy: 0.7525\n",
      "Epoch 153/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7521 - val_loss: 0.5633 - val_accuracy: 0.7524\n",
      "Epoch 154/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7529 - val_loss: 0.5661 - val_accuracy: 0.7516\n",
      "Epoch 155/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7518 - val_loss: 0.5638 - val_accuracy: 0.7514\n",
      "Epoch 156/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5656 - accuracy: 0.7521 - val_loss: 0.5669 - val_accuracy: 0.7521\n",
      "Epoch 157/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7524 - val_loss: 0.5790 - val_accuracy: 0.7479\n",
      "Epoch 158/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7518 - val_loss: 0.5689 - val_accuracy: 0.7494\n",
      "Epoch 159/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7522 - val_loss: 0.5704 - val_accuracy: 0.7507\n",
      "Epoch 160/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7521 - val_loss: 0.5654 - val_accuracy: 0.7515\n",
      "Epoch 161/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7524 - val_loss: 0.5634 - val_accuracy: 0.7525\n",
      "Epoch 162/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7520 - val_loss: 0.5634 - val_accuracy: 0.7521\n",
      "Epoch 163/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7525 - val_loss: 0.5723 - val_accuracy: 0.7507\n",
      "Epoch 164/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7527 - val_loss: 0.5665 - val_accuracy: 0.7513\n",
      "Epoch 165/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7521 - val_loss: 0.5714 - val_accuracy: 0.7479\n",
      "Epoch 166/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7530 - val_loss: 0.5670 - val_accuracy: 0.7515\n",
      "Epoch 167/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7524 - val_loss: 0.5627 - val_accuracy: 0.7530\n",
      "Epoch 168/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7526 - val_loss: 0.5640 - val_accuracy: 0.7530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7522 - val_loss: 0.5665 - val_accuracy: 0.7519\n",
      "Epoch 170/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7524 - val_loss: 0.5673 - val_accuracy: 0.7504\n",
      "Epoch 171/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7524 - val_loss: 0.5698 - val_accuracy: 0.7511\n",
      "Epoch 172/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7526 - val_loss: 0.5643 - val_accuracy: 0.7513\n",
      "Epoch 173/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7523 - val_loss: 0.5692 - val_accuracy: 0.7508\n",
      "Epoch 174/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7524 - val_loss: 0.5630 - val_accuracy: 0.7522\n",
      "Epoch 175/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7517 - val_loss: 0.5651 - val_accuracy: 0.7537\n",
      "Epoch 176/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7518 - val_loss: 0.5638 - val_accuracy: 0.7520\n",
      "Epoch 177/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7523 - val_loss: 0.5632 - val_accuracy: 0.7522\n",
      "Epoch 178/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7522 - val_loss: 0.5634 - val_accuracy: 0.7526\n",
      "Epoch 179/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5650 - accuracy: 0.7521 - val_loss: 0.5648 - val_accuracy: 0.7526\n",
      "Epoch 180/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7525 - val_loss: 0.5636 - val_accuracy: 0.7520\n",
      "Epoch 181/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7522 - val_loss: 0.5693 - val_accuracy: 0.7506\n",
      "Epoch 182/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7522 - val_loss: 0.5767 - val_accuracy: 0.7495\n",
      "Epoch 183/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7524 - val_loss: 0.5629 - val_accuracy: 0.7529\n",
      "Epoch 184/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7525 - val_loss: 0.5685 - val_accuracy: 0.7505\n",
      "Epoch 185/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7519 - val_loss: 0.5648 - val_accuracy: 0.7512\n",
      "Epoch 186/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7524 - val_loss: 0.5648 - val_accuracy: 0.7532\n",
      "Epoch 187/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7526 - val_loss: 0.5638 - val_accuracy: 0.7525\n",
      "Epoch 188/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7522 - val_loss: 0.5649 - val_accuracy: 0.7521\n",
      "Epoch 189/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7522 - val_loss: 0.5656 - val_accuracy: 0.7517\n",
      "Epoch 190/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7525 - val_loss: 0.5645 - val_accuracy: 0.7514\n",
      "Epoch 191/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7525 - val_loss: 0.5679 - val_accuracy: 0.7515\n",
      "Epoch 192/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7524 - val_loss: 0.5635 - val_accuracy: 0.7505\n",
      "Epoch 193/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7523 - val_loss: 0.5631 - val_accuracy: 0.7533\n",
      "Epoch 194/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7522 - val_loss: 0.5658 - val_accuracy: 0.7510\n",
      "Epoch 195/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5650 - accuracy: 0.7520 - val_loss: 0.5716 - val_accuracy: 0.7503\n",
      "Epoch 196/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5646 - accuracy: 0.7528 - val_loss: 0.5662 - val_accuracy: 0.7524\n",
      "Epoch 197/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5648 - accuracy: 0.7524 - val_loss: 0.5642 - val_accuracy: 0.7516\n",
      "Epoch 198/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7524 - val_loss: 0.5637 - val_accuracy: 0.7519\n",
      "Epoch 199/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7523 - val_loss: 0.5674 - val_accuracy: 0.7507\n",
      "Epoch 200/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7526 - val_loss: 0.5637 - val_accuracy: 0.7520\n",
      "4441/4441 [==============================] - 3s 702us/step - loss: 1.3134 - accuracy: 0.4449\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x0000019CAD688DC0>\n",
      "Epoch Sizes:  200\n",
      "Neurons or Units:  128\n",
      "Test score: 1.3134479522705078\n",
      "Test accuracy: 0.44485417008399963\n",
      "\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,667\n",
      "Trainable params: 4,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.6506 - accuracy: 0.7404 - val_loss: 0.6090 - val_accuracy: 0.7478\n",
      "Epoch 2/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6041 - accuracy: 0.7473 - val_loss: 0.5973 - val_accuracy: 0.7470\n",
      "Epoch 3/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5985 - accuracy: 0.7478 - val_loss: 0.5974 - val_accuracy: 0.7508\n",
      "Epoch 4/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5955 - accuracy: 0.7485 - val_loss: 0.5928 - val_accuracy: 0.7517\n",
      "Epoch 5/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5938 - accuracy: 0.7487 - val_loss: 0.5937 - val_accuracy: 0.7494\n",
      "Epoch 6/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5924 - accuracy: 0.7480 - val_loss: 0.5899 - val_accuracy: 0.7516\n",
      "Epoch 7/200\n",
      "2498/2498 [==============================] - 443s 178ms/step - loss: 0.5920 - accuracy: 0.7482 - val_loss: 0.5892 - val_accuracy: 0.7515.5920 - \n",
      "Epoch 8/200\n",
      "2498/2498 [==============================] - 30s 12ms/step - loss: 0.5913 - accuracy: 0.7483 - val_loss: 0.5882 - val_accuracy: 0.7492\n",
      "Epoch 9/200\n",
      "2498/2498 [==============================] - 23s 9ms/step - loss: 0.5908 - accuracy: 0.7483 - val_loss: 0.5849 - val_accuracy: 0.7500\n",
      "Epoch 10/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5899 - accuracy: 0.7487 - val_loss: 0.5962 - val_accuracy: 0.7406\n",
      "Epoch 11/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5895 - accuracy: 0.7484 - val_loss: 0.5896 - val_accuracy: 0.7491\n",
      "Epoch 12/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5892 - accuracy: 0.7489 - val_loss: 0.5875 - val_accuracy: 0.7508\n",
      "Epoch 13/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5888 - accuracy: 0.7490 - val_loss: 0.5868 - val_accuracy: 0.7472\n",
      "Epoch 14/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5884 - accuracy: 0.7492 - val_loss: 0.5832 - val_accuracy: 0.7517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5879 - accuracy: 0.7490 - val_loss: 0.5862 - val_accuracy: 0.7473\n",
      "Epoch 16/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5878 - accuracy: 0.7490 - val_loss: 0.5981 - val_accuracy: 0.7500\n",
      "Epoch 17/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5876 - accuracy: 0.7485 - val_loss: 0.5824 - val_accuracy: 0.7501\n",
      "Epoch 18/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5872 - accuracy: 0.7489 - val_loss: 0.5845 - val_accuracy: 0.7488\n",
      "Epoch 19/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5869 - accuracy: 0.7492 - val_loss: 0.5816 - val_accuracy: 0.7495\n",
      "Epoch 20/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5862 - accuracy: 0.7491 - val_loss: 0.5874 - val_accuracy: 0.7518\n",
      "Epoch 21/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5859 - accuracy: 0.7495 - val_loss: 0.5881 - val_accuracy: 0.7517\n",
      "Epoch 22/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5857 - accuracy: 0.7493 - val_loss: 0.5821 - val_accuracy: 0.7506\n",
      "Epoch 23/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5853 - accuracy: 0.7497 - val_loss: 0.5855 - val_accuracy: 0.7513\n",
      "Epoch 24/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5846 - accuracy: 0.7499 - val_loss: 0.5788 - val_accuracy: 0.7506\n",
      "Epoch 25/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5841 - accuracy: 0.7497 - val_loss: 0.5831 - val_accuracy: 0.7468\n",
      "Epoch 26/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5840 - accuracy: 0.7494 - val_loss: 0.5872 - val_accuracy: 0.7517\n",
      "Epoch 27/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5836 - accuracy: 0.7500 - val_loss: 0.5809 - val_accuracy: 0.7481\n",
      "Epoch 28/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5828 - accuracy: 0.7508 - val_loss: 0.5798 - val_accuracy: 0.7521\n",
      "Epoch 29/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5824 - accuracy: 0.7506 - val_loss: 0.5795 - val_accuracy: 0.7511\n",
      "Epoch 30/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5816 - accuracy: 0.7504 - val_loss: 0.6082 - val_accuracy: 0.7451\n",
      "Epoch 31/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5811 - accuracy: 0.7511 - val_loss: 0.5779 - val_accuracy: 0.7528\n",
      "Epoch 32/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5808 - accuracy: 0.7504 - val_loss: 0.5796 - val_accuracy: 0.7491\n",
      "Epoch 33/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5801 - accuracy: 0.7504 - val_loss: 0.5782 - val_accuracy: 0.7509\n",
      "Epoch 34/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5795 - accuracy: 0.7511 - val_loss: 0.5747 - val_accuracy: 0.7526\n",
      "Epoch 35/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5792 - accuracy: 0.7510 - val_loss: 0.5781 - val_accuracy: 0.7490\n",
      "Epoch 36/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7512 - val_loss: 0.5763 - val_accuracy: 0.7522\n",
      "Epoch 37/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5780 - accuracy: 0.7514 - val_loss: 0.5770 - val_accuracy: 0.7503\n",
      "Epoch 38/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5779 - accuracy: 0.7518 - val_loss: 0.5812 - val_accuracy: 0.7534\n",
      "Epoch 39/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5774 - accuracy: 0.7517 - val_loss: 0.5769 - val_accuracy: 0.7505\n",
      "Epoch 40/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5769 - accuracy: 0.7516 - val_loss: 0.5843 - val_accuracy: 0.7495\n",
      "Epoch 41/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5767 - accuracy: 0.7515 - val_loss: 0.5741 - val_accuracy: 0.7512\n",
      "Epoch 42/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5760 - accuracy: 0.7516 - val_loss: 0.5756 - val_accuracy: 0.7508\n",
      "Epoch 43/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5755 - accuracy: 0.7518 - val_loss: 0.5797 - val_accuracy: 0.7524\n",
      "Epoch 44/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5756 - accuracy: 0.7521 - val_loss: 0.5764 - val_accuracy: 0.7530\n",
      "Epoch 45/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5750 - accuracy: 0.7521 - val_loss: 0.5738 - val_accuracy: 0.7518\n",
      "Epoch 46/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5749 - accuracy: 0.7523 - val_loss: 0.5746 - val_accuracy: 0.7526\n",
      "Epoch 47/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5744 - accuracy: 0.7520 - val_loss: 0.5708 - val_accuracy: 0.7525\n",
      "Epoch 48/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7521 - val_loss: 0.5718 - val_accuracy: 0.7523\n",
      "Epoch 49/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5739 - accuracy: 0.7525 - val_loss: 0.5739 - val_accuracy: 0.7526\n",
      "Epoch 50/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5737 - accuracy: 0.7521 - val_loss: 0.5733 - val_accuracy: 0.7524\n",
      "Epoch 51/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7523 - val_loss: 0.5719 - val_accuracy: 0.7517\n",
      "Epoch 52/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5732 - accuracy: 0.7523 - val_loss: 0.5736 - val_accuracy: 0.7527\n",
      "Epoch 53/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7525 - val_loss: 0.5733 - val_accuracy: 0.7534\n",
      "Epoch 54/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7524 - val_loss: 0.5822 - val_accuracy: 0.7511\n",
      "Epoch 55/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5724 - accuracy: 0.7524 - val_loss: 0.5715 - val_accuracy: 0.7533\n",
      "Epoch 56/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7523 - val_loss: 0.5700 - val_accuracy: 0.7540\n",
      "Epoch 57/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7524 - val_loss: 0.5702 - val_accuracy: 0.7532\n",
      "Epoch 58/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5719 - accuracy: 0.7523 - val_loss: 0.5714 - val_accuracy: 0.7516\n",
      "Epoch 59/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5719 - accuracy: 0.7525 - val_loss: 0.5726 - val_accuracy: 0.7518\n",
      "Epoch 60/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5719 - accuracy: 0.7525 - val_loss: 0.5723 - val_accuracy: 0.7514\n",
      "Epoch 61/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5715 - accuracy: 0.7523 - val_loss: 0.5756 - val_accuracy: 0.7520\n",
      "Epoch 62/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5711 - accuracy: 0.7526 - val_loss: 0.5760 - val_accuracy: 0.7492\n",
      "Epoch 63/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7526 - val_loss: 0.5712 - val_accuracy: 0.7528\n",
      "Epoch 64/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5711 - accuracy: 0.7527 - val_loss: 0.5697 - val_accuracy: 0.7524\n",
      "Epoch 65/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5708 - accuracy: 0.7525 - val_loss: 0.5735 - val_accuracy: 0.7495\n",
      "Epoch 66/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5708 - accuracy: 0.7520 - val_loss: 0.5695 - val_accuracy: 0.7516\n",
      "Epoch 67/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5705 - accuracy: 0.7525 - val_loss: 0.5689 - val_accuracy: 0.7531\n",
      "Epoch 68/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5702 - accuracy: 0.7526 - val_loss: 0.5736 - val_accuracy: 0.7499\n",
      "Epoch 69/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5705 - accuracy: 0.7527 - val_loss: 0.5726 - val_accuracy: 0.7531\n",
      "Epoch 70/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5702 - accuracy: 0.7524 - val_loss: 0.5705 - val_accuracy: 0.7520\n",
      "Epoch 71/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5702 - accuracy: 0.7522 - val_loss: 0.5713 - val_accuracy: 0.7509\n",
      "Epoch 72/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7523 - val_loss: 0.5692 - val_accuracy: 0.7530\n",
      "Epoch 73/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7524 - val_loss: 0.5703 - val_accuracy: 0.7517\n",
      "Epoch 74/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7528 - val_loss: 0.5676 - val_accuracy: 0.7528\n",
      "Epoch 75/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5696 - accuracy: 0.7529 - val_loss: 0.5700 - val_accuracy: 0.7514\n",
      "Epoch 76/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7529 - val_loss: 0.5723 - val_accuracy: 0.7526\n",
      "Epoch 77/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5694 - accuracy: 0.7526 - val_loss: 0.5707 - val_accuracy: 0.7520\n",
      "Epoch 78/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5694 - accuracy: 0.7528 - val_loss: 0.5707 - val_accuracy: 0.7514\n",
      "Epoch 79/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5692 - accuracy: 0.7528 - val_loss: 0.5682 - val_accuracy: 0.7534\n",
      "Epoch 80/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5692 - accuracy: 0.7522 - val_loss: 0.5756 - val_accuracy: 0.7474\n",
      "Epoch 81/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5692 - accuracy: 0.7526 - val_loss: 0.5708 - val_accuracy: 0.7506\n",
      "Epoch 82/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7525 - val_loss: 0.5758 - val_accuracy: 0.7512\n",
      "Epoch 83/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5689 - accuracy: 0.7528 - val_loss: 0.5679 - val_accuracy: 0.7524\n",
      "Epoch 84/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5689 - accuracy: 0.7525 - val_loss: 0.5700 - val_accuracy: 0.7518\n",
      "Epoch 85/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5688 - accuracy: 0.7528 - val_loss: 0.5722 - val_accuracy: 0.7503\n",
      "Epoch 86/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7530 - val_loss: 0.5681 - val_accuracy: 0.7535\n",
      "Epoch 87/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7520 - val_loss: 0.5695 - val_accuracy: 0.7516\n",
      "Epoch 88/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7527 - val_loss: 0.5670 - val_accuracy: 0.7532\n",
      "Epoch 89/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7531 - val_loss: 0.5680 - val_accuracy: 0.7521\n",
      "Epoch 90/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5685 - accuracy: 0.7530 - val_loss: 0.5667 - val_accuracy: 0.7529\n",
      "Epoch 91/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7526 - val_loss: 0.5686 - val_accuracy: 0.7532\n",
      "Epoch 92/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7528 - val_loss: 0.5663 - val_accuracy: 0.7523\n",
      "Epoch 93/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7528 - val_loss: 0.5670 - val_accuracy: 0.7539\n",
      "Epoch 94/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7529 - val_loss: 0.5696 - val_accuracy: 0.7524\n",
      "Epoch 95/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7524 - val_loss: 0.5671 - val_accuracy: 0.7519\n",
      "Epoch 96/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7530 - val_loss: 0.5708 - val_accuracy: 0.7517\n",
      "Epoch 97/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5678 - accuracy: 0.7526 - val_loss: 0.5735 - val_accuracy: 0.7499\n",
      "Epoch 98/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7519 - val_loss: 0.5683 - val_accuracy: 0.7528\n",
      "Epoch 99/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5678 - accuracy: 0.7528 - val_loss: 0.5679 - val_accuracy: 0.7526\n",
      "Epoch 100/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5677 - accuracy: 0.7528 - val_loss: 0.5721 - val_accuracy: 0.7514\n",
      "Epoch 101/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7531 - val_loss: 0.5698 - val_accuracy: 0.7523\n",
      "Epoch 102/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5673 - accuracy: 0.7528 - val_loss: 0.5693 - val_accuracy: 0.7512\n",
      "Epoch 103/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5674 - accuracy: 0.7527 - val_loss: 0.5695 - val_accuracy: 0.7508\n",
      "Epoch 104/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5674 - accuracy: 0.7527 - val_loss: 0.5668 - val_accuracy: 0.7532\n",
      "Epoch 105/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5673 - accuracy: 0.7532 - val_loss: 0.5671 - val_accuracy: 0.7516\n",
      "Epoch 106/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5671 - accuracy: 0.7533 - val_loss: 0.5687 - val_accuracy: 0.7516\n",
      "Epoch 107/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5674 - accuracy: 0.7526 - val_loss: 0.5653 - val_accuracy: 0.7528\n",
      "Epoch 108/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5672 - accuracy: 0.7529 - val_loss: 0.5677 - val_accuracy: 0.7533\n",
      "Epoch 109/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5671 - accuracy: 0.7527 - val_loss: 0.5713 - val_accuracy: 0.7523\n",
      "Epoch 110/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7526 - val_loss: 0.5676 - val_accuracy: 0.7512\n",
      "Epoch 111/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7531 - val_loss: 0.5665 - val_accuracy: 0.7531\n",
      "Epoch 112/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7529 - val_loss: 0.5667 - val_accuracy: 0.7518\n",
      "Epoch 113/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5669 - accuracy: 0.7535 - val_loss: 0.5708 - val_accuracy: 0.7511\n",
      "Epoch 114/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7528 - val_loss: 0.5879 - val_accuracy: 0.7457\n",
      "Epoch 115/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5667 - accuracy: 0.7528 - val_loss: 0.5679 - val_accuracy: 0.7515\n",
      "Epoch 116/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7529 - val_loss: 0.5679 - val_accuracy: 0.7520\n",
      "Epoch 117/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7528 - val_loss: 0.5648 - val_accuracy: 0.7532\n",
      "Epoch 118/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7525 - val_loss: 0.5656 - val_accuracy: 0.7526\n",
      "Epoch 119/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7528 - val_loss: 0.5691 - val_accuracy: 0.7518\n",
      "Epoch 120/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7528 - val_loss: 0.5679 - val_accuracy: 0.7527\n",
      "Epoch 121/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7530 - val_loss: 0.5792 - val_accuracy: 0.7483\n",
      "Epoch 122/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7528 - val_loss: 0.5679 - val_accuracy: 0.7516\n",
      "Epoch 123/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7533 - val_loss: 0.5789 - val_accuracy: 0.7485\n",
      "Epoch 124/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7530 - val_loss: 0.5678 - val_accuracy: 0.7513\n",
      "Epoch 125/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7530 - val_loss: 0.5682 - val_accuracy: 0.7524\n",
      "Epoch 126/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7527 - val_loss: 0.5659 - val_accuracy: 0.7521\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5664 - accuracy: 0.7528 - val_loss: 0.5670 - val_accuracy: 0.7528\n",
      "Epoch 128/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7530 - val_loss: 0.5654 - val_accuracy: 0.7520\n",
      "Epoch 129/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5663 - accuracy: 0.7529 - val_loss: 0.5649 - val_accuracy: 0.7528\n",
      "Epoch 130/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7533 - val_loss: 0.5672 - val_accuracy: 0.7506\n",
      "Epoch 131/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5662 - accuracy: 0.7533 - val_loss: 0.5757 - val_accuracy: 0.7498\n",
      "Epoch 132/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5662 - accuracy: 0.7530 - val_loss: 0.5735 - val_accuracy: 0.7508\n",
      "Epoch 133/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7527 - val_loss: 0.5695 - val_accuracy: 0.7511\n",
      "Epoch 134/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7525 - val_loss: 0.5701 - val_accuracy: 0.7518\n",
      "Epoch 135/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7534 - val_loss: 0.5743 - val_accuracy: 0.7499\n",
      "Epoch 136/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5661 - accuracy: 0.7530 - val_loss: 0.5661 - val_accuracy: 0.7513\n",
      "Epoch 137/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7528 - val_loss: 0.5638 - val_accuracy: 0.7530\n",
      "Epoch 138/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5660 - accuracy: 0.7530 - val_loss: 0.5655 - val_accuracy: 0.7529\n",
      "Epoch 139/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7530 - val_loss: 0.5706 - val_accuracy: 0.7520\n",
      "Epoch 140/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5658 - accuracy: 0.7526 - val_loss: 0.5667 - val_accuracy: 0.7532\n",
      "Epoch 141/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5659 - accuracy: 0.7530 - val_loss: 0.5658 - val_accuracy: 0.7520\n",
      "Epoch 142/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7528 - val_loss: 0.5636 - val_accuracy: 0.7528\n",
      "Epoch 143/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5657 - accuracy: 0.7527 - val_loss: 0.5755 - val_accuracy: 0.7474\n",
      "Epoch 144/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5659 - accuracy: 0.7530 - val_loss: 0.5649 - val_accuracy: 0.7540\n",
      "Epoch 145/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5659 - accuracy: 0.7531 - val_loss: 0.5683 - val_accuracy: 0.7523\n",
      "Epoch 146/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5658 - accuracy: 0.7526 - val_loss: 0.5647 - val_accuracy: 0.7530\n",
      "Epoch 147/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7526 - val_loss: 0.5665 - val_accuracy: 0.7529\n",
      "Epoch 148/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5656 - accuracy: 0.7531 - val_loss: 0.5688 - val_accuracy: 0.7503\n",
      "Epoch 149/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7529 - val_loss: 0.5681 - val_accuracy: 0.7518\n",
      "Epoch 150/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5656 - accuracy: 0.7530 - val_loss: 0.5660 - val_accuracy: 0.7531\n",
      "Epoch 151/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7529 - val_loss: 0.5656 - val_accuracy: 0.7526\n",
      "Epoch 152/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7530 - val_loss: 0.5667 - val_accuracy: 0.7508\n",
      "Epoch 153/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7530 - val_loss: 0.5712 - val_accuracy: 0.7507\n",
      "Epoch 154/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7526 - val_loss: 0.5697 - val_accuracy: 0.7519\n",
      "Epoch 155/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7530 - val_loss: 0.5703 - val_accuracy: 0.7511\n",
      "Epoch 156/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5655 - accuracy: 0.7526 - val_loss: 0.5668 - val_accuracy: 0.7521\n",
      "Epoch 157/200\n",
      "2498/2498 [==============================] - 2s 985us/step - loss: 0.5654 - accuracy: 0.7528 - val_loss: 0.5690 - val_accuracy: 0.7523\n",
      "Epoch 158/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7529 - val_loss: 0.5793 - val_accuracy: 0.7480\n",
      "Epoch 159/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7524 - val_loss: 0.5671 - val_accuracy: 0.7510\n",
      "Epoch 160/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5654 - accuracy: 0.7527 - val_loss: 0.5684 - val_accuracy: 0.7515\n",
      "Epoch 161/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7527 - val_loss: 0.5711 - val_accuracy: 0.7516\n",
      "Epoch 162/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7525 - val_loss: 0.5678 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5650 - accuracy: 0.7530 - val_loss: 0.5639 - val_accuracy: 0.7526\n",
      "Epoch 164/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5652 - accuracy: 0.7530 - val_loss: 0.5646 - val_accuracy: 0.7531.5\n",
      "Epoch 165/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7530 - val_loss: 0.5781 - val_accuracy: 0.7487\n",
      "Epoch 166/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7530 - val_loss: 0.5682 - val_accuracy: 0.7513\n",
      "Epoch 167/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7528 - val_loss: 0.5648 - val_accuracy: 0.7521\n",
      "Epoch 168/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7528 - val_loss: 0.5659 - val_accuracy: 0.7524\n",
      "Epoch 169/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7533 - val_loss: 0.5686 - val_accuracy: 0.7519\n",
      "Epoch 170/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7530 - val_loss: 0.5664 - val_accuracy: 0.7524\n",
      "Epoch 171/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7526 - val_loss: 0.5654 - val_accuracy: 0.7523\n",
      "Epoch 172/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7530 - val_loss: 0.5656 - val_accuracy: 0.7530\n",
      "Epoch 173/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7529 - val_loss: 0.5647 - val_accuracy: 0.7521\n",
      "Epoch 174/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5651 - accuracy: 0.7526 - val_loss: 0.5645 - val_accuracy: 0.7531\n",
      "Epoch 175/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7532 - val_loss: 0.5638 - val_accuracy: 0.7526\n",
      "Epoch 176/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5649 - accuracy: 0.7526 - val_loss: 0.5640 - val_accuracy: 0.7527\n",
      "Epoch 177/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5649 - accuracy: 0.7535 - val_loss: 0.5638 - val_accuracy: 0.7535\n",
      "Epoch 178/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5651 - accuracy: 0.7526 - val_loss: 0.5668 - val_accuracy: 0.7524\n",
      "Epoch 179/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7530 - val_loss: 0.5643 - val_accuracy: 0.7528\n",
      "Epoch 180/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5647 - accuracy: 0.7532 - val_loss: 0.5634 - val_accuracy: 0.7533\n",
      "Epoch 181/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5650 - accuracy: 0.7524 - val_loss: 0.5736 - val_accuracy: 0.7497\n",
      "Epoch 182/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7531 - val_loss: 0.5648 - val_accuracy: 0.7520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7529 - val_loss: 0.5648 - val_accuracy: 0.7531\n",
      "Epoch 184/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5647 - accuracy: 0.7532 - val_loss: 0.5653 - val_accuracy: 0.7523\n",
      "Epoch 185/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7529 - val_loss: 0.5638 - val_accuracy: 0.7536\n",
      "Epoch 186/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5647 - accuracy: 0.7534 - val_loss: 0.5642 - val_accuracy: 0.7527\n",
      "Epoch 187/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7529 - val_loss: 0.5690 - val_accuracy: 0.7511\n",
      "Epoch 188/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7533 - val_loss: 0.5663 - val_accuracy: 0.7517\n",
      "Epoch 189/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5645 - accuracy: 0.7526 - val_loss: 0.5631 - val_accuracy: 0.7538\n",
      "Epoch 190/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7528 - val_loss: 0.5635 - val_accuracy: 0.7534\n",
      "Epoch 191/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5646 - accuracy: 0.7530 - val_loss: 0.5658 - val_accuracy: 0.7522\n",
      "Epoch 192/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5646 - accuracy: 0.7531 - val_loss: 0.5782 - val_accuracy: 0.7479\n",
      "Epoch 193/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5646 - accuracy: 0.7527 - val_loss: 0.5673 - val_accuracy: 0.7522\n",
      "Epoch 194/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7526 - val_loss: 0.5757 - val_accuracy: 0.7490\n",
      "Epoch 195/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5645 - accuracy: 0.7528 - val_loss: 0.5649 - val_accuracy: 0.7530\n",
      "Epoch 196/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7525 - val_loss: 0.5684 - val_accuracy: 0.7516\n",
      "Epoch 197/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5646 - accuracy: 0.7526 - val_loss: 0.5654 - val_accuracy: 0.7528\n",
      "Epoch 198/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7528 - val_loss: 0.5633 - val_accuracy: 0.7533\n",
      "Epoch 199/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7530 - val_loss: 0.5667 - val_accuracy: 0.7522\n",
      "Epoch 200/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7527 - val_loss: 0.5680 - val_accuracy: 0.7519\n",
      "4441/4441 [==============================] - 3s 610us/step - loss: 1.3290 - accuracy: 0.4513\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop object at 0x0000019CAD688DC0>\n",
      "Epoch Sizes:  200\n",
      "Neurons or Units:  256\n",
      "Test score: 1.3289968967437744\n",
      "Test accuracy: 0.4512723684310913\n",
      "\n",
      "[0.45332029461860657, 0.45748648047447205, 0.4546433389186859, 0.4510471820831299, 0.4514060914516449, 0.45284879207611084, 0.4473735988140106, 0.44945669174194336, 0.45847174525260925, 0.4521661400794983, 0.45222947001457214, 0.43204593658447266, 0.4422292113304138, 0.4447838068008423, 0.44921743869781494, 0.44308072328567505, 0.44485417008399963, 0.4512723684310913]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Time 6739.020378351212 seconds: \n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,211\n",
      "Trainable params: 1,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6867 - accuracy: 0.7363 - val_loss: 0.6252 - val_accuracy: 0.7477\n",
      "Epoch 2/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6165 - accuracy: 0.7480 - val_loss: 0.6092 - val_accuracy: 0.7499\n",
      "Epoch 3/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6052 - accuracy: 0.7488 - val_loss: 0.6023 - val_accuracy: 0.7495\n",
      "Epoch 4/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5990 - accuracy: 0.7493 - val_loss: 0.5961 - val_accuracy: 0.7501\n",
      "Epoch 5/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5947 - accuracy: 0.7497 - val_loss: 0.5947 - val_accuracy: 0.7494\n",
      "Epoch 6/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5919 - accuracy: 0.7495 - val_loss: 0.5942 - val_accuracy: 0.7458\n",
      "Epoch 7/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5895 - accuracy: 0.7503 - val_loss: 0.5884 - val_accuracy: 0.7500\n",
      "Epoch 8/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5872 - accuracy: 0.7504 - val_loss: 0.5863 - val_accuracy: 0.7513\n",
      "Epoch 9/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5862 - accuracy: 0.7503 - val_loss: 0.5845 - val_accuracy: 0.7495\n",
      "Epoch 10/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5846 - accuracy: 0.7504 - val_loss: 0.5860 - val_accuracy: 0.7520\n",
      "Epoch 11/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5835 - accuracy: 0.7507 - val_loss: 0.5819 - val_accuracy: 0.7511\n",
      "Epoch 12/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5830 - accuracy: 0.7511 - val_loss: 0.5827 - val_accuracy: 0.7496\n",
      "Epoch 13/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5818 - accuracy: 0.7505 - val_loss: 0.5818 - val_accuracy: 0.7499\n",
      "Epoch 14/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5809 - accuracy: 0.7509 - val_loss: 0.5805 - val_accuracy: 0.7486\n",
      "Epoch 15/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5802 - accuracy: 0.7509 - val_loss: 0.5802 - val_accuracy: 0.7491\n",
      "Epoch 16/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5798 - accuracy: 0.7512 - val_loss: 0.5791 - val_accuracy: 0.7501\n",
      "Epoch 17/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5794 - accuracy: 0.7512 - val_loss: 0.5766 - val_accuracy: 0.7511\n",
      "Epoch 18/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5784 - accuracy: 0.7513 - val_loss: 0.5846 - val_accuracy: 0.7520\n",
      "Epoch 19/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5782 - accuracy: 0.7510 - val_loss: 0.5780 - val_accuracy: 0.7495\n",
      "Epoch 20/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5776 - accuracy: 0.7512 - val_loss: 0.5789 - val_accuracy: 0.7525\n",
      "Epoch 21/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5771 - accuracy: 0.7517 - val_loss: 0.5756 - val_accuracy: 0.7514\n",
      "Epoch 22/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5766 - accuracy: 0.7517 - val_loss: 0.5769 - val_accuracy: 0.7521\n",
      "Epoch 23/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5763 - accuracy: 0.7520 - val_loss: 0.5758 - val_accuracy: 0.7512\n",
      "Epoch 24/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5760 - accuracy: 0.7517 - val_loss: 0.5750 - val_accuracy: 0.7504\n",
      "Epoch 25/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5755 - accuracy: 0.7517 - val_loss: 0.5740 - val_accuracy: 0.7511\n",
      "Epoch 26/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5752 - accuracy: 0.7516 - val_loss: 0.5750 - val_accuracy: 0.7518\n",
      "Epoch 27/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5749 - accuracy: 0.7519 - val_loss: 0.5730 - val_accuracy: 0.7514\n",
      "Epoch 28/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5746 - accuracy: 0.7521 - val_loss: 0.5826 - val_accuracy: 0.7461\n",
      "Epoch 29/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5743 - accuracy: 0.7519 - val_loss: 0.5746 - val_accuracy: 0.7507\n",
      "Epoch 30/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5738 - accuracy: 0.7523 - val_loss: 0.5724 - val_accuracy: 0.7523\n",
      "Epoch 31/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5737 - accuracy: 0.7523 - val_loss: 0.5768 - val_accuracy: 0.7523\n",
      "Epoch 32/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7520 - val_loss: 0.5767 - val_accuracy: 0.7490\n",
      "Epoch 33/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5730 - accuracy: 0.7524 - val_loss: 0.5749 - val_accuracy: 0.7502\n",
      "Epoch 34/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5731 - accuracy: 0.7525 - val_loss: 0.5731 - val_accuracy: 0.7508\n",
      "Epoch 35/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5730 - accuracy: 0.7525 - val_loss: 0.5732 - val_accuracy: 0.7521\n",
      "Epoch 36/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5724 - accuracy: 0.7520 - val_loss: 0.5756 - val_accuracy: 0.7526\n",
      "Epoch 37/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5724 - accuracy: 0.7523 - val_loss: 0.5742 - val_accuracy: 0.7527\n",
      "Epoch 38/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5720 - accuracy: 0.7527 - val_loss: 0.5730 - val_accuracy: 0.7503\n",
      "Epoch 39/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5717 - accuracy: 0.7524 - val_loss: 0.5714 - val_accuracy: 0.7516\n",
      "Epoch 40/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5715 - accuracy: 0.7524 - val_loss: 0.5701 - val_accuracy: 0.7520\n",
      "Epoch 41/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7526 - val_loss: 0.5716 - val_accuracy: 0.7533\n",
      "Epoch 42/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5710 - accuracy: 0.7525 - val_loss: 0.5741 - val_accuracy: 0.7505\n",
      "Epoch 43/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7519 - val_loss: 0.5751 - val_accuracy: 0.7495\n",
      "Epoch 44/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5705 - accuracy: 0.7525 - val_loss: 0.5716 - val_accuracy: 0.7511\n",
      "Epoch 45/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5707 - accuracy: 0.7529 - val_loss: 0.5714 - val_accuracy: 0.7533\n",
      "Epoch 46/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5708 - accuracy: 0.7525 - val_loss: 0.5731 - val_accuracy: 0.7523\n",
      "Epoch 47/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7527 - val_loss: 0.5690 - val_accuracy: 0.7527\n",
      "Epoch 48/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5701 - accuracy: 0.7530 - val_loss: 0.5695 - val_accuracy: 0.7523\n",
      "Epoch 49/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5702 - accuracy: 0.7530 - val_loss: 0.5714 - val_accuracy: 0.7515\n",
      "Epoch 50/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7525 - val_loss: 0.5739 - val_accuracy: 0.7498\n",
      "4441/4441 [==============================] - 3s 722us/step - loss: 1.3229 - accuracy: 0.4548\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000019CAD688A60>\n",
      "Epoch Sizes:  50\n",
      "Neurons or Units:  64\n",
      "Test score: 1.3229447603225708\n",
      "Test accuracy: 0.4547911286354065\n",
      "\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6342 - accuracy: 0.7445 - val_loss: 0.6121 - val_accuracy: 0.7470\n",
      "Epoch 2/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6073 - accuracy: 0.7479 - val_loss: 0.6092 - val_accuracy: 0.7401\n",
      "Epoch 3/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5996 - accuracy: 0.7488 - val_loss: 0.5955 - val_accuracy: 0.7485\n",
      "Epoch 4/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5956 - accuracy: 0.7487 - val_loss: 0.5962 - val_accuracy: 0.7434\n",
      "Epoch 5/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5926 - accuracy: 0.7491 - val_loss: 0.5913 - val_accuracy: 0.7512\n",
      "Epoch 6/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5903 - accuracy: 0.7495 - val_loss: 0.5899 - val_accuracy: 0.7497\n",
      "Epoch 7/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5889 - accuracy: 0.7491 - val_loss: 0.5868 - val_accuracy: 0.7519\n",
      "Epoch 8/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5873 - accuracy: 0.7497 - val_loss: 0.5848 - val_accuracy: 0.7506\n",
      "Epoch 9/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5865 - accuracy: 0.7498 - val_loss: 0.5843 - val_accuracy: 0.7496\n",
      "Epoch 10/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5857 - accuracy: 0.7499 - val_loss: 0.5824 - val_accuracy: 0.7510\n",
      "Epoch 11/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5849 - accuracy: 0.7499 - val_loss: 0.5857 - val_accuracy: 0.7523\n",
      "Epoch 12/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5840 - accuracy: 0.7499 - val_loss: 0.5820 - val_accuracy: 0.7510\n",
      "Epoch 13/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5833 - accuracy: 0.7499 - val_loss: 0.5898 - val_accuracy: 0.7491\n",
      "Epoch 14/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5827 - accuracy: 0.7501 - val_loss: 0.5882 - val_accuracy: 0.7520\n",
      "Epoch 15/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5820 - accuracy: 0.7501 - val_loss: 0.5838 - val_accuracy: 0.7520\n",
      "Epoch 16/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5818 - accuracy: 0.7503 - val_loss: 0.5803 - val_accuracy: 0.7493\n",
      "Epoch 17/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5810 - accuracy: 0.7507 - val_loss: 0.5791 - val_accuracy: 0.7517\n",
      "Epoch 18/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5806 - accuracy: 0.7506 - val_loss: 0.5780 - val_accuracy: 0.7505\n",
      "Epoch 19/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5797 - accuracy: 0.7505 - val_loss: 0.5787 - val_accuracy: 0.7496\n",
      "Epoch 20/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5795 - accuracy: 0.7511 - val_loss: 0.5782 - val_accuracy: 0.7500\n",
      "Epoch 21/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7509 - val_loss: 0.5765 - val_accuracy: 0.7506\n",
      "Epoch 22/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5783 - accuracy: 0.7518 - val_loss: 0.5774 - val_accuracy: 0.7517\n",
      "Epoch 23/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5782 - accuracy: 0.7512 - val_loss: 0.5750 - val_accuracy: 0.7521\n",
      "Epoch 24/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5775 - accuracy: 0.7515 - val_loss: 0.5780 - val_accuracy: 0.7497\n",
      "Epoch 25/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5771 - accuracy: 0.7511 - val_loss: 0.5787 - val_accuracy: 0.7498\n",
      "Epoch 26/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5770 - accuracy: 0.7513 - val_loss: 0.5782 - val_accuracy: 0.7490\n",
      "Epoch 27/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5761 - accuracy: 0.7515 - val_loss: 0.5763 - val_accuracy: 0.7505\n",
      "Epoch 28/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5758 - accuracy: 0.7515 - val_loss: 0.5733 - val_accuracy: 0.7521\n",
      "Epoch 29/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5758 - accuracy: 0.7519 - val_loss: 0.5754 - val_accuracy: 0.7507\n",
      "Epoch 30/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5754 - accuracy: 0.7516 - val_loss: 0.5767 - val_accuracy: 0.7530\n",
      "Epoch 31/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5747 - accuracy: 0.7520 - val_loss: 0.5790 - val_accuracy: 0.7484\n",
      "Epoch 32/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5749 - accuracy: 0.7520 - val_loss: 0.5746 - val_accuracy: 0.7530\n",
      "Epoch 33/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5743 - accuracy: 0.7520 - val_loss: 0.5718 - val_accuracy: 0.7520\n",
      "Epoch 34/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5741 - accuracy: 0.7520 - val_loss: 0.5725 - val_accuracy: 0.7521\n",
      "Epoch 35/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5736 - accuracy: 0.7522 - val_loss: 0.5761 - val_accuracy: 0.7500\n",
      "Epoch 36/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5738 - accuracy: 0.7519 - val_loss: 0.5743 - val_accuracy: 0.7505\n",
      "Epoch 37/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7522 - val_loss: 0.5712 - val_accuracy: 0.7519\n",
      "Epoch 38/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5729 - accuracy: 0.7520 - val_loss: 0.5724 - val_accuracy: 0.7514\n",
      "Epoch 39/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5730 - accuracy: 0.7523 - val_loss: 0.5754 - val_accuracy: 0.7517\n",
      "Epoch 40/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5729 - accuracy: 0.7524 - val_loss: 0.5775 - val_accuracy: 0.7518\n",
      "Epoch 41/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5726 - accuracy: 0.7524 - val_loss: 0.5709 - val_accuracy: 0.7523\n",
      "Epoch 42/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5724 - accuracy: 0.7528 - val_loss: 0.5750 - val_accuracy: 0.7530\n",
      "Epoch 43/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7526 - val_loss: 0.5707 - val_accuracy: 0.7521\n",
      "Epoch 44/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5720 - accuracy: 0.7521 - val_loss: 0.5715 - val_accuracy: 0.7519\n",
      "Epoch 45/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5719 - accuracy: 0.7525 - val_loss: 0.5709 - val_accuracy: 0.7527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5718 - accuracy: 0.7519 - val_loss: 0.5701 - val_accuracy: 0.7518\n",
      "Epoch 47/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7527 - val_loss: 0.5714 - val_accuracy: 0.7512\n",
      "Epoch 48/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5713 - accuracy: 0.7522 - val_loss: 0.5715 - val_accuracy: 0.7530\n",
      "Epoch 49/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5715 - accuracy: 0.7524 - val_loss: 0.5717 - val_accuracy: 0.7527\n",
      "Epoch 50/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5711 - accuracy: 0.7526 - val_loss: 0.5695 - val_accuracy: 0.7528\n",
      "4441/4441 [==============================] - 3s 734us/step - loss: 1.3107 - accuracy: 0.4502\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000019CAD688A60>\n",
      "Epoch Sizes:  50\n",
      "Neurons or Units:  128\n",
      "Test score: 1.3107496500015259\n",
      "Test accuracy: 0.4501534104347229\n",
      "\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,667\n",
      "Trainable params: 4,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6297 - accuracy: 0.7451 - val_loss: 0.6065 - val_accuracy: 0.7478\n",
      "Epoch 2/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6032 - accuracy: 0.7483 - val_loss: 0.5989 - val_accuracy: 0.7466\n",
      "Epoch 3/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5957 - accuracy: 0.7491 - val_loss: 0.5911 - val_accuracy: 0.7480\n",
      "Epoch 4/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5911 - accuracy: 0.7499 - val_loss: 0.5877 - val_accuracy: 0.7503\n",
      "Epoch 5/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5881 - accuracy: 0.7496 - val_loss: 0.5859 - val_accuracy: 0.7484\n",
      "Epoch 6/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5856 - accuracy: 0.7503 - val_loss: 0.5879 - val_accuracy: 0.7463\n",
      "Epoch 7/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5838 - accuracy: 0.7504 - val_loss: 0.5845 - val_accuracy: 0.7476\n",
      "Epoch 8/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5822 - accuracy: 0.7511 - val_loss: 0.5815 - val_accuracy: 0.7503\n",
      "Epoch 9/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5812 - accuracy: 0.7509 - val_loss: 0.5807 - val_accuracy: 0.7497\n",
      "Epoch 10/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5807 - accuracy: 0.7508 - val_loss: 0.5815 - val_accuracy: 0.7481\n",
      "Epoch 11/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5787 - accuracy: 0.7512 - val_loss: 0.5762 - val_accuracy: 0.7512\n",
      "Epoch 12/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5784 - accuracy: 0.7514 - val_loss: 0.5775 - val_accuracy: 0.7509\n",
      "Epoch 13/50\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5778 - accuracy: 0.7514 - val_loss: 0.5796 - val_accuracy: 0.7495\n",
      "Epoch 14/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5771 - accuracy: 0.7520 - val_loss: 0.5740 - val_accuracy: 0.7529\n",
      "Epoch 15/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5764 - accuracy: 0.7518 - val_loss: 0.5780 - val_accuracy: 0.7526\n",
      "Epoch 16/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5763 - accuracy: 0.7518 - val_loss: 0.5763 - val_accuracy: 0.7507\n",
      "Epoch 17/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5758 - accuracy: 0.7517 - val_loss: 0.5743 - val_accuracy: 0.7518\n",
      "Epoch 18/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5748 - accuracy: 0.7524 - val_loss: 0.5809 - val_accuracy: 0.7468\n",
      "Epoch 19/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5746 - accuracy: 0.7519 - val_loss: 0.5749 - val_accuracy: 0.7509\n",
      "Epoch 20/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5742 - accuracy: 0.7519 - val_loss: 0.5748 - val_accuracy: 0.7497\n",
      "Epoch 21/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5735 - accuracy: 0.7518 - val_loss: 0.5717 - val_accuracy: 0.7526\n",
      "Epoch 22/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5734 - accuracy: 0.7521 - val_loss: 0.5754 - val_accuracy: 0.7526\n",
      "Epoch 23/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5731 - accuracy: 0.7522 - val_loss: 0.5724 - val_accuracy: 0.7512\n",
      "Epoch 24/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7519 - val_loss: 0.5765 - val_accuracy: 0.7520\n",
      "Epoch 25/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5728 - accuracy: 0.7523 - val_loss: 0.5723 - val_accuracy: 0.7530\n",
      "Epoch 26/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5723 - accuracy: 0.7522 - val_loss: 0.5717 - val_accuracy: 0.7516\n",
      "Epoch 27/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5725 - accuracy: 0.7522 - val_loss: 0.5700 - val_accuracy: 0.7527\n",
      "Epoch 28/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5719 - accuracy: 0.7521 - val_loss: 0.5755 - val_accuracy: 0.7516\n",
      "Epoch 29/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5717 - accuracy: 0.7524 - val_loss: 0.5715 - val_accuracy: 0.7520\n",
      "Epoch 30/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5713 - accuracy: 0.7519 - val_loss: 0.5763 - val_accuracy: 0.7526\n",
      "Epoch 31/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5709 - accuracy: 0.7522 - val_loss: 0.5718 - val_accuracy: 0.7511\n",
      "Epoch 32/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5711 - accuracy: 0.7526 - val_loss: 0.5714 - val_accuracy: 0.7519\n",
      "Epoch 33/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7518 - val_loss: 0.5699 - val_accuracy: 0.7530\n",
      "Epoch 34/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5704 - accuracy: 0.7521 - val_loss: 0.5734 - val_accuracy: 0.7515\n",
      "Epoch 35/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5705 - accuracy: 0.7522 - val_loss: 0.5731 - val_accuracy: 0.7514\n",
      "Epoch 36/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5702 - accuracy: 0.7523 - val_loss: 0.5687 - val_accuracy: 0.7523\n",
      "Epoch 37/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5706 - accuracy: 0.7523 - val_loss: 0.5682 - val_accuracy: 0.7531\n",
      "Epoch 38/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5701 - accuracy: 0.7523 - val_loss: 0.5689 - val_accuracy: 0.7524\n",
      "Epoch 39/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7527 - val_loss: 0.5719 - val_accuracy: 0.7498\n",
      "Epoch 40/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5695 - accuracy: 0.7524 - val_loss: 0.5695 - val_accuracy: 0.7528\n",
      "Epoch 41/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5694 - accuracy: 0.7527 - val_loss: 0.5682 - val_accuracy: 0.7524\n",
      "Epoch 42/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5694 - accuracy: 0.7521 - val_loss: 0.5682 - val_accuracy: 0.7522\n",
      "Epoch 43/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5694 - accuracy: 0.7520 - val_loss: 0.5724 - val_accuracy: 0.7510\n",
      "Epoch 44/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5695 - accuracy: 0.7523 - val_loss: 0.5734 - val_accuracy: 0.7489\n",
      "Epoch 45/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5694 - accuracy: 0.7520 - val_loss: 0.5682 - val_accuracy: 0.7521\n",
      "Epoch 46/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7524 - val_loss: 0.5819 - val_accuracy: 0.7488\n",
      "Epoch 47/50\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7529 - val_loss: 0.5725 - val_accuracy: 0.7521\n",
      "Epoch 48/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5684 - accuracy: 0.7526 - val_loss: 0.5725 - val_accuracy: 0.7520\n",
      "Epoch 49/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5686 - accuracy: 0.7527 - val_loss: 0.5724 - val_accuracy: 0.7522\n",
      "Epoch 50/50\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5684 - accuracy: 0.7524 - val_loss: 0.5678 - val_accuracy: 0.7535\n",
      "4441/4441 [==============================] - 3s 778us/step - loss: 1.3170 - accuracy: 0.4456\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000019CAD688A60>\n",
      "Epoch Sizes:  50\n",
      "Neurons or Units:  256\n",
      "Test score: 1.3169994354248047\n",
      "Test accuracy: 0.44559311866760254\n",
      "\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,211\n",
      "Trainable params: 1,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.6449 - accuracy: 0.7435 - val_loss: 0.6192 - val_accuracy: 0.7487\n",
      "Epoch 2/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6123 - accuracy: 0.7476 - val_loss: 0.6075 - val_accuracy: 0.7498\n",
      "Epoch 3/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6036 - accuracy: 0.7488 - val_loss: 0.6025 - val_accuracy: 0.7450\n",
      "Epoch 4/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5982 - accuracy: 0.7490 - val_loss: 0.5969 - val_accuracy: 0.7492\n",
      "Epoch 5/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5948 - accuracy: 0.7493 - val_loss: 0.5925 - val_accuracy: 0.7487\n",
      "Epoch 6/100\n",
      "2498/2498 [==============================] - 2741s 1s/step - loss: 0.5925 - accuracy: 0.7494 - val_loss: 0.5927 - val_accuracy: 0.7472\n",
      "Epoch 7/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5904 - accuracy: 0.7498 - val_loss: 0.5953 - val_accuracy: 0.7430\n",
      "Epoch 8/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5887 - accuracy: 0.7500 - val_loss: 0.5915 - val_accuracy: 0.7444\n",
      "Epoch 9/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5877 - accuracy: 0.7501 - val_loss: 0.5860 - val_accuracy: 0.7507\n",
      "Epoch 10/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5866 - accuracy: 0.7502 - val_loss: 0.5852 - val_accuracy: 0.7513\n",
      "Epoch 11/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5856 - accuracy: 0.7502 - val_loss: 0.5849 - val_accuracy: 0.7485\n",
      "Epoch 12/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5847 - accuracy: 0.7502 - val_loss: 0.5844 - val_accuracy: 0.7486\n",
      "Epoch 13/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5839 - accuracy: 0.7505 - val_loss: 0.5879 - val_accuracy: 0.7512\n",
      "Epoch 14/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5832 - accuracy: 0.7503 - val_loss: 0.5836 - val_accuracy: 0.7510\n",
      "Epoch 15/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5827 - accuracy: 0.7503 - val_loss: 0.5829 - val_accuracy: 0.7497\n",
      "Epoch 16/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5821 - accuracy: 0.7501 - val_loss: 0.5849 - val_accuracy: 0.7515\n",
      "Epoch 17/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5811 - accuracy: 0.7503 - val_loss: 0.5844 - val_accuracy: 0.7474\n",
      "Epoch 18/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5809 - accuracy: 0.7507 - val_loss: 0.5795 - val_accuracy: 0.7514\n",
      "Epoch 19/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5803 - accuracy: 0.7509 - val_loss: 0.5810 - val_accuracy: 0.7523\n",
      "Epoch 20/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5800 - accuracy: 0.7508 - val_loss: 0.5785 - val_accuracy: 0.7509\n",
      "Epoch 21/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5792 - accuracy: 0.7506 - val_loss: 0.5805 - val_accuracy: 0.7513\n",
      "Epoch 22/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5789 - accuracy: 0.7510 - val_loss: 0.5771 - val_accuracy: 0.7512\n",
      "Epoch 23/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5780 - accuracy: 0.7513 - val_loss: 0.5774 - val_accuracy: 0.7501\n",
      "Epoch 24/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5777 - accuracy: 0.7510 - val_loss: 0.5806 - val_accuracy: 0.7469\n",
      "Epoch 25/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5773 - accuracy: 0.7511 - val_loss: 0.5769 - val_accuracy: 0.7501\n",
      "Epoch 26/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5769 - accuracy: 0.7509 - val_loss: 0.5794 - val_accuracy: 0.7504\n",
      "Epoch 27/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5763 - accuracy: 0.7514 - val_loss: 0.5773 - val_accuracy: 0.7487\n",
      "Epoch 28/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5759 - accuracy: 0.7516 - val_loss: 0.5745 - val_accuracy: 0.7509\n",
      "Epoch 29/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5761 - accuracy: 0.7515 - val_loss: 0.5795 - val_accuracy: 0.7520\n",
      "Epoch 30/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5746 - accuracy: 0.7520 - val_loss: 0.5737 - val_accuracy: 0.7519\n",
      "Epoch 31/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5747 - accuracy: 0.7517 - val_loss: 0.5756 - val_accuracy: 0.7515\n",
      "Epoch 32/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5743 - accuracy: 0.7518 - val_loss: 0.5734 - val_accuracy: 0.7518\n",
      "Epoch 33/100\n",
      "2498/2498 [==============================] - 2s 927us/step - loss: 0.5739 - accuracy: 0.7521 - val_loss: 0.5736 - val_accuracy: 0.7506\n",
      "Epoch 34/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5737 - accuracy: 0.7519 - val_loss: 0.5760 - val_accuracy: 0.7491\n",
      "Epoch 35/100\n",
      "2498/2498 [==============================] - 2s 893us/step - loss: 0.5735 - accuracy: 0.7521 - val_loss: 0.5735 - val_accuracy: 0.7506\n",
      "Epoch 36/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7520 - val_loss: 0.5710 - val_accuracy: 0.7522\n",
      "Epoch 37/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5727 - accuracy: 0.7520 - val_loss: 0.5776 - val_accuracy: 0.7521\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5729 - accuracy: 0.7523 - val_loss: 0.5734 - val_accuracy: 0.7519\n",
      "Epoch 39/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5722 - accuracy: 0.7520 - val_loss: 0.5724 - val_accuracy: 0.7525\n",
      "Epoch 40/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7519 - val_loss: 0.5715 - val_accuracy: 0.7509\n",
      "Epoch 41/100\n",
      "2498/2498 [==============================] - 2s 877us/step - loss: 0.5721 - accuracy: 0.7523 - val_loss: 0.5722 - val_accuracy: 0.7513\n",
      "Epoch 42/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5718 - accuracy: 0.7522 - val_loss: 0.5743 - val_accuracy: 0.7531\n",
      "Epoch 43/100\n",
      "2498/2498 [==============================] - 2s 938us/step - loss: 0.5719 - accuracy: 0.7522 - val_loss: 0.5725 - val_accuracy: 0.7498\n",
      "Epoch 44/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5713 - accuracy: 0.7523 - val_loss: 0.5709 - val_accuracy: 0.7517\n",
      "Epoch 45/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5713 - accuracy: 0.7527 - val_loss: 0.5729 - val_accuracy: 0.7498\n",
      "Epoch 46/100\n",
      "2498/2498 [==============================] - 2s 938us/step - loss: 0.5710 - accuracy: 0.7527 - val_loss: 0.5732 - val_accuracy: 0.7517\n",
      "Epoch 47/100\n",
      "2498/2498 [==============================] - 2s 810us/step - loss: 0.5707 - accuracy: 0.7530 - val_loss: 0.5721 - val_accuracy: 0.7506\n",
      "Epoch 48/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5705 - accuracy: 0.7527 - val_loss: 0.5708 - val_accuracy: 0.7523\n",
      "Epoch 49/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7528 - val_loss: 0.5712 - val_accuracy: 0.7521\n",
      "Epoch 50/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7524 - val_loss: 0.5757 - val_accuracy: 0.7518\n",
      "Epoch 51/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5703 - accuracy: 0.7524 - val_loss: 0.5738 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5702 - accuracy: 0.7522 - val_loss: 0.5687 - val_accuracy: 0.7521\n",
      "Epoch 53/100\n",
      "2498/2498 [==============================] - 2s 915us/step - loss: 0.5700 - accuracy: 0.7527 - val_loss: 0.5739 - val_accuracy: 0.7497\n",
      "Epoch 54/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5695 - accuracy: 0.7524 - val_loss: 0.5725 - val_accuracy: 0.7501\n",
      "Epoch 55/100\n",
      "2498/2498 [==============================] - 2s 900us/step - loss: 0.5697 - accuracy: 0.7527 - val_loss: 0.5695 - val_accuracy: 0.7514\n",
      "Epoch 56/100\n",
      "2498/2498 [==============================] - 2s 985us/step - loss: 0.5698 - accuracy: 0.7525 - val_loss: 0.5708 - val_accuracy: 0.7515\n",
      "Epoch 57/100\n",
      "2498/2498 [==============================] - 2s 897us/step - loss: 0.5695 - accuracy: 0.7525 - val_loss: 0.5734 - val_accuracy: 0.7511\n",
      "Epoch 58/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5695 - accuracy: 0.7524 - val_loss: 0.5724 - val_accuracy: 0.7521\n",
      "Epoch 59/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5693 - accuracy: 0.7527 - val_loss: 0.5725 - val_accuracy: 0.7522\n",
      "Epoch 60/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5694 - accuracy: 0.7526 - val_loss: 0.5677 - val_accuracy: 0.7524\n",
      "Epoch 61/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5689 - accuracy: 0.7525 - val_loss: 0.5692 - val_accuracy: 0.7519\n",
      "Epoch 62/100\n",
      "2498/2498 [==============================] - 2s 971us/step - loss: 0.5690 - accuracy: 0.7526 - val_loss: 0.5723 - val_accuracy: 0.7522\n",
      "Epoch 63/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5689 - accuracy: 0.7526 - val_loss: 0.5717 - val_accuracy: 0.7508\n",
      "Epoch 64/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5688 - accuracy: 0.7528 - val_loss: 0.5694 - val_accuracy: 0.7541\n",
      "Epoch 65/100\n",
      "2498/2498 [==============================] - 2s 805us/step - loss: 0.5687 - accuracy: 0.7529 - val_loss: 0.5676 - val_accuracy: 0.7525\n",
      "Epoch 66/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7529 - val_loss: 0.5749 - val_accuracy: 0.7522\n",
      "Epoch 67/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7527 - val_loss: 0.5689 - val_accuracy: 0.7520\n",
      "Epoch 68/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7528 - val_loss: 0.5690 - val_accuracy: 0.7521\n",
      "Epoch 69/100\n",
      "2498/2498 [==============================] - 2s 976us/step - loss: 0.5679 - accuracy: 0.7526 - val_loss: 0.5728 - val_accuracy: 0.7517\n",
      "Epoch 70/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7523 - val_loss: 0.5694 - val_accuracy: 0.7527\n",
      "Epoch 71/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5682 - accuracy: 0.7528 - val_loss: 0.5668 - val_accuracy: 0.7527\n",
      "Epoch 72/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5681 - accuracy: 0.7527 - val_loss: 0.5685 - val_accuracy: 0.7520\n",
      "Epoch 73/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5681 - accuracy: 0.7523 - val_loss: 0.5747 - val_accuracy: 0.7507\n",
      "Epoch 74/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5678 - accuracy: 0.7524 - val_loss: 0.5706 - val_accuracy: 0.7519\n",
      "Epoch 75/100\n",
      "2498/2498 [==============================] - 2s 944us/step - loss: 0.5683 - accuracy: 0.7525 - val_loss: 0.5730 - val_accuracy: 0.7508\n",
      "Epoch 76/100\n",
      "2498/2498 [==============================] - 2s 870us/step - loss: 0.5678 - accuracy: 0.7524 - val_loss: 0.5665 - val_accuracy: 0.7524\n",
      "Epoch 77/100\n",
      "2498/2498 [==============================] - 2s 851us/step - loss: 0.5671 - accuracy: 0.7534 - val_loss: 0.5662 - val_accuracy: 0.7526\n",
      "Epoch 78/100\n",
      "2498/2498 [==============================] - 2s 863us/step - loss: 0.5674 - accuracy: 0.7531 - val_loss: 0.5658 - val_accuracy: 0.7532\n",
      "Epoch 79/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7528 - val_loss: 0.5771 - val_accuracy: 0.7513\n",
      "Epoch 80/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5674 - accuracy: 0.7525 - val_loss: 0.5667 - val_accuracy: 0.7524\n",
      "Epoch 81/100\n",
      "2498/2498 [==============================] - 2s 966us/step - loss: 0.5674 - accuracy: 0.7526 - val_loss: 0.5673 - val_accuracy: 0.7518\n",
      "Epoch 82/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7524 - val_loss: 0.5670 - val_accuracy: 0.7524\n",
      "Epoch 83/100\n",
      "2498/2498 [==============================] - 2s 921us/step - loss: 0.5673 - accuracy: 0.7527 - val_loss: 0.5675 - val_accuracy: 0.7525\n",
      "Epoch 84/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5673 - accuracy: 0.7526 - val_loss: 0.5683 - val_accuracy: 0.7527\n",
      "Epoch 85/100\n",
      "2498/2498 [==============================] - 2s 901us/step - loss: 0.5670 - accuracy: 0.7528 - val_loss: 0.5694 - val_accuracy: 0.7528\n",
      "Epoch 86/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5671 - accuracy: 0.7533 - val_loss: 0.5662 - val_accuracy: 0.7526\n",
      "Epoch 87/100\n",
      "2498/2498 [==============================] - 2s 951us/step - loss: 0.5670 - accuracy: 0.7527 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7527 - val_loss: 0.5677 - val_accuracy: 0.7524\n",
      "Epoch 89/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7528 - val_loss: 0.5669 - val_accuracy: 0.7529\n",
      "Epoch 90/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5670 - accuracy: 0.7527 - val_loss: 0.5675 - val_accuracy: 0.7513\n",
      "Epoch 91/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7530 - val_loss: 0.5721 - val_accuracy: 0.7498\n",
      "Epoch 92/100\n",
      "2498/2498 [==============================] - 2s 904us/step - loss: 0.5668 - accuracy: 0.7524 - val_loss: 0.5665 - val_accuracy: 0.7520\n",
      "Epoch 93/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7524 - val_loss: 0.5698 - val_accuracy: 0.7524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5669 - accuracy: 0.7526 - val_loss: 0.5702 - val_accuracy: 0.7508\n",
      "Epoch 95/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7523 - val_loss: 0.5671 - val_accuracy: 0.7521\n",
      "Epoch 96/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7529 - val_loss: 0.5673 - val_accuracy: 0.7521\n",
      "Epoch 97/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7531 - val_loss: 0.5675 - val_accuracy: 0.7508\n",
      "Epoch 98/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7531 - val_loss: 0.5734 - val_accuracy: 0.7514\n",
      "Epoch 99/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5667 - accuracy: 0.7531 - val_loss: 0.5699 - val_accuracy: 0.7488\n",
      "Epoch 100/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7528 - val_loss: 0.5688 - val_accuracy: 0.7519\n",
      "4441/4441 [==============================] - 4s 983us/step - loss: 1.2838 - accuracy: 0.4395\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000019CAD688A60>\n",
      "Epoch Sizes:  100\n",
      "Neurons or Units:  64\n",
      "Test score: 1.2837789058685303\n",
      "Test accuracy: 0.4394915997982025\n",
      "\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6343 - accuracy: 0.7455 - val_loss: 0.6113 - val_accuracy: 0.7482\n",
      "Epoch 2/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6066 - accuracy: 0.7482 - val_loss: 0.6014 - val_accuracy: 0.7489\n",
      "Epoch 3/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5989 - accuracy: 0.7490 - val_loss: 0.5965 - val_accuracy: 0.7470\n",
      "Epoch 4/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5937 - accuracy: 0.7493 - val_loss: 0.5906 - val_accuracy: 0.7514\n",
      "Epoch 5/100\n",
      "2498/2498 [==============================] - 2s 859us/step - loss: 0.5905 - accuracy: 0.7497 - val_loss: 0.5906 - val_accuracy: 0.7465\n",
      "Epoch 6/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5880 - accuracy: 0.7500 - val_loss: 0.5864 - val_accuracy: 0.7520\n",
      "Epoch 7/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5863 - accuracy: 0.7502 - val_loss: 0.5861 - val_accuracy: 0.7489\n",
      "Epoch 8/100\n",
      "2498/2498 [==============================] - 2s 916us/step - loss: 0.5845 - accuracy: 0.7500 - val_loss: 0.5830 - val_accuracy: 0.7514\n",
      "Epoch 9/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5830 - accuracy: 0.7506 - val_loss: 0.5826 - val_accuracy: 0.7492\n",
      "Epoch 10/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5823 - accuracy: 0.7505 - val_loss: 0.5842 - val_accuracy: 0.7519\n",
      "Epoch 11/100\n",
      "2498/2498 [==============================] - 2s 932us/step - loss: 0.5813 - accuracy: 0.7511 - val_loss: 0.5802 - val_accuracy: 0.7502\n",
      "Epoch 12/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5799 - accuracy: 0.7513 - val_loss: 0.5815 - val_accuracy: 0.7515\n",
      "Epoch 13/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5795 - accuracy: 0.7513 - val_loss: 0.5773 - val_accuracy: 0.7506\n",
      "Epoch 14/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5789 - accuracy: 0.7509 - val_loss: 0.5763 - val_accuracy: 0.7509\n",
      "Epoch 15/100\n",
      "2498/2498 [==============================] - 2s 951us/step - loss: 0.5782 - accuracy: 0.7516 - val_loss: 0.5807 - val_accuracy: 0.7518\n",
      "Epoch 16/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5775 - accuracy: 0.7515 - val_loss: 0.5769 - val_accuracy: 0.7497\n",
      "Epoch 17/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5770 - accuracy: 0.7512 - val_loss: 0.5841 - val_accuracy: 0.7516\n",
      "Epoch 18/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5767 - accuracy: 0.7519 - val_loss: 0.5793 - val_accuracy: 0.7486\n",
      "Epoch 19/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5758 - accuracy: 0.7520 - val_loss: 0.5806 - val_accuracy: 0.7493\n",
      "Epoch 20/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5755 - accuracy: 0.7518 - val_loss: 0.5726 - val_accuracy: 0.7515\n",
      "Epoch 21/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5754 - accuracy: 0.7515 - val_loss: 0.5770 - val_accuracy: 0.7498\n",
      "Epoch 22/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5752 - accuracy: 0.7519 - val_loss: 0.5742 - val_accuracy: 0.7503\n",
      "Epoch 23/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5747 - accuracy: 0.7521 - val_loss: 0.5732 - val_accuracy: 0.7515\n",
      "Epoch 24/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5742 - accuracy: 0.7517 - val_loss: 0.5751 - val_accuracy: 0.7526\n",
      "Epoch 25/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5741 - accuracy: 0.7517 - val_loss: 0.5780 - val_accuracy: 0.7494\n",
      "Epoch 26/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5737 - accuracy: 0.7520 - val_loss: 0.5720 - val_accuracy: 0.7518\n",
      "Epoch 27/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5733 - accuracy: 0.7517 - val_loss: 0.5772 - val_accuracy: 0.7504\n",
      "Epoch 28/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5735 - accuracy: 0.7519 - val_loss: 0.5716 - val_accuracy: 0.7528\n",
      "Epoch 29/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5726 - accuracy: 0.7520 - val_loss: 0.5749 - val_accuracy: 0.7499\n",
      "Epoch 30/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5723 - accuracy: 0.7521 - val_loss: 0.5720 - val_accuracy: 0.7512\n",
      "Epoch 31/100\n",
      "2498/2498 [==============================] - 2s 927us/step - loss: 0.5726 - accuracy: 0.7521 - val_loss: 0.5767 - val_accuracy: 0.7494\n",
      "Epoch 32/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5722 - accuracy: 0.7521 - val_loss: 0.5732 - val_accuracy: 0.7519\n",
      "Epoch 33/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5723 - accuracy: 0.7520 - val_loss: 0.5701 - val_accuracy: 0.7524\n",
      "Epoch 34/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5719 - accuracy: 0.7520 - val_loss: 0.5717 - val_accuracy: 0.7520\n",
      "Epoch 35/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5717 - accuracy: 0.7520 - val_loss: 0.5747 - val_accuracy: 0.7490\n",
      "Epoch 36/100\n",
      "2498/2498 [==============================] - 2s 891us/step - loss: 0.5716 - accuracy: 0.7523 - val_loss: 0.5708 - val_accuracy: 0.7517\n",
      "Epoch 37/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5710 - accuracy: 0.7522 - val_loss: 0.5708 - val_accuracy: 0.7522\n",
      "Epoch 38/100\n",
      "2498/2498 [==============================] - 2s 914us/step - loss: 0.5712 - accuracy: 0.7524 - val_loss: 0.5737 - val_accuracy: 0.7517\n",
      "Epoch 39/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5711 - accuracy: 0.7519 - val_loss: 0.5703 - val_accuracy: 0.7512\n",
      "Epoch 40/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5706 - accuracy: 0.7524 - val_loss: 0.5729 - val_accuracy: 0.7505\n",
      "Epoch 41/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5708 - accuracy: 0.7517 - val_loss: 0.5700 - val_accuracy: 0.7502\n",
      "Epoch 42/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5706 - accuracy: 0.7520 - val_loss: 0.5710 - val_accuracy: 0.7527\n",
      "Epoch 43/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5703 - accuracy: 0.7515 - val_loss: 0.5701 - val_accuracy: 0.7523\n",
      "Epoch 44/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5701 - accuracy: 0.7523 - val_loss: 0.5716 - val_accuracy: 0.7517\n",
      "Epoch 45/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5704 - accuracy: 0.7519 - val_loss: 0.5708 - val_accuracy: 0.7520\n",
      "Epoch 46/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5703 - accuracy: 0.7520 - val_loss: 0.5698 - val_accuracy: 0.7517\n",
      "Epoch 47/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5699 - accuracy: 0.7519 - val_loss: 0.5736 - val_accuracy: 0.7513\n",
      "Epoch 48/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5695 - accuracy: 0.7526 - val_loss: 0.5708 - val_accuracy: 0.7502\n",
      "Epoch 49/100\n",
      "2498/2498 [==============================] - 2s 997us/step - loss: 0.5696 - accuracy: 0.7517 - val_loss: 0.5689 - val_accuracy: 0.7516\n",
      "Epoch 50/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5693 - accuracy: 0.7525 - val_loss: 0.5760 - val_accuracy: 0.7475\n",
      "Epoch 51/100\n",
      "2498/2498 [==============================] - 2s 967us/step - loss: 0.5692 - accuracy: 0.7522 - val_loss: 0.5716 - val_accuracy: 0.7520\n",
      "Epoch 52/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7521 - val_loss: 0.5965 - val_accuracy: 0.7430\n",
      "Epoch 53/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5692 - accuracy: 0.7524 - val_loss: 0.5679 - val_accuracy: 0.7520\n",
      "Epoch 54/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5691 - accuracy: 0.7523 - val_loss: 0.5688 - val_accuracy: 0.7512\n",
      "Epoch 55/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7521 - val_loss: 0.5671 - val_accuracy: 0.7518\n",
      "Epoch 56/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7525 - val_loss: 0.5700 - val_accuracy: 0.7514\n",
      "Epoch 57/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7525 - val_loss: 0.5676 - val_accuracy: 0.7520\n",
      "Epoch 58/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5687 - accuracy: 0.7524 - val_loss: 0.5747 - val_accuracy: 0.7489\n",
      "Epoch 59/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5686 - accuracy: 0.7523 - val_loss: 0.5674 - val_accuracy: 0.7521\n",
      "Epoch 60/100\n",
      "2498/2498 [==============================] - 2s 918us/step - loss: 0.5681 - accuracy: 0.7525 - val_loss: 0.5731 - val_accuracy: 0.7519\n",
      "Epoch 61/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7519 - val_loss: 0.5728 - val_accuracy: 0.7488\n",
      "Epoch 62/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7526 - val_loss: 0.5683 - val_accuracy: 0.7515\n",
      "Epoch 63/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7526 - val_loss: 0.5678 - val_accuracy: 0.7511\n",
      "Epoch 64/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7523 - val_loss: 0.5671 - val_accuracy: 0.7514\n",
      "Epoch 65/100\n",
      "2498/2498 [==============================] - 2s 778us/step - loss: 0.5679 - accuracy: 0.7529 - val_loss: 0.5666 - val_accuracy: 0.7523\n",
      "Epoch 66/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7522 - val_loss: 0.5680 - val_accuracy: 0.7520\n",
      "Epoch 67/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5678 - accuracy: 0.7522 - val_loss: 0.5674 - val_accuracy: 0.7517\n",
      "Epoch 68/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5679 - accuracy: 0.7523 - val_loss: 0.5672 - val_accuracy: 0.7519\n",
      "Epoch 69/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7522 - val_loss: 0.5705 - val_accuracy: 0.7493\n",
      "Epoch 70/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5678 - accuracy: 0.7522 - val_loss: 0.5675 - val_accuracy: 0.7519\n",
      "Epoch 71/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7526 - val_loss: 0.5681 - val_accuracy: 0.7511\n",
      "Epoch 72/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5678 - accuracy: 0.7521 - val_loss: 0.5677 - val_accuracy: 0.7520\n",
      "Epoch 73/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7527 - val_loss: 0.5691 - val_accuracy: 0.7508\n",
      "Epoch 74/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7524 - val_loss: 0.5653 - val_accuracy: 0.7527\n",
      "Epoch 75/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5672 - accuracy: 0.7524 - val_loss: 0.5675 - val_accuracy: 0.7520\n",
      "Epoch 76/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5673 - accuracy: 0.7523 - val_loss: 0.5695 - val_accuracy: 0.7509\n",
      "Epoch 77/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7528 - val_loss: 0.5734 - val_accuracy: 0.7506\n",
      "Epoch 78/100\n",
      "2498/2498 [==============================] - 2s 998us/step - loss: 0.5667 - accuracy: 0.7526 - val_loss: 0.5664 - val_accuracy: 0.7524\n",
      "Epoch 79/100\n",
      "2498/2498 [==============================] - 2s 896us/step - loss: 0.5670 - accuracy: 0.7524 - val_loss: 0.5662 - val_accuracy: 0.7530\n",
      "Epoch 80/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5671 - accuracy: 0.7524 - val_loss: 0.5666 - val_accuracy: 0.7521\n",
      "Epoch 81/100\n",
      "2498/2498 [==============================] - 2s 967us/step - loss: 0.5667 - accuracy: 0.7529 - val_loss: 0.5675 - val_accuracy: 0.7519\n",
      "Epoch 82/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5670 - accuracy: 0.7525 - val_loss: 0.5660 - val_accuracy: 0.7516\n",
      "Epoch 83/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7527 - val_loss: 0.5675 - val_accuracy: 0.7525\n",
      "Epoch 84/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7523 - val_loss: 0.5715 - val_accuracy: 0.7498\n",
      "Epoch 85/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7525 - val_loss: 0.5761 - val_accuracy: 0.7505\n",
      "Epoch 86/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7527 - val_loss: 0.5747 - val_accuracy: 0.7494\n",
      "Epoch 87/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7528 - val_loss: 0.5657 - val_accuracy: 0.7522\n",
      "Epoch 88/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7529 - val_loss: 0.5664 - val_accuracy: 0.7515\n",
      "Epoch 89/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7524 - val_loss: 0.5654 - val_accuracy: 0.7524\n",
      "Epoch 90/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7525 - val_loss: 0.5693 - val_accuracy: 0.7512\n",
      "Epoch 91/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5661 - accuracy: 0.7525 - val_loss: 0.5691 - val_accuracy: 0.7503\n",
      "Epoch 92/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7525 - val_loss: 0.5692 - val_accuracy: 0.7503\n",
      "Epoch 93/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5666 - accuracy: 0.7527 - val_loss: 0.5660 - val_accuracy: 0.7523\n",
      "Epoch 94/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7525 - val_loss: 0.5677 - val_accuracy: 0.7509\n",
      "Epoch 95/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7526 - val_loss: 0.5677 - val_accuracy: 0.7513\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5662 - accuracy: 0.7523 - val_loss: 0.5682 - val_accuracy: 0.7521\n",
      "Epoch 97/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5660 - accuracy: 0.7526 - val_loss: 0.5664 - val_accuracy: 0.7518\n",
      "Epoch 98/100\n",
      "2498/2498 [==============================] - 890s 356ms/step - loss: 0.5662 - accuracy: 0.7526 - val_loss: 0.5654 - val_accuracy: 0.7521\n",
      "Epoch 99/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5659 - accuracy: 0.7523 - val_loss: 0.5644 - val_accuracy: 0.7526\n",
      "Epoch 100/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7524 - val_loss: 0.5655 - val_accuracy: 0.7525\n",
      "4441/4441 [==============================] - 2s 528us/step - loss: 1.2720 - accuracy: 0.4453\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000019CAD688A60>\n",
      "Epoch Sizes:  100\n",
      "Neurons or Units:  128\n",
      "Test score: 1.2719742059707642\n",
      "Test accuracy: 0.44533976912498474\n",
      "\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,667\n",
      "Trainable params: 4,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6289 - accuracy: 0.7448 - val_loss: 0.6097 - val_accuracy: 0.7483\n",
      "Epoch 2/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6034 - accuracy: 0.7486 - val_loss: 0.5977 - val_accuracy: 0.7486\n",
      "Epoch 3/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5965 - accuracy: 0.7487 - val_loss: 0.5932 - val_accuracy: 0.7472\n",
      "Epoch 4/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5923 - accuracy: 0.7494 - val_loss: 0.5894 - val_accuracy: 0.7475\n",
      "Epoch 5/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5899 - accuracy: 0.7500 - val_loss: 0.5860 - val_accuracy: 0.7492\n",
      "Epoch 6/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5875 - accuracy: 0.7500 - val_loss: 0.5863 - val_accuracy: 0.7507\n",
      "Epoch 7/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5860 - accuracy: 0.7498 - val_loss: 0.5841 - val_accuracy: 0.7484\n",
      "Epoch 8/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5842 - accuracy: 0.7503 - val_loss: 0.5849 - val_accuracy: 0.7508\n",
      "Epoch 9/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5835 - accuracy: 0.7502 - val_loss: 0.6006 - val_accuracy: 0.7489\n",
      "Epoch 10/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5822 - accuracy: 0.7504 - val_loss: 0.5808 - val_accuracy: 0.7494\n",
      "Epoch 11/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5815 - accuracy: 0.7503 - val_loss: 0.5807 - val_accuracy: 0.7503\n",
      "Epoch 12/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5808 - accuracy: 0.7507 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5800 - accuracy: 0.7505 - val_loss: 0.5790 - val_accuracy: 0.7498\n",
      "Epoch 14/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5793 - accuracy: 0.7505 - val_loss: 0.5783 - val_accuracy: 0.7488\n",
      "Epoch 15/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5788 - accuracy: 0.7510 - val_loss: 0.5773 - val_accuracy: 0.7502\n",
      "Epoch 16/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5784 - accuracy: 0.7510 - val_loss: 0.5770 - val_accuracy: 0.7507\n",
      "Epoch 17/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5777 - accuracy: 0.7508 - val_loss: 0.5798 - val_accuracy: 0.7518\n",
      "Epoch 18/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5772 - accuracy: 0.7515 - val_loss: 0.5787 - val_accuracy: 0.7487\n",
      "Epoch 19/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5768 - accuracy: 0.7514 - val_loss: 0.5777 - val_accuracy: 0.7494\n",
      "Epoch 20/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5764 - accuracy: 0.7518 - val_loss: 0.5769 - val_accuracy: 0.7514\n",
      "Epoch 21/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5760 - accuracy: 0.7511 - val_loss: 0.5735 - val_accuracy: 0.7521\n",
      "Epoch 22/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5760 - accuracy: 0.7509 - val_loss: 0.5785 - val_accuracy: 0.7488\n",
      "Epoch 23/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5752 - accuracy: 0.7518 - val_loss: 0.5725 - val_accuracy: 0.7521\n",
      "Epoch 24/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5749 - accuracy: 0.7517 - val_loss: 0.5753 - val_accuracy: 0.7502\n",
      "Epoch 25/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5744 - accuracy: 0.7518 - val_loss: 0.5769 - val_accuracy: 0.7519\n",
      "Epoch 26/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5740 - accuracy: 0.7517 - val_loss: 0.5731 - val_accuracy: 0.7515\n",
      "Epoch 27/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5735 - accuracy: 0.7517 - val_loss: 0.5750 - val_accuracy: 0.7525\n",
      "Epoch 28/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5735 - accuracy: 0.7525 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5737 - accuracy: 0.7522 - val_loss: 0.5760 - val_accuracy: 0.7525\n",
      "Epoch 30/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5733 - accuracy: 0.7518 - val_loss: 0.5728 - val_accuracy: 0.7518\n",
      "Epoch 31/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5727 - accuracy: 0.7523 - val_loss: 0.5789 - val_accuracy: 0.7479\n",
      "Epoch 32/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5727 - accuracy: 0.7520 - val_loss: 0.5711 - val_accuracy: 0.7519\n",
      "Epoch 33/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5723 - accuracy: 0.7519 - val_loss: 0.5718 - val_accuracy: 0.7526\n",
      "Epoch 34/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5725 - accuracy: 0.7524 - val_loss: 0.5722 - val_accuracy: 0.7509\n",
      "Epoch 35/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7523 - val_loss: 0.5700 - val_accuracy: 0.7523\n",
      "Epoch 36/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5719 - accuracy: 0.7524 - val_loss: 0.5804 - val_accuracy: 0.7502\n",
      "Epoch 37/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5715 - accuracy: 0.7525 - val_loss: 0.5714 - val_accuracy: 0.7518\n",
      "Epoch 38/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5715 - accuracy: 0.7519 - val_loss: 0.5697 - val_accuracy: 0.7527\n",
      "Epoch 39/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5709 - accuracy: 0.7528 - val_loss: 0.5710 - val_accuracy: 0.7523\n",
      "Epoch 40/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5710 - accuracy: 0.7523 - val_loss: 0.5701 - val_accuracy: 0.7520\n",
      "Epoch 41/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5710 - accuracy: 0.7526 - val_loss: 0.5694 - val_accuracy: 0.7529\n",
      "Epoch 42/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7521 - val_loss: 0.5695 - val_accuracy: 0.7523\n",
      "Epoch 43/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5703 - accuracy: 0.7520 - val_loss: 0.5709 - val_accuracy: 0.7520\n",
      "Epoch 44/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5705 - accuracy: 0.7525 - val_loss: 0.5770 - val_accuracy: 0.7478\n",
      "Epoch 45/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5703 - accuracy: 0.7521 - val_loss: 0.5700 - val_accuracy: 0.7517\n",
      "Epoch 46/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5700 - accuracy: 0.7526 - val_loss: 0.5698 - val_accuracy: 0.7520\n",
      "Epoch 47/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7526 - val_loss: 0.5706 - val_accuracy: 0.7511\n",
      "Epoch 48/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5700 - accuracy: 0.7526 - val_loss: 0.5700 - val_accuracy: 0.7517\n",
      "Epoch 49/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5696 - accuracy: 0.7521 - val_loss: 0.5780 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7523 - val_loss: 0.5710 - val_accuracy: 0.7507\n",
      "Epoch 51/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5693 - accuracy: 0.7527 - val_loss: 0.5768 - val_accuracy: 0.7493\n",
      "Epoch 52/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5695 - accuracy: 0.7523 - val_loss: 0.5691 - val_accuracy: 0.7525\n",
      "Epoch 53/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5691 - accuracy: 0.7527 - val_loss: 0.5778 - val_accuracy: 0.7509\n",
      "Epoch 54/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5691 - accuracy: 0.7529 - val_loss: 0.5737 - val_accuracy: 0.7514\n",
      "Epoch 55/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5689 - accuracy: 0.7522 - val_loss: 0.5697 - val_accuracy: 0.7507\n",
      "Epoch 56/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7524 - val_loss: 0.5677 - val_accuracy: 0.7527\n",
      "Epoch 57/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5689 - accuracy: 0.7523 - val_loss: 0.5694 - val_accuracy: 0.7513\n",
      "Epoch 58/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5688 - accuracy: 0.7527 - val_loss: 0.5675 - val_accuracy: 0.7528\n",
      "Epoch 59/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7526 - val_loss: 0.5703 - val_accuracy: 0.7514\n",
      "Epoch 60/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5684 - accuracy: 0.7525 - val_loss: 0.5682 - val_accuracy: 0.7509\n",
      "Epoch 61/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5684 - accuracy: 0.7526 - val_loss: 0.5704 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5681 - accuracy: 0.7530 - val_loss: 0.5762 - val_accuracy: 0.7507\n",
      "Epoch 63/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5683 - accuracy: 0.7523 - val_loss: 0.5704 - val_accuracy: 0.7515\n",
      "Epoch 64/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7522 - val_loss: 0.5722 - val_accuracy: 0.7527\n",
      "Epoch 65/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5680 - accuracy: 0.7527 - val_loss: 0.5679 - val_accuracy: 0.7521\n",
      "Epoch 66/100\n",
      "2498/2498 [==============================] - 2s 995us/step - loss: 0.5680 - accuracy: 0.7525 - val_loss: 0.5681 - val_accuracy: 0.7520\n",
      "Epoch 67/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7521 - val_loss: 0.5664 - val_accuracy: 0.7527\n",
      "Epoch 68/100\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5676 - accuracy: 0.7532 - val_loss: 0.5672 - val_accuracy: 0.7523\n",
      "Epoch 69/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5681 - accuracy: 0.7525 - val_loss: 0.5676 - val_accuracy: 0.7523\n",
      "Epoch 70/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7523 - val_loss: 0.5683 - val_accuracy: 0.7528\n",
      "Epoch 71/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5678 - accuracy: 0.7531 - val_loss: 0.5761 - val_accuracy: 0.7498\n",
      "Epoch 72/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5677 - accuracy: 0.7524 - val_loss: 0.5682 - val_accuracy: 0.7508\n",
      "Epoch 73/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5674 - accuracy: 0.7528 - val_loss: 0.5693 - val_accuracy: 0.7507\n",
      "Epoch 74/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5672 - accuracy: 0.7527 - val_loss: 0.5692 - val_accuracy: 0.7523\n",
      "Epoch 75/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5673 - accuracy: 0.7526 - val_loss: 0.5677 - val_accuracy: 0.7518\n",
      "Epoch 76/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7526 - val_loss: 0.5733 - val_accuracy: 0.7510\n",
      "Epoch 77/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7530 - val_loss: 0.5700 - val_accuracy: 0.7513\n",
      "Epoch 78/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5669 - accuracy: 0.7530 - val_loss: 0.5662 - val_accuracy: 0.7523\n",
      "Epoch 79/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5671 - accuracy: 0.7527 - val_loss: 0.5671 - val_accuracy: 0.7525\n",
      "Epoch 80/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5668 - accuracy: 0.7531 - val_loss: 0.5677 - val_accuracy: 0.7511\n",
      "Epoch 81/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7527 - val_loss: 0.5672 - val_accuracy: 0.7528\n",
      "Epoch 82/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5669 - accuracy: 0.7533 - val_loss: 0.5667 - val_accuracy: 0.7517\n",
      "Epoch 83/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7528 - val_loss: 0.5662 - val_accuracy: 0.7532\n",
      "Epoch 84/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5669 - accuracy: 0.7526 - val_loss: 0.5665 - val_accuracy: 0.7526\n",
      "Epoch 85/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7531 - val_loss: 0.5664 - val_accuracy: 0.7527\n",
      "Epoch 86/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7522 - val_loss: 0.5658 - val_accuracy: 0.7518\n",
      "Epoch 87/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5668 - accuracy: 0.7525 - val_loss: 0.5659 - val_accuracy: 0.7525\n",
      "Epoch 88/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7524 - val_loss: 0.5693 - val_accuracy: 0.7507\n",
      "Epoch 89/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7526 - val_loss: 0.5663 - val_accuracy: 0.7521\n",
      "Epoch 90/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7528 - val_loss: 0.5650 - val_accuracy: 0.7529\n",
      "Epoch 91/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7522 - val_loss: 0.5716 - val_accuracy: 0.7497\n",
      "Epoch 92/100\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5666 - accuracy: 0.7530 - val_loss: 0.5662 - val_accuracy: 0.7523\n",
      "Epoch 93/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7528 - val_loss: 0.5658 - val_accuracy: 0.7523\n",
      "Epoch 94/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7527 - val_loss: 0.5647 - val_accuracy: 0.7523\n",
      "Epoch 95/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7531 - val_loss: 0.5645 - val_accuracy: 0.7525\n",
      "Epoch 96/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7526 - val_loss: 0.5654 - val_accuracy: 0.7522\n",
      "Epoch 97/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7525 - val_loss: 0.5655 - val_accuracy: 0.7520\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7527 - val_loss: 0.5671 - val_accuracy: 0.7511\n",
      "Epoch 99/100\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5661 - accuracy: 0.7528 - val_loss: 0.5667 - val_accuracy: 0.7518\n",
      "Epoch 100/100\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7529 - val_loss: 0.5654 - val_accuracy: 0.7531\n",
      "4441/4441 [==============================] - 4s 1ms/step - loss: 1.2799 - accuracy: 0.4492\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000019CAD688A60>\n",
      "Epoch Sizes:  100\n",
      "Neurons or Units:  256\n",
      "Test score: 1.2798566818237305\n",
      "Test accuracy: 0.44919630885124207\n",
      "\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,211\n",
      "Trainable params: 1,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.6438 - accuracy: 0.7434 - val_loss: 0.6171 - val_accuracy: 0.7490\n",
      "Epoch 2/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6093 - accuracy: 0.7487 - val_loss: 0.6043 - val_accuracy: 0.7482\n",
      "Epoch 3/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.6005 - accuracy: 0.7495 - val_loss: 0.5967 - val_accuracy: 0.7487\n",
      "Epoch 4/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5951 - accuracy: 0.7496 - val_loss: 0.5933 - val_accuracy: 0.7515\n",
      "Epoch 5/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5918 - accuracy: 0.7502 - val_loss: 0.5902 - val_accuracy: 0.7483\n",
      "Epoch 6/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5891 - accuracy: 0.7505 - val_loss: 0.5887 - val_accuracy: 0.7492\n",
      "Epoch 7/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5869 - accuracy: 0.7504 - val_loss: 0.5861 - val_accuracy: 0.7496\n",
      "Epoch 8/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5856 - accuracy: 0.7506 - val_loss: 0.5924 - val_accuracy: 0.7496\n",
      "Epoch 9/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5839 - accuracy: 0.7509 - val_loss: 0.5843 - val_accuracy: 0.7519\n",
      "Epoch 10/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5827 - accuracy: 0.7515 - val_loss: 0.5842 - val_accuracy: 0.7523\n",
      "Epoch 11/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5818 - accuracy: 0.7510 - val_loss: 0.5796 - val_accuracy: 0.7523\n",
      "Epoch 12/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5811 - accuracy: 0.7505 - val_loss: 0.5800 - val_accuracy: 0.7509\n",
      "Epoch 13/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5801 - accuracy: 0.7515 - val_loss: 0.5795 - val_accuracy: 0.7497\n",
      "Epoch 14/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5793 - accuracy: 0.7515 - val_loss: 0.5786 - val_accuracy: 0.7509\n",
      "Epoch 15/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5787 - accuracy: 0.7513 - val_loss: 0.5776 - val_accuracy: 0.7517\n",
      "Epoch 16/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5780 - accuracy: 0.7516 - val_loss: 0.5778 - val_accuracy: 0.7505\n",
      "Epoch 17/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5775 - accuracy: 0.7518 - val_loss: 0.5759 - val_accuracy: 0.7515\n",
      "Epoch 18/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5770 - accuracy: 0.7520 - val_loss: 0.5760 - val_accuracy: 0.7506\n",
      "Epoch 19/200\n",
      "2498/2498 [==============================] - 2s 912us/step - loss: 0.5766 - accuracy: 0.7520 - val_loss: 0.5776 - val_accuracy: 0.7517\n",
      "Epoch 20/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5761 - accuracy: 0.7518 - val_loss: 0.5777 - val_accuracy: 0.7522\n",
      "Epoch 21/200\n",
      "2498/2498 [==============================] - 2s 980us/step - loss: 0.5757 - accuracy: 0.7514 - val_loss: 0.5755 - val_accuracy: 0.7511\n",
      "Epoch 22/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5752 - accuracy: 0.7518 - val_loss: 0.5802 - val_accuracy: 0.7519\n",
      "Epoch 23/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5750 - accuracy: 0.7519 - val_loss: 0.5747 - val_accuracy: 0.7512\n",
      "Epoch 24/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5747 - accuracy: 0.7516 - val_loss: 0.5740 - val_accuracy: 0.7518\n",
      "Epoch 25/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5746 - accuracy: 0.7521 - val_loss: 0.5735 - val_accuracy: 0.7509\n",
      "Epoch 26/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5744 - accuracy: 0.7521 - val_loss: 0.5769 - val_accuracy: 0.7514\n",
      "Epoch 27/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5741 - accuracy: 0.7515 - val_loss: 0.5731 - val_accuracy: 0.7517\n",
      "Epoch 28/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7524 - val_loss: 0.5727 - val_accuracy: 0.7517\n",
      "Epoch 29/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5735 - accuracy: 0.7516 - val_loss: 0.5766 - val_accuracy: 0.7518\n",
      "Epoch 30/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5732 - accuracy: 0.7520 - val_loss: 0.5738 - val_accuracy: 0.7519\n",
      "Epoch 31/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5729 - accuracy: 0.7519 - val_loss: 0.5721 - val_accuracy: 0.7518\n",
      "Epoch 32/200\n",
      "2498/2498 [==============================] - 2s 889us/step - loss: 0.5727 - accuracy: 0.7525 - val_loss: 0.5719 - val_accuracy: 0.7509\n",
      "Epoch 33/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5723 - accuracy: 0.7523 - val_loss: 0.5705 - val_accuracy: 0.7522\n",
      "Epoch 34/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5725 - accuracy: 0.7523 - val_loss: 0.5762 - val_accuracy: 0.7486\n",
      "Epoch 35/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5724 - accuracy: 0.7520 - val_loss: 0.5727 - val_accuracy: 0.7524\n",
      "Epoch 36/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5719 - accuracy: 0.7526 - val_loss: 0.5707 - val_accuracy: 0.7526\n",
      "Epoch 37/200\n",
      "2498/2498 [==============================] - 2s 970us/step - loss: 0.5715 - accuracy: 0.7526 - val_loss: 0.5711 - val_accuracy: 0.7520\n",
      "Epoch 38/200\n",
      "2498/2498 [==============================] - 2s 891us/step - loss: 0.5716 - accuracy: 0.7519 - val_loss: 0.5777 - val_accuracy: 0.7490\n",
      "Epoch 39/200\n",
      "2498/2498 [==============================] - 2s 961us/step - loss: 0.5713 - accuracy: 0.7522 - val_loss: 0.5716 - val_accuracy: 0.7519\n",
      "Epoch 40/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5715 - accuracy: 0.7525 - val_loss: 0.5701 - val_accuracy: 0.7523\n",
      "Epoch 41/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5711 - accuracy: 0.7525 - val_loss: 0.5709 - val_accuracy: 0.7517\n",
      "Epoch 42/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5710 - accuracy: 0.7525 - val_loss: 0.5695 - val_accuracy: 0.7526\n",
      "Epoch 43/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5710 - accuracy: 0.7520 - val_loss: 0.5707 - val_accuracy: 0.7517\n",
      "Epoch 44/200\n",
      "2498/2498 [==============================] - 2s 834us/step - loss: 0.5707 - accuracy: 0.7529 - val_loss: 0.5700 - val_accuracy: 0.7520\n",
      "Epoch 45/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5706 - accuracy: 0.7525 - val_loss: 0.5702 - val_accuracy: 0.7520\n",
      "Epoch 46/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5703 - accuracy: 0.7525 - val_loss: 0.5694 - val_accuracy: 0.7527\n",
      "Epoch 47/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5703 - accuracy: 0.7528 - val_loss: 0.5701 - val_accuracy: 0.7522\n",
      "Epoch 48/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5702 - accuracy: 0.7521 - val_loss: 0.5732 - val_accuracy: 0.7512\n",
      "Epoch 49/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7527 - val_loss: 0.5691 - val_accuracy: 0.7526\n",
      "Epoch 50/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5699 - accuracy: 0.7525 - val_loss: 0.5725 - val_accuracy: 0.7523\n",
      "Epoch 51/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5699 - accuracy: 0.7523 - val_loss: 0.5772 - val_accuracy: 0.7483\n",
      "Epoch 52/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7524 - val_loss: 0.5691 - val_accuracy: 0.7523\n",
      "Epoch 53/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5697 - accuracy: 0.7523 - val_loss: 0.5692 - val_accuracy: 0.7513\n",
      "Epoch 54/200\n",
      "2498/2498 [==============================] - 2s 989us/step - loss: 0.5697 - accuracy: 0.7527 - val_loss: 0.5688 - val_accuracy: 0.7534\n",
      "Epoch 55/200\n",
      "2498/2498 [==============================] - 2s 853us/step - loss: 0.5695 - accuracy: 0.7527 - val_loss: 0.5681 - val_accuracy: 0.7518\n",
      "Epoch 56/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5694 - accuracy: 0.7530 - val_loss: 0.5681 - val_accuracy: 0.7525\n",
      "Epoch 57/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5692 - accuracy: 0.7527 - val_loss: 0.5733 - val_accuracy: 0.7522\n",
      "Epoch 58/200\n",
      "2498/2498 [==============================] - 2s 953us/step - loss: 0.5690 - accuracy: 0.7530 - val_loss: 0.5714 - val_accuracy: 0.7503\n",
      "Epoch 59/200\n",
      "2498/2498 [==============================] - 2s 848us/step - loss: 0.5694 - accuracy: 0.7526 - val_loss: 0.5690 - val_accuracy: 0.7512\n",
      "Epoch 60/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5689 - accuracy: 0.7528 - val_loss: 0.5689 - val_accuracy: 0.7526\n",
      "Epoch 61/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7525 - val_loss: 0.5680 - val_accuracy: 0.7525\n",
      "Epoch 62/200\n",
      "2498/2498 [==============================] - 2s 1ms/step - loss: 0.5691 - accuracy: 0.7524 - val_loss: 0.5699 - val_accuracy: 0.7507\n",
      "Epoch 63/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5688 - accuracy: 0.7527 - val_loss: 0.5713 - val_accuracy: 0.7525\n",
      "Epoch 64/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5689 - accuracy: 0.7530 - val_loss: 0.5705 - val_accuracy: 0.7510\n",
      "Epoch 65/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5688 - accuracy: 0.7524 - val_loss: 0.5695 - val_accuracy: 0.7529\n",
      "Epoch 66/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5684 - accuracy: 0.7524 - val_loss: 0.5704 - val_accuracy: 0.7509\n",
      "Epoch 67/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5686 - accuracy: 0.7525 - val_loss: 0.5686 - val_accuracy: 0.7519\n",
      "Epoch 68/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5682 - accuracy: 0.7526 - val_loss: 0.5693 - val_accuracy: 0.7529\n",
      "Epoch 69/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7529 - val_loss: 0.5721 - val_accuracy: 0.7500\n",
      "Epoch 70/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5684 - accuracy: 0.7524 - val_loss: 0.5750 - val_accuracy: 0.7519\n",
      "Epoch 71/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5685 - accuracy: 0.7526 - val_loss: 0.5676 - val_accuracy: 0.7518\n",
      "Epoch 72/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7526 - val_loss: 0.5686 - val_accuracy: 0.7512\n",
      "Epoch 73/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5682 - accuracy: 0.7522 - val_loss: 0.5683 - val_accuracy: 0.7520\n",
      "Epoch 74/200\n",
      "2498/2498 [==============================] - 2s 963us/step - loss: 0.5682 - accuracy: 0.7529 - val_loss: 0.5672 - val_accuracy: 0.7522\n",
      "Epoch 75/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7524 - val_loss: 0.5683 - val_accuracy: 0.7519\n",
      "Epoch 76/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5678 - accuracy: 0.7526 - val_loss: 0.5687 - val_accuracy: 0.7531\n",
      "Epoch 77/200\n",
      "2498/2498 [==============================] - 2s 920us/step - loss: 0.5681 - accuracy: 0.7524 - val_loss: 0.5675 - val_accuracy: 0.7522\n",
      "Epoch 78/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7528 - val_loss: 0.5682 - val_accuracy: 0.7518\n",
      "Epoch 79/200\n",
      "2498/2498 [==============================] - 2s 976us/step - loss: 0.5680 - accuracy: 0.7524 - val_loss: 0.5684 - val_accuracy: 0.7522\n",
      "Epoch 80/200\n",
      "2498/2498 [==============================] - 2s 998us/step - loss: 0.5678 - accuracy: 0.7526 - val_loss: 0.5699 - val_accuracy: 0.7504\n",
      "Epoch 81/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7526 - val_loss: 0.5673 - val_accuracy: 0.7519\n",
      "Epoch 82/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5675 - accuracy: 0.7527 - val_loss: 0.5706 - val_accuracy: 0.7519\n",
      "Epoch 83/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7525 - val_loss: 0.5691 - val_accuracy: 0.7507\n",
      "Epoch 84/200\n",
      "2498/2498 [==============================] - 2196s 879ms/step - loss: 0.5675 - accuracy: 0.7531 - val_loss: 0.5717 - val_accuracy: 0.7503\n",
      "Epoch 85/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7526 - val_loss: 0.5663 - val_accuracy: 0.7524\n",
      "Epoch 86/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5676 - accuracy: 0.7527 - val_loss: 0.5669 - val_accuracy: 0.7529\n",
      "Epoch 87/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5674 - accuracy: 0.7526 - val_loss: 0.5694 - val_accuracy: 0.7529\n",
      "Epoch 88/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5674 - accuracy: 0.7524 - val_loss: 0.5705 - val_accuracy: 0.7519\n",
      "Epoch 89/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5673 - accuracy: 0.7527 - val_loss: 0.5679 - val_accuracy: 0.7512\n",
      "Epoch 90/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5671 - accuracy: 0.7528 - val_loss: 0.5670 - val_accuracy: 0.7531\n",
      "Epoch 91/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5671 - accuracy: 0.7527 - val_loss: 0.5668 - val_accuracy: 0.7519\n",
      "Epoch 92/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5672 - accuracy: 0.7530 - val_loss: 0.5672 - val_accuracy: 0.7533\n",
      "Epoch 93/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5674 - accuracy: 0.7524 - val_loss: 0.5666 - val_accuracy: 0.7521\n",
      "Epoch 94/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5671 - accuracy: 0.7526 - val_loss: 0.5687 - val_accuracy: 0.7519\n",
      "Epoch 95/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5668 - accuracy: 0.7526 - val_loss: 0.5706 - val_accuracy: 0.7519\n",
      "Epoch 96/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5670 - accuracy: 0.7527 - val_loss: 0.5671 - val_accuracy: 0.7526\n",
      "Epoch 97/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5669 - accuracy: 0.7526 - val_loss: 0.5682 - val_accuracy: 0.7524\n",
      "Epoch 98/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5672 - accuracy: 0.7525 - val_loss: 0.5760 - val_accuracy: 0.7507\n",
      "Epoch 99/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5668 - accuracy: 0.7533 - val_loss: 0.5678 - val_accuracy: 0.7509\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5670 - accuracy: 0.7526 - val_loss: 0.5660 - val_accuracy: 0.7529\n",
      "Epoch 101/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5668 - accuracy: 0.7526 - val_loss: 0.5737 - val_accuracy: 0.7490\n",
      "Epoch 102/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5669 - accuracy: 0.7530 - val_loss: 0.5668 - val_accuracy: 0.7521\n",
      "Epoch 103/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7532 - val_loss: 0.5710 - val_accuracy: 0.7499\n",
      "Epoch 104/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7527 - val_loss: 0.5663 - val_accuracy: 0.7527\n",
      "Epoch 105/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5667 - accuracy: 0.7530 - val_loss: 0.5695 - val_accuracy: 0.7506\n",
      "Epoch 106/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5667 - accuracy: 0.7527 - val_loss: 0.5796 - val_accuracy: 0.7468\n",
      "Epoch 107/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5670 - accuracy: 0.7528 - val_loss: 0.5661 - val_accuracy: 0.7521\n",
      "Epoch 108/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7526 - val_loss: 0.5663 - val_accuracy: 0.7524\n",
      "Epoch 109/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5666 - accuracy: 0.7525 - val_loss: 0.5652 - val_accuracy: 0.7526\n",
      "Epoch 110/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7523 - val_loss: 0.5666 - val_accuracy: 0.7521\n",
      "Epoch 111/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7527 - val_loss: 0.5667 - val_accuracy: 0.7518\n",
      "Epoch 112/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7528 - val_loss: 0.5660 - val_accuracy: 0.7526\n",
      "Epoch 113/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7527 - val_loss: 0.5691 - val_accuracy: 0.7501\n",
      "Epoch 114/200\n",
      "2498/2498 [==============================] - 2s 943us/step - loss: 0.5664 - accuracy: 0.7527 - val_loss: 0.5701 - val_accuracy: 0.7506\n",
      "Epoch 115/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7527 - val_loss: 0.5651 - val_accuracy: 0.7528\n",
      "Epoch 116/200\n",
      "2498/2498 [==============================] - 2s 916us/step - loss: 0.5665 - accuracy: 0.7530 - val_loss: 0.5721 - val_accuracy: 0.7494\n",
      "Epoch 117/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5661 - accuracy: 0.7531 - val_loss: 0.5668 - val_accuracy: 0.7521\n",
      "Epoch 118/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7529 - val_loss: 0.5660 - val_accuracy: 0.7515\n",
      "Epoch 119/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7528 - val_loss: 0.5693 - val_accuracy: 0.7504\n",
      "Epoch 120/200\n",
      "2498/2498 [==============================] - 2s 871us/step - loss: 0.5663 - accuracy: 0.7534 - val_loss: 0.5663 - val_accuracy: 0.7520\n",
      "Epoch 121/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7529 - val_loss: 0.5671 - val_accuracy: 0.7517\n",
      "Epoch 122/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5659 - accuracy: 0.7530 - val_loss: 0.5678 - val_accuracy: 0.7511\n",
      "Epoch 123/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5659 - accuracy: 0.7532 - val_loss: 0.5693 - val_accuracy: 0.7520\n",
      "Epoch 124/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7527 - val_loss: 0.5655 - val_accuracy: 0.7526\n",
      "Epoch 125/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5662 - accuracy: 0.7526 - val_loss: 0.5696 - val_accuracy: 0.7494\n",
      "Epoch 126/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5660 - accuracy: 0.7532 - val_loss: 0.5680 - val_accuracy: 0.7522\n",
      "Epoch 127/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5659 - accuracy: 0.7527 - val_loss: 0.5672 - val_accuracy: 0.7525\n",
      "Epoch 128/200\n",
      "2498/2498 [==============================] - 2s 959us/step - loss: 0.5660 - accuracy: 0.7528 - val_loss: 0.5663 - val_accuracy: 0.7525\n",
      "Epoch 129/200\n",
      "2498/2498 [==============================] - 2s 926us/step - loss: 0.5663 - accuracy: 0.7526 - val_loss: 0.5657 - val_accuracy: 0.7518\n",
      "Epoch 130/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5660 - accuracy: 0.7530 - val_loss: 0.5668 - val_accuracy: 0.7511\n",
      "Epoch 131/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5657 - accuracy: 0.7529 - val_loss: 0.5664 - val_accuracy: 0.7517\n",
      "Epoch 132/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7530 - val_loss: 0.5657 - val_accuracy: 0.7521\n",
      "Epoch 133/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5661 - accuracy: 0.7524 - val_loss: 0.5696 - val_accuracy: 0.7497\n",
      "Epoch 134/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5656 - accuracy: 0.7534 - val_loss: 0.5667 - val_accuracy: 0.7512\n",
      "Epoch 135/200\n",
      "2498/2498 [==============================] - 2s 904us/step - loss: 0.5659 - accuracy: 0.7528 - val_loss: 0.5675 - val_accuracy: 0.7511\n",
      "Epoch 136/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7528 - val_loss: 0.5651 - val_accuracy: 0.7522\n",
      "Epoch 137/200\n",
      "2498/2498 [==============================] - 2s 944us/step - loss: 0.5657 - accuracy: 0.7529 - val_loss: 0.5685 - val_accuracy: 0.7510\n",
      "Epoch 138/200\n",
      "2498/2498 [==============================] - 2s 952us/step - loss: 0.5658 - accuracy: 0.7526 - val_loss: 0.5653 - val_accuracy: 0.7530\n",
      "Epoch 139/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5657 - accuracy: 0.7530 - val_loss: 0.5657 - val_accuracy: 0.7517\n",
      "Epoch 140/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7532 - val_loss: 0.5652 - val_accuracy: 0.7523\n",
      "Epoch 141/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7532 - val_loss: 0.5650 - val_accuracy: 0.7522\n",
      "Epoch 142/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7530 - val_loss: 0.5670 - val_accuracy: 0.7522\n",
      "Epoch 143/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7533 - val_loss: 0.5652 - val_accuracy: 0.7524\n",
      "Epoch 144/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5658 - accuracy: 0.7533 - val_loss: 0.5721 - val_accuracy: 0.7512\n",
      "Epoch 145/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5654 - accuracy: 0.7530 - val_loss: 0.5709 - val_accuracy: 0.7516\n",
      "Epoch 146/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5656 - accuracy: 0.7530 - val_loss: 0.5687 - val_accuracy: 0.7504\n",
      "Epoch 147/200\n",
      "2498/2498 [==============================] - 2s 988us/step - loss: 0.5653 - accuracy: 0.7532 - val_loss: 0.5649 - val_accuracy: 0.7519\n",
      "Epoch 148/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7531 - val_loss: 0.5666 - val_accuracy: 0.7519\n",
      "Epoch 149/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5653 - accuracy: 0.7531 - val_loss: 0.5655 - val_accuracy: 0.7520\n",
      "Epoch 150/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7530 - val_loss: 0.5650 - val_accuracy: 0.7527\n",
      "Epoch 151/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5651 - accuracy: 0.7526 - val_loss: 0.5656 - val_accuracy: 0.7520\n",
      "Epoch 152/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7532 - val_loss: 0.5667 - val_accuracy: 0.7513\n",
      "Epoch 153/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7527 - val_loss: 0.5645 - val_accuracy: 0.7524\n",
      "Epoch 154/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5651 - accuracy: 0.7531 - val_loss: 0.5643 - val_accuracy: 0.7521\n",
      "Epoch 155/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5648 - accuracy: 0.7532 - val_loss: 0.5679 - val_accuracy: 0.7514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7529 - val_loss: 0.5645 - val_accuracy: 0.7524\n",
      "Epoch 157/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7527 - val_loss: 0.5665 - val_accuracy: 0.7528\n",
      "Epoch 158/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7526 - val_loss: 0.5656 - val_accuracy: 0.7527\n",
      "Epoch 159/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7529 - val_loss: 0.5658 - val_accuracy: 0.7520\n",
      "Epoch 160/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7530 - val_loss: 0.5648 - val_accuracy: 0.7526\n",
      "Epoch 161/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7532 - val_loss: 0.5655 - val_accuracy: 0.7523\n",
      "Epoch 162/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7528 - val_loss: 0.5652 - val_accuracy: 0.7532\n",
      "Epoch 163/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5651 - accuracy: 0.7526 - val_loss: 0.5678 - val_accuracy: 0.7513\n",
      "Epoch 164/200\n",
      "2498/2498 [==============================] - 2s 903us/step - loss: 0.5651 - accuracy: 0.7526 - val_loss: 0.5698 - val_accuracy: 0.7486\n",
      "Epoch 165/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7534 - val_loss: 0.5640 - val_accuracy: 0.7526\n",
      "Epoch 166/200\n",
      "2498/2498 [==============================] - 2s 993us/step - loss: 0.5651 - accuracy: 0.7532 - val_loss: 0.5660 - val_accuracy: 0.7516\n",
      "Epoch 167/200\n",
      "2498/2498 [==============================] - 2s 909us/step - loss: 0.5649 - accuracy: 0.7533 - val_loss: 0.5685 - val_accuracy: 0.7502\n",
      "Epoch 168/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7530 - val_loss: 0.5697 - val_accuracy: 0.7513\n",
      "Epoch 169/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7529 - val_loss: 0.5674 - val_accuracy: 0.7517\n",
      "Epoch 170/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7533 - val_loss: 0.5658 - val_accuracy: 0.7514\n",
      "Epoch 171/200\n",
      "2498/2498 [==============================] - 2s 907us/step - loss: 0.5650 - accuracy: 0.7533 - val_loss: 0.5640 - val_accuracy: 0.7528\n",
      "Epoch 172/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7527 - val_loss: 0.5677 - val_accuracy: 0.7512\n",
      "Epoch 173/200\n",
      "2498/2498 [==============================] - 2s 909us/step - loss: 0.5649 - accuracy: 0.7528 - val_loss: 0.5640 - val_accuracy: 0.7528\n",
      "Epoch 174/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7531 - val_loss: 0.5646 - val_accuracy: 0.7531\n",
      "Epoch 175/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5648 - accuracy: 0.7531 - val_loss: 0.5646 - val_accuracy: 0.7520\n",
      "Epoch 176/200\n",
      "2498/2498 [==============================] - 2s 920us/step - loss: 0.5649 - accuracy: 0.7530 - val_loss: 0.5651 - val_accuracy: 0.7516\n",
      "Epoch 177/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7532 - val_loss: 0.5657 - val_accuracy: 0.7525\n",
      "Epoch 178/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7528 - val_loss: 0.5644 - val_accuracy: 0.7524\n",
      "Epoch 179/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7530 - val_loss: 0.5649 - val_accuracy: 0.7520\n",
      "Epoch 180/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7523 - val_loss: 0.5638 - val_accuracy: 0.7526\n",
      "Epoch 181/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5649 - accuracy: 0.7529 - val_loss: 0.5654 - val_accuracy: 0.7520\n",
      "Epoch 182/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5648 - accuracy: 0.7531 - val_loss: 0.5653 - val_accuracy: 0.7520\n",
      "Epoch 183/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5646 - accuracy: 0.7531 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5646 - accuracy: 0.7534 - val_loss: 0.5660 - val_accuracy: 0.7516\n",
      "Epoch 185/200\n",
      "2498/2498 [==============================] - 2s 932us/step - loss: 0.5646 - accuracy: 0.7531 - val_loss: 0.5690 - val_accuracy: 0.7494\n",
      "Epoch 186/200\n",
      "2498/2498 [==============================] - 2s 917us/step - loss: 0.5645 - accuracy: 0.7529 - val_loss: 0.5662 - val_accuracy: 0.7524\n",
      "Epoch 187/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7531 - val_loss: 0.5666 - val_accuracy: 0.7525\n",
      "Epoch 188/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5645 - accuracy: 0.7538 - val_loss: 0.5665 - val_accuracy: 0.7522\n",
      "Epoch 189/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7530 - val_loss: 0.5642 - val_accuracy: 0.7527\n",
      "Epoch 190/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5643 - accuracy: 0.7535 - val_loss: 0.5648 - val_accuracy: 0.7530\n",
      "Epoch 191/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5645 - accuracy: 0.7531 - val_loss: 0.5635 - val_accuracy: 0.7532\n",
      "Epoch 192/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5643 - accuracy: 0.7531 - val_loss: 0.5674 - val_accuracy: 0.7514\n",
      "Epoch 193/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5645 - accuracy: 0.7531 - val_loss: 0.5649 - val_accuracy: 0.7520\n",
      "Epoch 194/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5644 - accuracy: 0.7534 - val_loss: 0.5643 - val_accuracy: 0.7528\n",
      "Epoch 195/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7529 - val_loss: 0.5657 - val_accuracy: 0.7522\n",
      "Epoch 196/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5645 - accuracy: 0.7527 - val_loss: 0.5644 - val_accuracy: 0.7526\n",
      "Epoch 197/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5644 - accuracy: 0.7534 - val_loss: 0.5702 - val_accuracy: 0.7503\n",
      "Epoch 198/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5644 - accuracy: 0.7532 - val_loss: 0.5662 - val_accuracy: 0.7506\n",
      "Epoch 199/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5644 - accuracy: 0.7532 - val_loss: 0.5648 - val_accuracy: 0.7519\n",
      "Epoch 200/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5642 - accuracy: 0.7529 - val_loss: 0.5658 - val_accuracy: 0.7530\n",
      "4441/4441 [==============================] - 4s 984us/step - loss: 1.2514 - accuracy: 0.4413\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000019CAD688A60>\n",
      "Epoch Sizes:  200\n",
      "Neurons or Units:  64\n",
      "Test score: 1.2513715028762817\n",
      "Test accuracy: 0.44129320979118347\n",
      "\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 128)               1920      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.6337 - accuracy: 0.7451 - val_loss: 0.6115 - val_accuracy: 0.7509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.6055 - accuracy: 0.7482 - val_loss: 0.5995 - val_accuracy: 0.7487\n",
      "Epoch 3/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5979 - accuracy: 0.7492 - val_loss: 0.5966 - val_accuracy: 0.7475\n",
      "Epoch 4/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5934 - accuracy: 0.7494 - val_loss: 0.5935 - val_accuracy: 0.7497\n",
      "Epoch 5/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5908 - accuracy: 0.7499 - val_loss: 0.5871 - val_accuracy: 0.7498\n",
      "Epoch 6/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5887 - accuracy: 0.7499 - val_loss: 0.5856 - val_accuracy: 0.7510\n",
      "Epoch 7/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5866 - accuracy: 0.7501 - val_loss: 0.5858 - val_accuracy: 0.7495\n",
      "Epoch 8/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5853 - accuracy: 0.7500 - val_loss: 0.5852 - val_accuracy: 0.7470\n",
      "Epoch 9/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5844 - accuracy: 0.7500 - val_loss: 0.5835 - val_accuracy: 0.7499\n",
      "Epoch 10/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5833 - accuracy: 0.7503 - val_loss: 0.5867 - val_accuracy: 0.7459\n",
      "Epoch 11/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5820 - accuracy: 0.7510 - val_loss: 0.5817 - val_accuracy: 0.7505\n",
      "Epoch 12/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5814 - accuracy: 0.7507 - val_loss: 0.5833 - val_accuracy: 0.7477\n",
      "Epoch 13/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5809 - accuracy: 0.7509 - val_loss: 0.5785 - val_accuracy: 0.7505\n",
      "Epoch 14/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5798 - accuracy: 0.7507 - val_loss: 0.5828 - val_accuracy: 0.7462\n",
      "Epoch 15/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5795 - accuracy: 0.7504 - val_loss: 0.5788 - val_accuracy: 0.7507\n",
      "Epoch 16/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5788 - accuracy: 0.7512 - val_loss: 0.5780 - val_accuracy: 0.7531\n",
      "Epoch 17/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5783 - accuracy: 0.7518 - val_loss: 0.5801 - val_accuracy: 0.7481\n",
      "Epoch 18/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5781 - accuracy: 0.7514 - val_loss: 0.5919 - val_accuracy: 0.7405\n",
      "Epoch 19/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5774 - accuracy: 0.7516 - val_loss: 0.5835 - val_accuracy: 0.7521\n",
      "Epoch 20/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5768 - accuracy: 0.7512 - val_loss: 0.5752 - val_accuracy: 0.7521\n",
      "Epoch 21/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5769 - accuracy: 0.7512 - val_loss: 0.5771 - val_accuracy: 0.7493\n",
      "Epoch 22/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5759 - accuracy: 0.7519 - val_loss: 0.5807 - val_accuracy: 0.7519\n",
      "Epoch 23/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5759 - accuracy: 0.7518 - val_loss: 0.5735 - val_accuracy: 0.7514\n",
      "Epoch 24/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5756 - accuracy: 0.7517 - val_loss: 0.5753 - val_accuracy: 0.7528\n",
      "Epoch 25/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5752 - accuracy: 0.7513 - val_loss: 0.5742 - val_accuracy: 0.7525\n",
      "Epoch 26/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5751 - accuracy: 0.7518 - val_loss: 0.5743 - val_accuracy: 0.7534\n",
      "Epoch 27/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5749 - accuracy: 0.7519 - val_loss: 0.5734 - val_accuracy: 0.7520\n",
      "Epoch 28/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5741 - accuracy: 0.7517 - val_loss: 0.5811 - val_accuracy: 0.7478\n",
      "Epoch 29/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5740 - accuracy: 0.7520 - val_loss: 0.5754 - val_accuracy: 0.7502\n",
      "Epoch 30/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7523 - val_loss: 0.5733 - val_accuracy: 0.7515\n",
      "Epoch 31/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5737 - accuracy: 0.7522 - val_loss: 0.5755 - val_accuracy: 0.7523\n",
      "Epoch 32/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5737 - accuracy: 0.7519 - val_loss: 0.5719 - val_accuracy: 0.7525\n",
      "Epoch 33/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5731 - accuracy: 0.7519 - val_loss: 0.5798 - val_accuracy: 0.7515\n",
      "Epoch 34/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5731 - accuracy: 0.7519 - val_loss: 0.5745 - val_accuracy: 0.7523\n",
      "Epoch 35/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5728 - accuracy: 0.7523 - val_loss: 0.5725 - val_accuracy: 0.7526\n",
      "Epoch 36/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5725 - accuracy: 0.7524 - val_loss: 0.5751 - val_accuracy: 0.7489\n",
      "Epoch 37/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5722 - accuracy: 0.7519 - val_loss: 0.5729 - val_accuracy: 0.7520\n",
      "Epoch 38/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5722 - accuracy: 0.7523 - val_loss: 0.5790 - val_accuracy: 0.7485\n",
      "Epoch 39/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5722 - accuracy: 0.7518 - val_loss: 0.5716 - val_accuracy: 0.7516\n",
      "Epoch 40/200\n",
      "2498/2498 [==============================] - 2s 941us/step - loss: 0.5719 - accuracy: 0.7523 - val_loss: 0.5724 - val_accuracy: 0.7522\n",
      "Epoch 41/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5720 - accuracy: 0.7525 - val_loss: 0.5710 - val_accuracy: 0.7524\n",
      "Epoch 42/200\n",
      "2498/2498 [==============================] - 2s 949us/step - loss: 0.5712 - accuracy: 0.7524 - val_loss: 0.5707 - val_accuracy: 0.7519\n",
      "Epoch 43/200\n",
      "2498/2498 [==============================] - 2s 990us/step - loss: 0.5714 - accuracy: 0.7529 - val_loss: 0.5746 - val_accuracy: 0.7523\n",
      "Epoch 44/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7526 - val_loss: 0.5751 - val_accuracy: 0.7525\n",
      "Epoch 45/200\n",
      "2498/2498 [==============================] - 2s 971us/step - loss: 0.5712 - accuracy: 0.7522 - val_loss: 0.5720 - val_accuracy: 0.7524\n",
      "Epoch 46/200\n",
      "2498/2498 [==============================] - 2s 924us/step - loss: 0.5709 - accuracy: 0.7527 - val_loss: 0.5717 - val_accuracy: 0.7502\n",
      "Epoch 47/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5707 - accuracy: 0.7522 - val_loss: 0.5694 - val_accuracy: 0.7519\n",
      "Epoch 48/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5707 - accuracy: 0.7520 - val_loss: 0.5705 - val_accuracy: 0.7521\n",
      "Epoch 49/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5705 - accuracy: 0.7526 - val_loss: 0.5691 - val_accuracy: 0.7530\n",
      "Epoch 50/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5704 - accuracy: 0.7525 - val_loss: 0.5694 - val_accuracy: 0.7520\n",
      "Epoch 51/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5703 - accuracy: 0.7525 - val_loss: 0.5704 - val_accuracy: 0.7523\n",
      "Epoch 52/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5702 - accuracy: 0.7527 - val_loss: 0.5742 - val_accuracy: 0.7504\n",
      "Epoch 53/200\n",
      "2498/2498 [==============================] - 2s 988us/step - loss: 0.5702 - accuracy: 0.7524 - val_loss: 0.5715 - val_accuracy: 0.7511\n",
      "Epoch 54/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5698 - accuracy: 0.7531 - val_loss: 0.5719 - val_accuracy: 0.7508\n",
      "Epoch 55/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5701 - accuracy: 0.7525 - val_loss: 0.5689 - val_accuracy: 0.7527\n",
      "Epoch 56/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7530 - val_loss: 0.5715 - val_accuracy: 0.7536\n",
      "Epoch 57/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5695 - accuracy: 0.7524 - val_loss: 0.5748 - val_accuracy: 0.7492\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5694 - accuracy: 0.7526 - val_loss: 0.5684 - val_accuracy: 0.7530\n",
      "Epoch 59/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5693 - accuracy: 0.7525 - val_loss: 0.5738 - val_accuracy: 0.7526\n",
      "Epoch 60/200\n",
      "2498/2498 [==============================] - 2s 935us/step - loss: 0.5691 - accuracy: 0.7526 - val_loss: 0.5682 - val_accuracy: 0.7518\n",
      "Epoch 61/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5693 - accuracy: 0.7524 - val_loss: 0.5710 - val_accuracy: 0.7502\n",
      "Epoch 62/200\n",
      "2498/2498 [==============================] - 3904s 2s/step - loss: 0.5691 - accuracy: 0.7525 - val_loss: 0.5687 - val_accuracy: 0.7514\n",
      "Epoch 63/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5695 - accuracy: 0.7526 - val_loss: 0.5679 - val_accuracy: 0.7530\n",
      "Epoch 64/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5689 - accuracy: 0.7524 - val_loss: 0.5711 - val_accuracy: 0.7514\n",
      "Epoch 65/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5690 - accuracy: 0.7525 - val_loss: 0.5679 - val_accuracy: 0.7522\n",
      "Epoch 66/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5688 - accuracy: 0.7531 - val_loss: 0.5718 - val_accuracy: 0.7519\n",
      "Epoch 67/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7525 - val_loss: 0.5766 - val_accuracy: 0.7509\n",
      "Epoch 68/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7529 - val_loss: 0.5689 - val_accuracy: 0.7530\n",
      "Epoch 69/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7529 - val_loss: 0.5685 - val_accuracy: 0.7522\n",
      "Epoch 70/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7530 - val_loss: 0.5676 - val_accuracy: 0.7524\n",
      "Epoch 71/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5686 - accuracy: 0.7525 - val_loss: 0.5711 - val_accuracy: 0.7507\n",
      "Epoch 72/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5685 - accuracy: 0.7526 - val_loss: 0.5671 - val_accuracy: 0.7526\n",
      "Epoch 73/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5682 - accuracy: 0.7525 - val_loss: 0.5681 - val_accuracy: 0.7524\n",
      "Epoch 74/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7525 - val_loss: 0.5686 - val_accuracy: 0.7525\n",
      "Epoch 75/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5680 - accuracy: 0.7528 - val_loss: 0.5668 - val_accuracy: 0.7530\n",
      "Epoch 76/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5678 - accuracy: 0.7526 - val_loss: 0.5688 - val_accuracy: 0.7512\n",
      "Epoch 77/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5679 - accuracy: 0.7529 - val_loss: 0.5742 - val_accuracy: 0.7491\n",
      "Epoch 78/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5678 - accuracy: 0.7527 - val_loss: 0.5693 - val_accuracy: 0.7514\n",
      "Epoch 79/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5679 - accuracy: 0.7527 - val_loss: 0.5694 - val_accuracy: 0.7507\n",
      "Epoch 80/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5677 - accuracy: 0.7528 - val_loss: 0.5665 - val_accuracy: 0.7529\n",
      "Epoch 81/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5674 - accuracy: 0.7529 - val_loss: 0.5767 - val_accuracy: 0.7476\n",
      "Epoch 82/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5675 - accuracy: 0.7527 - val_loss: 0.5668 - val_accuracy: 0.7525\n",
      "Epoch 83/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5676 - accuracy: 0.7523 - val_loss: 0.5664 - val_accuracy: 0.7524\n",
      "Epoch 84/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5673 - accuracy: 0.7527 - val_loss: 0.5659 - val_accuracy: 0.7532\n",
      "Epoch 85/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5672 - accuracy: 0.7526 - val_loss: 0.5671 - val_accuracy: 0.7520\n",
      "Epoch 86/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5673 - accuracy: 0.7528 - val_loss: 0.5721 - val_accuracy: 0.7509\n",
      "Epoch 87/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5669 - accuracy: 0.7528 - val_loss: 0.5679 - val_accuracy: 0.7521\n",
      "Epoch 88/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5668 - accuracy: 0.7530 - val_loss: 0.5711 - val_accuracy: 0.7503\n",
      "Epoch 89/200\n",
      "2498/2498 [==============================] - 2s 984us/step - loss: 0.5672 - accuracy: 0.7525 - val_loss: 0.5658 - val_accuracy: 0.7524\n",
      "Epoch 90/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5670 - accuracy: 0.7529 - val_loss: 0.5670 - val_accuracy: 0.7520\n",
      "Epoch 91/200\n",
      "2498/2498 [==============================] - 2s 948us/step - loss: 0.5669 - accuracy: 0.7526 - val_loss: 0.5661 - val_accuracy: 0.7526\n",
      "Epoch 92/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5668 - accuracy: 0.7526 - val_loss: 0.5660 - val_accuracy: 0.7522\n",
      "Epoch 93/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5670 - accuracy: 0.7529 - val_loss: 0.5672 - val_accuracy: 0.7522\n",
      "Epoch 94/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5668 - accuracy: 0.7529 - val_loss: 0.5674 - val_accuracy: 0.7530\n",
      "Epoch 95/200\n",
      "2498/2498 [==============================] - 2s 959us/step - loss: 0.5668 - accuracy: 0.7526 - val_loss: 0.5653 - val_accuracy: 0.7525\n",
      "Epoch 96/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7529 - val_loss: 0.5662 - val_accuracy: 0.7520\n",
      "Epoch 97/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5667 - accuracy: 0.7528 - val_loss: 0.5665 - val_accuracy: 0.7529\n",
      "Epoch 98/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5666 - accuracy: 0.7527 - val_loss: 0.5735 - val_accuracy: 0.7498\n",
      "Epoch 99/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5665 - accuracy: 0.7532 - val_loss: 0.5666 - val_accuracy: 0.7524\n",
      "Epoch 100/200\n",
      "2498/2498 [==============================] - 2s 954us/step - loss: 0.5664 - accuracy: 0.7529 - val_loss: 0.5653 - val_accuracy: 0.7525\n",
      "Epoch 101/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7532 - val_loss: 0.5660 - val_accuracy: 0.7525\n",
      "Epoch 102/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7530 - val_loss: 0.5678 - val_accuracy: 0.7503\n",
      "Epoch 103/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7527 - val_loss: 0.5648 - val_accuracy: 0.7531\n",
      "Epoch 104/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7529 - val_loss: 0.5673 - val_accuracy: 0.7521\n",
      "Epoch 105/200\n",
      "2498/2498 [==============================] - 2s 973us/step - loss: 0.5660 - accuracy: 0.7529 - val_loss: 0.5652 - val_accuracy: 0.7528\n",
      "Epoch 106/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7526 - val_loss: 0.5713 - val_accuracy: 0.7508\n",
      "Epoch 107/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5657 - accuracy: 0.7528 - val_loss: 0.5665 - val_accuracy: 0.7519\n",
      "Epoch 108/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5661 - accuracy: 0.7531 - val_loss: 0.5683 - val_accuracy: 0.7510\n",
      "Epoch 109/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5662 - accuracy: 0.7527 - val_loss: 0.5654 - val_accuracy: 0.7528\n",
      "Epoch 110/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5657 - accuracy: 0.7529 - val_loss: 0.5676 - val_accuracy: 0.7540\n",
      "Epoch 111/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7529 - val_loss: 0.5689 - val_accuracy: 0.7521\n",
      "Epoch 112/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5663 - accuracy: 0.7530 - val_loss: 0.5697 - val_accuracy: 0.7508\n",
      "Epoch 113/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7528 - val_loss: 0.5661 - val_accuracy: 0.7522\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 2s 954us/step - loss: 0.5655 - accuracy: 0.7534 - val_loss: 0.5672 - val_accuracy: 0.7533\n",
      "Epoch 115/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5658 - accuracy: 0.7530 - val_loss: 0.5708 - val_accuracy: 0.7514\n",
      "Epoch 116/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7531 - val_loss: 0.5658 - val_accuracy: 0.7526\n",
      "Epoch 117/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5656 - accuracy: 0.7528 - val_loss: 0.5676 - val_accuracy: 0.7527\n",
      "Epoch 118/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5656 - accuracy: 0.7533 - val_loss: 0.5667 - val_accuracy: 0.7531\n",
      "Epoch 119/200\n",
      "2498/2498 [==============================] - 2s 831us/step - loss: 0.5656 - accuracy: 0.7530 - val_loss: 0.5654 - val_accuracy: 0.7529\n",
      "Epoch 120/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7526 - val_loss: 0.5685 - val_accuracy: 0.7516\n",
      "Epoch 121/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7531 - val_loss: 0.5722 - val_accuracy: 0.7516\n",
      "Epoch 122/200\n",
      "2498/2498 [==============================] - 2s 947us/step - loss: 0.5656 - accuracy: 0.7526 - val_loss: 0.5690 - val_accuracy: 0.7513\n",
      "Epoch 123/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7530 - val_loss: 0.5665 - val_accuracy: 0.7527\n",
      "Epoch 124/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5658 - accuracy: 0.7525 - val_loss: 0.5657 - val_accuracy: 0.7521\n",
      "Epoch 125/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7531 - val_loss: 0.5653 - val_accuracy: 0.7529\n",
      "Epoch 126/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5653 - accuracy: 0.7531 - val_loss: 0.5663 - val_accuracy: 0.7524\n",
      "Epoch 127/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7531 - val_loss: 0.5697 - val_accuracy: 0.7505\n",
      "Epoch 128/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5653 - accuracy: 0.7527 - val_loss: 0.5641 - val_accuracy: 0.7530\n",
      "Epoch 129/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7533 - val_loss: 0.5688 - val_accuracy: 0.7516\n",
      "Epoch 130/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7532 - val_loss: 0.5657 - val_accuracy: 0.7536\n",
      "Epoch 131/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7534 - val_loss: 0.5662 - val_accuracy: 0.7521\n",
      "Epoch 132/200\n",
      "2498/2498 [==============================] - 2s 955us/step - loss: 0.5655 - accuracy: 0.7526 - val_loss: 0.5637 - val_accuracy: 0.7537\n",
      "Epoch 133/200\n",
      "2498/2498 [==============================] - 2s 958us/step - loss: 0.5648 - accuracy: 0.7528 - val_loss: 0.5647 - val_accuracy: 0.7528\n",
      "Epoch 134/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7527 - val_loss: 0.5653 - val_accuracy: 0.7519\n",
      "Epoch 135/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7530 - val_loss: 0.5648 - val_accuracy: 0.7522\n",
      "Epoch 136/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5650 - accuracy: 0.7525 - val_loss: 0.5655 - val_accuracy: 0.7518\n",
      "Epoch 137/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7530 - val_loss: 0.5648 - val_accuracy: 0.7525\n",
      "Epoch 138/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7531 - val_loss: 0.5662 - val_accuracy: 0.7522\n",
      "Epoch 139/200\n",
      "2498/2498 [==============================] - 2s 925us/step - loss: 0.5647 - accuracy: 0.7530 - val_loss: 0.5659 - val_accuracy: 0.7533\n",
      "Epoch 140/200\n",
      "2498/2498 [==============================] - 2s 963us/step - loss: 0.5650 - accuracy: 0.7530 - val_loss: 0.5649 - val_accuracy: 0.7528\n",
      "Epoch 141/200\n",
      "2498/2498 [==============================] - 2s 973us/step - loss: 0.5646 - accuracy: 0.7527 - val_loss: 0.5748 - val_accuracy: 0.7491\n",
      "Epoch 142/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5650 - accuracy: 0.7528 - val_loss: 0.5679 - val_accuracy: 0.7514\n",
      "Epoch 143/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5647 - accuracy: 0.7527 - val_loss: 0.5646 - val_accuracy: 0.7530\n",
      "Epoch 144/200\n",
      "2498/2498 [==============================] - 2s 958us/step - loss: 0.5646 - accuracy: 0.7529 - val_loss: 0.5661 - val_accuracy: 0.7515\n",
      "Epoch 145/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5648 - accuracy: 0.7529 - val_loss: 0.5649 - val_accuracy: 0.7522\n",
      "Epoch 146/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5647 - accuracy: 0.7528 - val_loss: 0.5653 - val_accuracy: 0.7520\n",
      "Epoch 147/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7525 - val_loss: 0.5630 - val_accuracy: 0.7533\n",
      "Epoch 148/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5646 - accuracy: 0.7527 - val_loss: 0.5673 - val_accuracy: 0.7509\n",
      "Epoch 149/200\n",
      "2498/2498 [==============================] - 2s 836us/step - loss: 0.5644 - accuracy: 0.7527 - val_loss: 0.5653 - val_accuracy: 0.7524\n",
      "Epoch 150/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5645 - accuracy: 0.7529 - val_loss: 0.5683 - val_accuracy: 0.7508\n",
      "Epoch 151/200\n",
      "2498/2498 [==============================] - 2s 914us/step - loss: 0.5646 - accuracy: 0.7529 - val_loss: 0.5631 - val_accuracy: 0.7527\n",
      "Epoch 152/200\n",
      "2498/2498 [==============================] - 2s 999us/step - loss: 0.5645 - accuracy: 0.7528 - val_loss: 0.5635 - val_accuracy: 0.7524\n",
      "Epoch 153/200\n",
      "2498/2498 [==============================] - 2s 922us/step - loss: 0.5645 - accuracy: 0.7529 - val_loss: 0.5679 - val_accuracy: 0.7519\n",
      "Epoch 154/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5642 - accuracy: 0.7527 - val_loss: 0.5635 - val_accuracy: 0.7528\n",
      "Epoch 155/200\n",
      "2498/2498 [==============================] - 2s 987us/step - loss: 0.5645 - accuracy: 0.7523 - val_loss: 0.5646 - val_accuracy: 0.7524\n",
      "Epoch 156/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5640 - accuracy: 0.7527 - val_loss: 0.5679 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5645 - accuracy: 0.7525 - val_loss: 0.5681 - val_accuracy: 0.7498\n",
      "Epoch 158/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5643 - accuracy: 0.7529 - val_loss: 0.5644 - val_accuracy: 0.7521\n",
      "Epoch 159/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5644 - accuracy: 0.7527 - val_loss: 0.5652 - val_accuracy: 0.7512\n",
      "Epoch 160/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5642 - accuracy: 0.7525 - val_loss: 0.5644 - val_accuracy: 0.7522\n",
      "Epoch 161/200\n",
      "2498/2498 [==============================] - 2s 902us/step - loss: 0.5642 - accuracy: 0.7527 - val_loss: 0.5630 - val_accuracy: 0.7533\n",
      "Epoch 162/200\n",
      "2498/2498 [==============================] - 2s 845us/step - loss: 0.5641 - accuracy: 0.7531 - val_loss: 0.5650 - val_accuracy: 0.7508\n",
      "Epoch 163/200\n",
      "2498/2498 [==============================] - 2s 961us/step - loss: 0.5642 - accuracy: 0.7523 - val_loss: 0.5695 - val_accuracy: 0.7523\n",
      "Epoch 164/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5644 - accuracy: 0.7528 - val_loss: 0.5749 - val_accuracy: 0.7496\n",
      "Epoch 165/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5644 - accuracy: 0.7529 - val_loss: 0.5652 - val_accuracy: 0.7515\n",
      "Epoch 166/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5645 - accuracy: 0.7526 - val_loss: 0.5664 - val_accuracy: 0.7514\n",
      "Epoch 167/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5642 - accuracy: 0.7527 - val_loss: 0.5663 - val_accuracy: 0.7508\n",
      "Epoch 168/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5640 - accuracy: 0.7531 - val_loss: 0.5670 - val_accuracy: 0.7518\n",
      "Epoch 169/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5639 - accuracy: 0.7527 - val_loss: 0.5623 - val_accuracy: 0.7540\n",
      "Epoch 170/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5640 - accuracy: 0.7526 - val_loss: 0.5627 - val_accuracy: 0.7527\n",
      "Epoch 171/200\n",
      "2498/2498 [==============================] - 2s 976us/step - loss: 0.5641 - accuracy: 0.7529 - val_loss: 0.5636 - val_accuracy: 0.7519\n",
      "Epoch 172/200\n",
      "2498/2498 [==============================] - 2s 950us/step - loss: 0.5639 - accuracy: 0.7527 - val_loss: 0.5627 - val_accuracy: 0.7519\n",
      "Epoch 173/200\n",
      "2498/2498 [==============================] - 2s 980us/step - loss: 0.5641 - accuracy: 0.7529 - val_loss: 0.5741 - val_accuracy: 0.7490\n",
      "Epoch 174/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5639 - accuracy: 0.7523 - val_loss: 0.5647 - val_accuracy: 0.7521\n",
      "Epoch 175/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5638 - accuracy: 0.7528 - val_loss: 0.5635 - val_accuracy: 0.7518\n",
      "Epoch 176/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5634 - accuracy: 0.7526 - val_loss: 0.5641 - val_accuracy: 0.7526\n",
      "Epoch 177/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5639 - accuracy: 0.7531 - val_loss: 0.5703 - val_accuracy: 0.7502\n",
      "Epoch 178/200\n",
      "2498/2498 [==============================] - 2s 992us/step - loss: 0.5636 - accuracy: 0.7531 - val_loss: 0.5632 - val_accuracy: 0.7525\n",
      "Epoch 179/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5636 - accuracy: 0.7525 - val_loss: 0.5684 - val_accuracy: 0.7498\n",
      "Epoch 180/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5640 - accuracy: 0.7525 - val_loss: 0.5641 - val_accuracy: 0.7525\n",
      "Epoch 181/200\n",
      "2498/2498 [==============================] - 2s 962us/step - loss: 0.5638 - accuracy: 0.7528 - val_loss: 0.5643 - val_accuracy: 0.7529\n",
      "Epoch 182/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5636 - accuracy: 0.7530 - val_loss: 0.5657 - val_accuracy: 0.7521\n",
      "Epoch 183/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5636 - accuracy: 0.7528 - val_loss: 0.5656 - val_accuracy: 0.7518\n",
      "Epoch 184/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5636 - accuracy: 0.7528 - val_loss: 0.5657 - val_accuracy: 0.7519\n",
      "Epoch 185/200\n",
      "2498/2498 [==============================] - 2s 866us/step - loss: 0.5636 - accuracy: 0.7528 - val_loss: 0.5643 - val_accuracy: 0.7523\n",
      "Epoch 186/200\n",
      "2498/2498 [==============================] - 2s 915us/step - loss: 0.5637 - accuracy: 0.7529 - val_loss: 0.5634 - val_accuracy: 0.7518\n",
      "Epoch 187/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5635 - accuracy: 0.7528 - val_loss: 0.5643 - val_accuracy: 0.7510\n",
      "Epoch 188/200\n",
      "2498/2498 [==============================] - 2s 916us/step - loss: 0.5635 - accuracy: 0.7529 - val_loss: 0.5625 - val_accuracy: 0.7537\n",
      "Epoch 189/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5634 - accuracy: 0.7527 - val_loss: 0.5621 - val_accuracy: 0.7526\n",
      "Epoch 190/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5636 - accuracy: 0.7527 - val_loss: 0.5674 - val_accuracy: 0.7497\n",
      "Epoch 191/200\n",
      "2498/2498 [==============================] - 2s 939us/step - loss: 0.5635 - accuracy: 0.7527 - val_loss: 0.5635 - val_accuracy: 0.7517\n",
      "Epoch 192/200\n",
      "2498/2498 [==============================] - 2s 858us/step - loss: 0.5635 - accuracy: 0.7528 - val_loss: 0.5640 - val_accuracy: 0.7521\n",
      "Epoch 193/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5634 - accuracy: 0.7523 - val_loss: 0.5626 - val_accuracy: 0.7524\n",
      "Epoch 194/200\n",
      "2498/2498 [==============================] - 2s 894us/step - loss: 0.5634 - accuracy: 0.7530 - val_loss: 0.5629 - val_accuracy: 0.7518\n",
      "Epoch 195/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5636 - accuracy: 0.7526 - val_loss: 0.5631 - val_accuracy: 0.7523\n",
      "Epoch 196/200\n",
      "2498/2498 [==============================] - 2s 952us/step - loss: 0.5636 - accuracy: 0.7527 - val_loss: 0.5634 - val_accuracy: 0.7523\n",
      "Epoch 197/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5633 - accuracy: 0.7526 - val_loss: 0.5677 - val_accuracy: 0.7517\n",
      "Epoch 198/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5635 - accuracy: 0.7527 - val_loss: 0.5645 - val_accuracy: 0.7516\n",
      "Epoch 199/200\n",
      "2498/2498 [==============================] - 2s 949us/step - loss: 0.5636 - accuracy: 0.7527 - val_loss: 0.5639 - val_accuracy: 0.7535\n",
      "Epoch 200/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5630 - accuracy: 0.7525 - val_loss: 0.5636 - val_accuracy: 0.7517\n",
      "4441/4441 [==============================] - 4s 950us/step - loss: 1.2423 - accuracy: 0.4505\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000019CAD688A60>\n",
      "Epoch Sizes:  200\n",
      "Neurons or Units:  128\n",
      "Test score: 1.2423312664031982\n",
      "Test accuracy: 0.45048418641090393\n",
      "\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 14)                56        \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 256)               3840      \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,667\n",
      "Trainable params: 4,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "2416/2498 [============================>.] - ETA: 0s - loss: 0.6319 - accuracy: 0.7451WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6314 - accuracy: 0.7451 - val_loss: 0.6145 - val_accuracy: 0.7414\n",
      "Epoch 2/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.6047 - accuracy: 0.7484 - val_loss: 0.5998 - val_accuracy: 0.7497\n",
      "Epoch 3/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5973 - accuracy: 0.7488 - val_loss: 0.5952 - val_accuracy: 0.7513\n",
      "Epoch 4/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5931 - accuracy: 0.7490 - val_loss: 0.5915 - val_accuracy: 0.7491\n",
      "Epoch 5/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5905 - accuracy: 0.7491 - val_loss: 0.5874 - val_accuracy: 0.7490\n",
      "Epoch 6/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5889 - accuracy: 0.7489 - val_loss: 0.5889 - val_accuracy: 0.7508\n",
      "Epoch 7/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5867 - accuracy: 0.7502 - val_loss: 0.5853 - val_accuracy: 0.7494\n",
      "Epoch 8/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5859 - accuracy: 0.7500 - val_loss: 0.5822 - val_accuracy: 0.7494\n",
      "Epoch 9/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5849 - accuracy: 0.7501 - val_loss: 0.5822 - val_accuracy: 0.7494\n",
      "Epoch 10/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5836 - accuracy: 0.7503 - val_loss: 0.5849 - val_accuracy: 0.7469\n",
      "Epoch 11/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5830 - accuracy: 0.7502 - val_loss: 0.5799 - val_accuracy: 0.7496\n",
      "Epoch 12/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5820 - accuracy: 0.7504 - val_loss: 0.5820 - val_accuracy: 0.7506\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5812 - accuracy: 0.7504 - val_loss: 0.5810 - val_accuracy: 0.7478\n",
      "Epoch 14/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5807 - accuracy: 0.7503 - val_loss: 0.5827 - val_accuracy: 0.7467\n",
      "Epoch 15/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5801 - accuracy: 0.7507 - val_loss: 0.5871 - val_accuracy: 0.7515\n",
      "Epoch 16/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5789 - accuracy: 0.7513 - val_loss: 0.5831 - val_accuracy: 0.7510\n",
      "Epoch 17/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5791 - accuracy: 0.7508 - val_loss: 0.5773 - val_accuracy: 0.7502\n",
      "Epoch 18/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5778 - accuracy: 0.7507 - val_loss: 0.5801 - val_accuracy: 0.7511\n",
      "Epoch 19/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5772 - accuracy: 0.7513 - val_loss: 0.5810 - val_accuracy: 0.7478\n",
      "Epoch 20/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5767 - accuracy: 0.7517 - val_loss: 0.5748 - val_accuracy: 0.7511\n",
      "Epoch 21/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5760 - accuracy: 0.7518 - val_loss: 0.5777 - val_accuracy: 0.7520\n",
      "Epoch 22/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5754 - accuracy: 0.7518 - val_loss: 0.5742 - val_accuracy: 0.7510\n",
      "Epoch 23/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5754 - accuracy: 0.7521 - val_loss: 0.5782 - val_accuracy: 0.7515\n",
      "Epoch 24/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5744 - accuracy: 0.7519 - val_loss: 0.5737 - val_accuracy: 0.7510\n",
      "Epoch 25/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5748 - accuracy: 0.7521 - val_loss: 0.5904 - val_accuracy: 0.7444\n",
      "Epoch 26/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5740 - accuracy: 0.7521 - val_loss: 0.5787 - val_accuracy: 0.7487\n",
      "Epoch 27/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5734 - accuracy: 0.7517 - val_loss: 0.5722 - val_accuracy: 0.7510\n",
      "Epoch 28/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5730 - accuracy: 0.7523 - val_loss: 0.5752 - val_accuracy: 0.7510\n",
      "Epoch 29/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5727 - accuracy: 0.7521 - val_loss: 0.5724 - val_accuracy: 0.7516\n",
      "Epoch 30/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5731 - accuracy: 0.7518 - val_loss: 0.5746 - val_accuracy: 0.7520\n",
      "Epoch 31/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5732 - accuracy: 0.7519 - val_loss: 0.5734 - val_accuracy: 0.7503\n",
      "Epoch 32/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5725 - accuracy: 0.7524 - val_loss: 0.5779 - val_accuracy: 0.7515\n",
      "Epoch 33/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5717 - accuracy: 0.7527 - val_loss: 0.5741 - val_accuracy: 0.7505\n",
      "Epoch 34/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5721 - accuracy: 0.7521 - val_loss: 0.5766 - val_accuracy: 0.7501\n",
      "Epoch 35/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5714 - accuracy: 0.7525 - val_loss: 0.5706 - val_accuracy: 0.7516\n",
      "Epoch 36/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5718 - accuracy: 0.7522 - val_loss: 0.5741 - val_accuracy: 0.7525\n",
      "Epoch 37/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5714 - accuracy: 0.7520 - val_loss: 0.5721 - val_accuracy: 0.7507\n",
      "Epoch 38/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5712 - accuracy: 0.7527 - val_loss: 0.5862 - val_accuracy: 0.7445\n",
      "Epoch 39/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5709 - accuracy: 0.7524 - val_loss: 0.5688 - val_accuracy: 0.7529\n",
      "Epoch 40/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7520 - val_loss: 0.5874 - val_accuracy: 0.7453\n",
      "Epoch 41/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5710 - accuracy: 0.7524 - val_loss: 0.5697 - val_accuracy: 0.7521\n",
      "Epoch 42/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5701 - accuracy: 0.7525 - val_loss: 0.5704 - val_accuracy: 0.7523\n",
      "Epoch 43/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5706 - accuracy: 0.7523 - val_loss: 0.5689 - val_accuracy: 0.7521\n",
      "Epoch 44/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7523 - val_loss: 0.5750 - val_accuracy: 0.7517\n",
      "Epoch 45/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5700 - accuracy: 0.7520 - val_loss: 0.5699 - val_accuracy: 0.7510\n",
      "Epoch 46/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5699 - accuracy: 0.7525 - val_loss: 0.5721 - val_accuracy: 0.7527\n",
      "Epoch 47/200\n",
      "2498/2498 [==============================] - 2s 963us/step - loss: 0.5697 - accuracy: 0.7523 - val_loss: 0.5686 - val_accuracy: 0.7528\n",
      "Epoch 48/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5698 - accuracy: 0.7523 - val_loss: 0.5691 - val_accuracy: 0.7523\n",
      "Epoch 49/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5695 - accuracy: 0.7523 - val_loss: 0.5709 - val_accuracy: 0.7516\n",
      "Epoch 50/200\n",
      "2498/2498 [==============================] - 2s 998us/step - loss: 0.5693 - accuracy: 0.7525 - val_loss: 0.5715 - val_accuracy: 0.7509\n",
      "Epoch 51/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5695 - accuracy: 0.7527 - val_loss: 0.5689 - val_accuracy: 0.7526\n",
      "Epoch 52/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5697 - accuracy: 0.7526 - val_loss: 0.5726 - val_accuracy: 0.7506\n",
      "Epoch 53/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5689 - accuracy: 0.7524 - val_loss: 0.5741 - val_accuracy: 0.7510\n",
      "Epoch 54/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5689 - accuracy: 0.7525 - val_loss: 0.5683 - val_accuracy: 0.7521\n",
      "Epoch 55/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5687 - accuracy: 0.7528 - val_loss: 0.5709 - val_accuracy: 0.7511\n",
      "Epoch 56/200\n",
      "2498/2498 [==============================] - 1769s 708ms/step - loss: 0.5689 - accuracy: 0.7522 - val_loss: 0.5704 - val_accuracy: 0.7524\n",
      "Epoch 57/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5685 - accuracy: 0.7523 - val_loss: 0.5674 - val_accuracy: 0.7524\n",
      "Epoch 58/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5683 - accuracy: 0.7522 - val_loss: 0.5684 - val_accuracy: 0.7512\n",
      "Epoch 59/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5684 - accuracy: 0.7522 - val_loss: 0.5716 - val_accuracy: 0.7513\n",
      "Epoch 60/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5682 - accuracy: 0.7524 - val_loss: 0.5680 - val_accuracy: 0.7527\n",
      "Epoch 61/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5680 - accuracy: 0.7525 - val_loss: 0.5786 - val_accuracy: 0.7480\n",
      "Epoch 62/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5678 - accuracy: 0.7527 - val_loss: 0.5691 - val_accuracy: 0.7537\n",
      "Epoch 63/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5680 - accuracy: 0.7527 - val_loss: 0.5707 - val_accuracy: 0.7514\n",
      "Epoch 64/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5677 - accuracy: 0.7528 - val_loss: 0.5675 - val_accuracy: 0.7516\n",
      "Epoch 65/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5679 - accuracy: 0.7529 - val_loss: 0.5686 - val_accuracy: 0.7523\n",
      "Epoch 66/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5673 - accuracy: 0.7529 - val_loss: 0.5685 - val_accuracy: 0.7522\n",
      "Epoch 67/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5675 - accuracy: 0.7527 - val_loss: 0.5751 - val_accuracy: 0.7501\n",
      "Epoch 68/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5677 - accuracy: 0.7527 - val_loss: 0.5677 - val_accuracy: 0.7514\n",
      "Epoch 69/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5675 - accuracy: 0.7523 - val_loss: 0.5718 - val_accuracy: 0.7520\n",
      "Epoch 70/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5674 - accuracy: 0.7524 - val_loss: 0.5664 - val_accuracy: 0.7528\n",
      "Epoch 71/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5671 - accuracy: 0.7530 - val_loss: 0.5674 - val_accuracy: 0.7531\n",
      "Epoch 72/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5672 - accuracy: 0.7527 - val_loss: 0.5664 - val_accuracy: 0.7520\n",
      "Epoch 73/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5670 - accuracy: 0.7518 - val_loss: 0.5654 - val_accuracy: 0.7530\n",
      "Epoch 74/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5670 - accuracy: 0.7527 - val_loss: 0.5764 - val_accuracy: 0.7502\n",
      "Epoch 75/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5668 - accuracy: 0.7527 - val_loss: 0.5656 - val_accuracy: 0.7530\n",
      "Epoch 76/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5668 - accuracy: 0.7532 - val_loss: 0.5672 - val_accuracy: 0.7518\n",
      "Epoch 77/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5667 - accuracy: 0.7527 - val_loss: 0.5688 - val_accuracy: 0.7514\n",
      "Epoch 78/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5669 - accuracy: 0.7527 - val_loss: 0.5671 - val_accuracy: 0.7520\n",
      "Epoch 79/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5668 - accuracy: 0.7527 - val_loss: 0.5772 - val_accuracy: 0.7495\n",
      "Epoch 80/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5665 - accuracy: 0.7524 - val_loss: 0.5659 - val_accuracy: 0.7525\n",
      "Epoch 81/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5663 - accuracy: 0.7528 - val_loss: 0.5683 - val_accuracy: 0.7506\n",
      "Epoch 82/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5665 - accuracy: 0.7530 - val_loss: 0.5673 - val_accuracy: 0.7514\n",
      "Epoch 83/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7523 - val_loss: 0.5724 - val_accuracy: 0.7495\n",
      "Epoch 84/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7526 - val_loss: 0.5654 - val_accuracy: 0.7524\n",
      "Epoch 85/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5664 - accuracy: 0.7527 - val_loss: 0.5657 - val_accuracy: 0.7516\n",
      "Epoch 86/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5664 - accuracy: 0.7522 - val_loss: 0.5680 - val_accuracy: 0.7507\n",
      "Epoch 87/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5664 - accuracy: 0.7529 - val_loss: 0.5666 - val_accuracy: 0.7518\n",
      "Epoch 88/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5660 - accuracy: 0.7527 - val_loss: 0.5662 - val_accuracy: 0.7514\n",
      "Epoch 89/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5662 - accuracy: 0.7524 - val_loss: 0.5710 - val_accuracy: 0.7517\n",
      "Epoch 90/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5661 - accuracy: 0.7522 - val_loss: 0.5713 - val_accuracy: 0.7494\n",
      "Epoch 91/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5658 - accuracy: 0.7528 - val_loss: 0.5660 - val_accuracy: 0.7521\n",
      "Epoch 92/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5659 - accuracy: 0.7527 - val_loss: 0.5665 - val_accuracy: 0.7521\n",
      "Epoch 93/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5657 - accuracy: 0.7526 - val_loss: 0.5638 - val_accuracy: 0.7528\n",
      "Epoch 94/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5661 - accuracy: 0.7523 - val_loss: 0.5739 - val_accuracy: 0.7485\n",
      "Epoch 95/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5656 - accuracy: 0.7524 - val_loss: 0.5669 - val_accuracy: 0.7533\n",
      "Epoch 96/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5655 - accuracy: 0.7528 - val_loss: 0.5655 - val_accuracy: 0.7524\n",
      "Epoch 97/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5655 - accuracy: 0.7528 - val_loss: 0.5656 - val_accuracy: 0.7523\n",
      "Epoch 98/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5656 - accuracy: 0.7529 - val_loss: 0.5642 - val_accuracy: 0.7529\n",
      "Epoch 99/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5653 - accuracy: 0.7527 - val_loss: 0.5657 - val_accuracy: 0.7520\n",
      "Epoch 100/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5655 - accuracy: 0.7528 - val_loss: 0.5750 - val_accuracy: 0.7498\n",
      "Epoch 101/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5657 - accuracy: 0.7528 - val_loss: 0.5639 - val_accuracy: 0.7526\n",
      "Epoch 102/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5651 - accuracy: 0.7527 - val_loss: 0.5763 - val_accuracy: 0.7492\n",
      "Epoch 103/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5656 - accuracy: 0.7527 - val_loss: 0.5688 - val_accuracy: 0.7515\n",
      "Epoch 104/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7527 - val_loss: 0.5660 - val_accuracy: 0.7522\n",
      "Epoch 105/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5651 - accuracy: 0.7530 - val_loss: 0.5656 - val_accuracy: 0.7535\n",
      "Epoch 106/200\n",
      "2498/2498 [==============================] - 2s 982us/step - loss: 0.5652 - accuracy: 0.7528 - val_loss: 0.5701 - val_accuracy: 0.7490\n",
      "Epoch 107/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5652 - accuracy: 0.7529 - val_loss: 0.5639 - val_accuracy: 0.7529\n",
      "Epoch 108/200\n",
      "2498/2498 [==============================] - 2s 983us/step - loss: 0.5649 - accuracy: 0.7530 - val_loss: 0.5672 - val_accuracy: 0.7530\n",
      "Epoch 109/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7526 - val_loss: 0.5643 - val_accuracy: 0.7524\n",
      "Epoch 110/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5650 - accuracy: 0.7525 - val_loss: 0.5644 - val_accuracy: 0.7526\n",
      "Epoch 111/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5650 - accuracy: 0.7526 - val_loss: 0.5693 - val_accuracy: 0.7510\n",
      "Epoch 112/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5654 - accuracy: 0.7525 - val_loss: 0.5695 - val_accuracy: 0.7515\n",
      "Epoch 113/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5652 - accuracy: 0.7529 - val_loss: 0.5637 - val_accuracy: 0.7523\n",
      "Epoch 114/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5647 - accuracy: 0.7530 - val_loss: 0.5657 - val_accuracy: 0.7514\n",
      "Epoch 115/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5649 - accuracy: 0.7530 - val_loss: 0.5652 - val_accuracy: 0.7526\n",
      "Epoch 116/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7533 - val_loss: 0.5642 - val_accuracy: 0.7533\n",
      "Epoch 117/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5648 - accuracy: 0.7524 - val_loss: 0.5660 - val_accuracy: 0.7521\n",
      "Epoch 118/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7526 - val_loss: 0.5701 - val_accuracy: 0.7520\n",
      "Epoch 119/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7528 - val_loss: 0.5684 - val_accuracy: 0.7511\n",
      "Epoch 120/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7528 - val_loss: 0.5659 - val_accuracy: 0.7518\n",
      "Epoch 121/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7530 - val_loss: 0.5721 - val_accuracy: 0.7497\n",
      "Epoch 122/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5647 - accuracy: 0.7527 - val_loss: 0.5639 - val_accuracy: 0.7521\n",
      "Epoch 123/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5648 - accuracy: 0.7523 - val_loss: 0.5634 - val_accuracy: 0.7521\n",
      "Epoch 124/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5647 - accuracy: 0.7527 - val_loss: 0.5650 - val_accuracy: 0.7526\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5645 - accuracy: 0.7527 - val_loss: 0.5653 - val_accuracy: 0.7512\n",
      "Epoch 126/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5646 - accuracy: 0.7528 - val_loss: 0.5642 - val_accuracy: 0.7516\n",
      "Epoch 127/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5647 - accuracy: 0.7523 - val_loss: 0.5643 - val_accuracy: 0.7514\n",
      "Epoch 128/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5645 - accuracy: 0.7529 - val_loss: 0.5649 - val_accuracy: 0.7521\n",
      "Epoch 129/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5647 - accuracy: 0.7523 - val_loss: 0.5646 - val_accuracy: 0.7519\n",
      "Epoch 130/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5644 - accuracy: 0.7533 - val_loss: 0.5665 - val_accuracy: 0.7512\n",
      "Epoch 131/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5646 - accuracy: 0.7527 - val_loss: 0.5700 - val_accuracy: 0.7509\n",
      "Epoch 132/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5649 - accuracy: 0.7530 - val_loss: 0.5635 - val_accuracy: 0.7524\n",
      "Epoch 133/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5645 - accuracy: 0.7525 - val_loss: 0.5657 - val_accuracy: 0.7514\n",
      "Epoch 134/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5648 - accuracy: 0.7528 - val_loss: 0.5639 - val_accuracy: 0.7521\n",
      "Epoch 135/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5642 - accuracy: 0.7531 - val_loss: 0.5699 - val_accuracy: 0.7504\n",
      "Epoch 136/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5643 - accuracy: 0.7525 - val_loss: 0.5639 - val_accuracy: 0.7530\n",
      "Epoch 137/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5642 - accuracy: 0.7528 - val_loss: 0.5658 - val_accuracy: 0.7526\n",
      "Epoch 138/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5645 - accuracy: 0.7524 - val_loss: 0.5647 - val_accuracy: 0.7525\n",
      "Epoch 139/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5642 - accuracy: 0.7528 - val_loss: 0.5643 - val_accuracy: 0.7520\n",
      "Epoch 140/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5641 - accuracy: 0.7530 - val_loss: 0.5632 - val_accuracy: 0.7524\n",
      "Epoch 141/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5641 - accuracy: 0.7532 - val_loss: 0.5647 - val_accuracy: 0.7517\n",
      "Epoch 142/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5642 - accuracy: 0.7527 - val_loss: 0.5716 - val_accuracy: 0.7502\n",
      "Epoch 143/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5645 - accuracy: 0.7526 - val_loss: 0.5650 - val_accuracy: 0.7524\n",
      "Epoch 144/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5642 - accuracy: 0.7528 - val_loss: 0.5653 - val_accuracy: 0.7512\n",
      "Epoch 145/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5642 - accuracy: 0.7523 - val_loss: 0.5662 - val_accuracy: 0.7511\n",
      "Epoch 146/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5638 - accuracy: 0.7526 - val_loss: 0.5680 - val_accuracy: 0.7504\n",
      "Epoch 147/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5643 - accuracy: 0.7524 - val_loss: 0.5637 - val_accuracy: 0.7521\n",
      "Epoch 148/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5641 - accuracy: 0.7527 - val_loss: 0.5634 - val_accuracy: 0.7525\n",
      "Epoch 149/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5639 - accuracy: 0.7529 - val_loss: 0.5635 - val_accuracy: 0.7526\n",
      "Epoch 150/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5643 - accuracy: 0.7522 - val_loss: 0.5667 - val_accuracy: 0.7512\n",
      "Epoch 151/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5639 - accuracy: 0.7531 - val_loss: 0.5647 - val_accuracy: 0.7524\n",
      "Epoch 152/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5642 - accuracy: 0.7525 - val_loss: 0.5662 - val_accuracy: 0.7509\n",
      "Epoch 153/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5640 - accuracy: 0.7528 - val_loss: 0.5646 - val_accuracy: 0.7517\n",
      "Epoch 154/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5637 - accuracy: 0.7527 - val_loss: 0.5663 - val_accuracy: 0.7503\n",
      "Epoch 155/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5636 - accuracy: 0.7525 - val_loss: 0.5633 - val_accuracy: 0.7523\n",
      "Epoch 156/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5641 - accuracy: 0.7531 - val_loss: 0.5638 - val_accuracy: 0.7509\n",
      "Epoch 157/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5637 - accuracy: 0.7527 - val_loss: 0.5629 - val_accuracy: 0.7520\n",
      "Epoch 158/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5637 - accuracy: 0.7525 - val_loss: 0.5639 - val_accuracy: 0.7513\n",
      "Epoch 159/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5637 - accuracy: 0.7530 - val_loss: 0.5690 - val_accuracy: 0.7515\n",
      "Epoch 160/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5638 - accuracy: 0.7524 - val_loss: 0.5638 - val_accuracy: 0.7528\n",
      "Epoch 161/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5636 - accuracy: 0.7525 - val_loss: 0.5637 - val_accuracy: 0.7522\n",
      "Epoch 162/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5636 - accuracy: 0.7526 - val_loss: 0.5699 - val_accuracy: 0.7501\n",
      "Epoch 163/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5641 - accuracy: 0.7524 - val_loss: 0.5659 - val_accuracy: 0.7517\n",
      "Epoch 164/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5635 - accuracy: 0.7529 - val_loss: 0.5659 - val_accuracy: 0.7508\n",
      "Epoch 165/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5637 - accuracy: 0.7528 - val_loss: 0.5639 - val_accuracy: 0.7523\n",
      "Epoch 166/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5634 - accuracy: 0.7526 - val_loss: 0.5665 - val_accuracy: 0.7507\n",
      "Epoch 167/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5636 - accuracy: 0.7527 - val_loss: 0.5646 - val_accuracy: 0.7522\n",
      "Epoch 168/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5636 - accuracy: 0.7526 - val_loss: 0.5719 - val_accuracy: 0.7499\n",
      "Epoch 169/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5634 - accuracy: 0.7525 - val_loss: 0.5621 - val_accuracy: 0.7526\n",
      "Epoch 170/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5632 - accuracy: 0.7529 - val_loss: 0.5628 - val_accuracy: 0.7526\n",
      "Epoch 171/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5636 - accuracy: 0.7526 - val_loss: 0.5619 - val_accuracy: 0.7523\n",
      "Epoch 172/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5634 - accuracy: 0.7527 - val_loss: 0.5638 - val_accuracy: 0.7524\n",
      "Epoch 173/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5631 - accuracy: 0.7526 - val_loss: 0.5618 - val_accuracy: 0.7526\n",
      "Epoch 174/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5632 - accuracy: 0.7528 - val_loss: 0.5688 - val_accuracy: 0.7485\n",
      "Epoch 175/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5635 - accuracy: 0.7528 - val_loss: 0.5645 - val_accuracy: 0.7525\n",
      "Epoch 176/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5635 - accuracy: 0.7526 - val_loss: 0.5625 - val_accuracy: 0.7529\n",
      "Epoch 177/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5632 - accuracy: 0.7524 - val_loss: 0.5622 - val_accuracy: 0.7525\n",
      "Epoch 178/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5636 - accuracy: 0.7527 - val_loss: 0.5643 - val_accuracy: 0.7520\n",
      "Epoch 179/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5633 - accuracy: 0.7522 - val_loss: 0.5635 - val_accuracy: 0.7519\n",
      "Epoch 180/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5630 - accuracy: 0.7527 - val_loss: 0.5633 - val_accuracy: 0.7517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5636 - accuracy: 0.7525 - val_loss: 0.5635 - val_accuracy: 0.7525\n",
      "Epoch 182/200\n",
      "2498/2498 [==============================] - 5s 2ms/step - loss: 0.5635 - accuracy: 0.7527 - val_loss: 0.5635 - val_accuracy: 0.7523\n",
      "Epoch 183/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5635 - accuracy: 0.7528 - val_loss: 0.5633 - val_accuracy: 0.7520\n",
      "Epoch 184/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5630 - accuracy: 0.7528 - val_loss: 0.5628 - val_accuracy: 0.7519\n",
      "Epoch 185/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5634 - accuracy: 0.7526 - val_loss: 0.5664 - val_accuracy: 0.7512\n",
      "Epoch 186/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5633 - accuracy: 0.7526 - val_loss: 0.5642 - val_accuracy: 0.7526\n",
      "Epoch 187/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5632 - accuracy: 0.7526 - val_loss: 0.5632 - val_accuracy: 0.7523\n",
      "Epoch 188/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5635 - accuracy: 0.7523 - val_loss: 0.5622 - val_accuracy: 0.7524\n",
      "Epoch 189/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5634 - accuracy: 0.7521 - val_loss: 0.5641 - val_accuracy: 0.7519\n",
      "Epoch 190/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5631 - accuracy: 0.7523 - val_loss: 0.5660 - val_accuracy: 0.7515\n",
      "Epoch 191/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5630 - accuracy: 0.7529 - val_loss: 0.5713 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "2498/2498 [==============================] - 2s 935us/step - loss: 0.5632 - accuracy: 0.7526 - val_loss: 0.5633 - val_accuracy: 0.7522\n",
      "Epoch 193/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5633 - accuracy: 0.7525 - val_loss: 0.5682 - val_accuracy: 0.7496\n",
      "Epoch 194/200\n",
      "2498/2498 [==============================] - 2s 961us/step - loss: 0.5633 - accuracy: 0.7522 - val_loss: 0.5622 - val_accuracy: 0.7521\n",
      "Epoch 195/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5634 - accuracy: 0.7523 - val_loss: 0.5666 - val_accuracy: 0.7508\n",
      "Epoch 196/200\n",
      "2498/2498 [==============================] - 4s 2ms/step - loss: 0.5631 - accuracy: 0.7526 - val_loss: 0.5658 - val_accuracy: 0.7514\n",
      "Epoch 197/200\n",
      "2498/2498 [==============================] - 4s 1ms/step - loss: 0.5630 - accuracy: 0.7528 - val_loss: 0.5644 - val_accuracy: 0.7522\n",
      "Epoch 198/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5630 - accuracy: 0.7523 - val_loss: 0.5692 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5629 - accuracy: 0.7527 - val_loss: 0.5626 - val_accuracy: 0.7528\n",
      "Epoch 200/200\n",
      "2498/2498 [==============================] - 3s 1ms/step - loss: 0.5628 - accuracy: 0.7530 - val_loss: 0.5612 - val_accuracy: 0.7532\n",
      "4441/4441 [==============================] - 5s 1ms/step - loss: 1.2836 - accuracy: 0.4454\n",
      "\n",
      "Optimizers:  <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x0000019CAD688A60>\n",
      "Epoch Sizes:  200\n",
      "Neurons or Units:  256\n",
      "Test score: 1.2836450338363647\n",
      "Test accuracy: 0.44542422890663147\n",
      "\n",
      "[0.45332029461860657, 0.45748648047447205, 0.4546433389186859, 0.4510471820831299, 0.4514060914516449, 0.45284879207611084, 0.4473735988140106, 0.44945669174194336, 0.45847174525260925, 0.4521661400794983, 0.45222947001457214, 0.43204593658447266, 0.4422292113304138, 0.4447838068008423, 0.44921743869781494, 0.44308072328567505, 0.44485417008399963, 0.4512723684310913, 0.4547911286354065, 0.4501534104347229, 0.44559311866760254, 0.4394915997982025, 0.44533976912498474, 0.44919630885124207, 0.44129320979118347, 0.45048418641090393, 0.44542422890663147]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Time 21746.080644845963 seconds: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.regularizers import l2\n",
    "import glob \n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "df = pd.concat([pd.read_csv(f, sep=',', na_values=\".\", header=None) for f in glob.glob('watch/gyro/*.txt')], ignore_index=True)\n",
    "\n",
    "Bf = df[[1,3,4,5]][df[1] == 'B']\n",
    "Ff = df[[1,3,4,5]][df[1] == 'F']\n",
    "Sf = df[[1,3,4,5]][df[1] == 'S']\n",
    "\n",
    "ds0 = Bf.append(Ff, ignore_index=True)\n",
    "dsf = ds0.append(Sf, ignore_index=True)\n",
    "\n",
    "X = dsf[[3,4,5]]\n",
    "y = dsf[[1]]\n",
    "\n",
    "#Initialisation\n",
    "No_classes = 3\n",
    "test_split = 0.25\n",
    "ver_bose = 1\n",
    "batchsize = 128\n",
    "\n",
    "#Step 2 Train, test and split the dataset. Random number generator, with popular integer \n",
    "#see numbers are 0 and 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#Step 3 Preprocess the X training data by Scaling\n",
    "sc = StandardScaler(with_mean=True, with_std=True)\n",
    "sc.fit(X_train)\n",
    "\n",
    "#Step3.1 Apply the scaler to the X training data\n",
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "#Step 3.2 Apply the SAME scaler to the X test data\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "#Step 4 convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train[1].factorize()[0], No_classes)\n",
    "y_test  = np_utils.to_categorical(y_test[1].factorize()[0], No_classes)\n",
    "\n",
    "#Step 5 Create and Implement Deep Learning Model\n",
    "accuracy = []\n",
    "for OPTIMIZER in [SGD(), RMSprop(), Adam()]: \n",
    "    for epoch_no in [50,100,200]:\n",
    "        for neurons_no in [64,128,256]:\n",
    "            #Step 5.1 Create the NN architecture\n",
    "            model = Sequential()\n",
    "            #Input Layer\n",
    "            model.add(Dense(units = 14, input_shape=(X_train.shape[1],), kernel_regularizer=l2())) \n",
    "            model.add(Activation('relu'))\n",
    "            #Hiden Layer\n",
    "            model.add(Dense(units = neurons_no, kernel_regularizer=l2()))\n",
    "            model.add(Activation('relu'))\n",
    "            #Output Layer\n",
    "            model.add(Dense(units = No_classes))\n",
    "            model.add(Activation('softmax'))\n",
    "            model.summary()\n",
    "            #Compile and fit the model\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "            model.fit(X_train_std, y_train, batch_size=batchsize, epochs=epoch_no,verbose=ver_bose, validation_split=test_split)\n",
    "            #Evaluate the model\n",
    "            score = model.evaluate(X_test_std, y_test, verbose=ver_bose)\n",
    "\n",
    "            #Print Outputs\n",
    "            print()\n",
    "            print('Optimizers: ', OPTIMIZER)\n",
    "            print('Epoch Sizes: ', epoch_no)            \n",
    "            print('Neurons or Units: ', neurons_no)            \n",
    "            print(\"Test score:\", score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "            accuracy.append(score[1])\n",
    "            print()\n",
    "\n",
    "    print(accuracy)\n",
    "    y = accuracy; N = len(y); x = range(N); width = 1./1.5;\n",
    "    plt.ylim(0.40,1.1)\n",
    "    plt.bar(x,y,width); plt.show()\n",
    "\n",
    "    print()\n",
    "    print(\"Execution Time %s seconds: \" % (time.time() - start_time))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
